
---
title: Gemini to Q*
url: https://browse.arxiv.org/html/2312.10868v1/
---
Abstract

This comprehensive survey explored the evolving landscape of generative Artificial Intelligence (AI), with a specific focus on the transformative impacts of Mixture of Experts (MoE), multimodal learning, and the speculated advancements towards Artificial General Intelligence (AGI). It critically examined the current state and future trajectory of generative Artificial Intelligence (AI), exploring how innovations like Google’s Gemini and the anticipated OpenAI Q* project are reshaping research priorities and applications across various domains, including an impact analysis on the generative AI research taxonomy. It assessed the computational challenges, scalability, and real-world implications of these technologies while highlighting their potential in driving significant progress in fields like healthcare, finance, and education. It also addressed the emerging academic challenges posed by the proliferation of both AI-themed and AI-generated preprints, examining their impact on the peer-review process and scholarly communication. The study highlighted the importance of incorporating ethical and human-centric methods in AI development, ensuring alignment with societal norms and welfare, and outlined a strategy for future AI research that focuses on a balanced and conscientious use of MoE, multimodality, and AGI in generative AI.
Index Terms: AI Ethics, Artificial General Intelligence (AGI), Artificial Intelligence (AI), Gemini, Generative AI, Mixture of Experts (MoE), Multimodality, Q* (Q-star), Research Impact Analysis.
I Introduction

The historical context of AI, tracing back to Alan Turing’s “Imitation Game” [1], early computational theories [2, 3], and the development of the first neural networks and machine learning [4, 5, 6], has set the foundation for today’s advanced models. This evolution, accentuated by crucial moments such as the rise of deep learning and reinforcement learning, has been vital in shaping the contemporary trends in AI, including the sophisticated Mixture of Experts (MoE) models and multimodal AI systems, illustrating the field’s dynamic and continuously evolving character. These advancements are a testament to the dynamic and ever-evolving nature of AI technology. The evolution of Artificial Intelligence (AI) has witnessed a crucial turn with the advent of Large Language Models (LLMs), notably ChatGPT, developed by OpenAI, and the recent unveiling of Google’s Gemini [7, 8]. This technology has not only revolutionized the industry and academia, but has also reignited critical discussions concerning AI consciousness and its potential threats to humanity [9, 10, 11]. The development of such advanced AI systems, including notable competitors like Anthropic’s Claude, and now Gemini, which demonstrates several advances over previous models like GPT-3 and Google’s own LaMDA, has reshaped the research landscape. Gemini’s ability to learn from two-way conversations and its “spike-and-slab” attention method, which allows it to focus on relevant parts of the context during multi-turn conversations, represents a significant leap in developing models that are better equipped for multidomain conversational applications1. These innovations in LLMs, including the mixture-of-experts methods employed by Gemini, signal a move towards models that can handle a diversity of inputs and foster multimodal approaches. Amidst this backdrop, speculations of an OpenAI project known as Q* (Q-Star) have surfaced, allegedly combining the power of LLMs with sophisticated algorithms such as Q-learning and A* (A-Star algorithm), further contributing to the dynamic research environment2.
I-A Changing AI Research Popularity

As the field of LLMs continues to evolve, exemplified by innovations such as Gemini and Q*, a multitude of studies have surfaced with the aim of charting future research paths, which have varied from identifying emerging trends to highlighting areas poised for swift progress. The dichotomy of established methods and early adoption is evident, with “hot topics” in LLM research increasingly shifting towards multimodal capabilities and conversation-driven learning, as demonstrated by Gemini. The propagation of preprints has expedited knowledge sharing, but also brings the risk of reduced academic scrutiny. Issues like inherent biases, noted by Retraction Watch, along with concerns about plagiarism and forgery, present substantial hurdles [12]. The academic world, therefore, stands at an intersection, necessitating a unified drive to refine research directions in light of the fast-paced evolution of the field, which appears to be partly traced through the changing popularity of various research keywords over time. The release of generative models like GPT and the widespread commercial success of ChatGPT have been influential. As depicted in Figure 4, the rise and fall of certain keywords appear to have correlated with significant industry milestones, such as the release of the “Transformer” model in 2017 [13], the GPT model in 2018 [14], and the commercial ChatGPT-3.5 in December 2022. For instance, the spike in searches related to “Deep Learning” coincides with the breakthroughs in neural network applications, while the interest in “Natural Language Processing” surges as models like GPT and LLaMA redefine what’s possible in language understanding and generation. The enduring attention to “Ethics / Ethical” in AI research, despite some fluctuations, reflects the continuous and deep-rooted concern for the moral dimensions of AI, underscoring that ethical considerations are not merely a reactionary measure, but an integral and persistent dialogue within the AI discussion [15].

It is academically intriguing to postulate whether these trends signify a causal relationship, where technological advancements drive research focus, or if the burgeoning research itself propels technological development. This paper also explores the profound societal and economic impacts of AI advancements. We examine how AI technologies are reshaping various industries, altering employment landscapes, and influencing socio-economic structures. This analysis highlights both the opportunities and challenges posed by AI in the modern world, emphasizing its role in driving innovation and economic growth, while also considering the ethical implications and potential for societal disruption. Future studies could yield more definitive insights, yet the synchronous interplay between innovation and academic curiosity remains a hallmark of AI’s progress.
2011201220132014201520162017201820192020202120222023100k200k300k400k500k600k700kYearNumber of search results
Figure 1: Number of search results on Google Scholar with different keywords by year 4

Meanwhile, the exponential increase in the number of preprints posted on arXiv under the Computer Science > Artificial Intelligence (cs.AI) category, as illustrated in Figure 2, appears to signify a paradigm shift in research dissemination within the AI community. While the rapid distribution of findings enables swift knowledge exchange, it also raises concerns regarding the validation of information. The surge in preprints may lead to the propagation of unvalidated or biased information, as these studies do not undergo the rigorous scrutiny and potential retraction typical of peer-reviewed publications [16, 17]. This trend underlines the need for careful consideration and critique in the academic community, especially given the potential for such unvetted studies to be cited and their findings propagated.
201120122013201420152016201720182019202020212022202302,0004,0006,0008,00010,00012,00014,00016,00018,00020,00022,00024,000YearNumber of Preprints
cs.AI Preprints on arXiv
Figure 2: Annual number of preprints posted under the cs.AI category on arXiv.org
I-B Objectives

The impetus for this investigation is the official unveiling of Gemini and the speculative discourse surrounding Q* project, which prompts a timely examination of the prevailing currents in generative AI research. This paper specifically contributes to the understanding of how MoE, multimodality, and Artificial General Intelligence (AGI) are impacting generative AI models, offering detailed analysis and future directions for each of these three key areas. This study does not aim to perpetuate conjecture about the unrevealed Q-Star initiative, but rather to critically appraise the potential for obsolescence or insignificance in extant research themes, whilst concurrently delving into burgeoning prospects within the rapidly transforming LLM panorama. This inquiry is reminiscent of the obsolete nature of encryption-centric or file-entropy-based ransomware detection methodologies, which have been eclipsed by the transition of ransomware collectives towards data theft strategies utilizing varied attack vectors, relegating contemporary studies on crypto-ransomware to the status of latecomers [18, 19]. Advances in AI are anticipated to not only enhance capabilities in language analysis and knowledge synthesis but also to pioneer in areas like Mixture of Experts (MoE) [20, 21, 22, 23, 24, 25], multimodality [26, 27, 28, 29, 30], and Artificial General Intelligence (AGI) [31, 32, 10, 11], and has already heralded the obsolescence of conventional, statistics-driven natural language processing techniques in many domains [8]. Nonetheless, the perennial imperative for AI to align with human ethics and values persists as a fundamental tenet [33, 34, 35], and the conjectural Q-Star initiative offers an unprecedented opportunity to instigate discourse on how such advancements might reconfigure the LLM research topography. Within this milieu, insights from Dr. Jim Fan (senior research scientist & lead of AI agents at NVIDIA) on Q*, particularly concerning the amalgamation of learning and search algorithms, furnish an invaluable perspective on the prospective technical construct and proficiencies of such an undertaking5. Our research methodology involved a structured literature search using key terms like ‘Large Language Models’ and ‘Generative AI’. We utilized filters across several academic databases such as IEEE Xplore, Scopus, ACM Digital Library, ScienceDirect, Web of Science, and ProQuest Central, tailored to identify relevant articles published in the timeframe from 2017 (the release of the “Transformer” model) to 2023 (the writing time of this manuscript). This paper aspires to dissect the technical ramifications of Gemini and Q*, probing how they (and similar technologies whose emergence is now inevitable) may transfigure research trajectories and disclose new vistas in the domain of AI. In doing so, we have pinpointed three nascent research domains—MoE, multimodality, and AGI—that stand to reshape the generative AI research landscape profoundly. This investigation adopts a survey-style approach, systematically mapping out a research roadmap that synthesizes and analyzes the current and emergent trends in generative AI.

The major contributions of this study is as follows:

    1.

    Detailed examination of the evolving landscape in generative AI, emphasizing the advancements and innovations in technologies like Gemini and Q*, and their wide-ranging implications within the AI domain.
    2.

    Analysis of the transformative effect of advanced generative AI systems on academic research, exploring how these developments are altering research methodologies, setting new trends, and potentially leading to the obsolescence of traditional approaches.
    3.

    Thorough assessment of the ethical, societal, and technical challenges arising from the integration of generative AI in academia, underscoring the crucial need for aligning these technologies with ethical norms, ensuring data privacy, and developing comprehensive governance frameworks.

The rest of this paper is organized as follows: Section II explores the historical development of Generative AI. Section III presents a taxonomy of current Generative AI research. Section IV explores the Mixture of Experts (MoE) model architecture, its innovative features, and its impact on transformer-based language models. Section V discusses the speculated capabilities of the Q* project. Section VI discusses the projected capabilities of AGI. Section VII examines the impact of recent advancements on the Generative AI research taxonomy. Section VIII identifies emerging research priorities in Generative AI. Section X discusses the academic challenges of the rapid surge of preprints in AI. The paper concludes in Section XI, summarizing the overall effects of these developments in generative AI.
II Background: Evolution of Generative AI

The ascent of Generative AI has been marked by significant milestones, with each new model paving the way for the next evolutionary leap. From single-purpose algorithms to LLMs like OpenAI’s ChatGPT and the latest multimodal systems, the AI landscape has been transformed, while countless other fields have been disrupted.
II-A The Evolution of Language Models

Language models have undergone a transformative journey (Fig. 3), evolving from rudimentary statistical methods to the complex neural network architectures that underpin today’s LLMs [36, 37]. This evolution has been driven by a relentless quest for models that more accurately reflect the nuances of human language, as well as the desire to push the boundaries of what machines can understand and generate [36, 38, 37]. However, this rapid advancement has not been without its challenges. As language models have grown in capability, so too have the ethical and safety concerns surrounding their use, prompting a reevaluation of how these models are developed and the purposes for which they are employed [36, 39, 40].
1980s: Statistical Models (n-grams)1990s: Adoption in NLP, n-gram Usage1997: Introduction of LSTMs2000s: LSTMs in Text/Voice Processing2010s: Deep Learning Era, GPT, BERT2020s: LLaMA, Gemini; ChatGPT Launch
Figure 3: Timeline of Key Developments in Language Model Evolution
II-A1 Language Models as Precursors

The inception of language modeling can be traced to the statistical approaches of the late 1980s, a period marked by a transition from rule-based to machine learning algorithms in Natural Language Processing (NLP) [41, 42, 43, 44, 45]. Early models, primarily n-gram based, calculated the probability of word sequences in a corpus, thus providing a rudimentary understanding of language structure [41]. Those models, simplistic yet groundbreaking, laid the groundwork for future advances in language understanding. With the increase of computational power, the late 1980s witnessed a revolution in NLP, pivoting towards statistical models capable of ‘soft’ probabilistic decisions, as opposed to the rigid, ‘handwritten’ rule-based systems that dominated early NLP systems [43]. IBM’s development of complicated statistical models throughout this period signified the growing importance and success of these approaches. In the subsequent decade, the popularity and applicability of statistical models surged, proving invaluable in managing the flourishing flow of digital text. The 1990s saw statistical methods firmly established in NLP research, with n-grams becoming instrumental in numerically capturing linguistic patterns. The introduction of Long Short-Term Memory (LSTM) networks in 1997 [46], and their application to voice and text processing a decade later [47, 48, 49], marked a significant milestone, leading to the current era where neural network models represent the cutting edge of NLP research and development.
II-A2 Large Language Models: Technical Advancement and Commercial Success

The advent of deep learning has revolutionized the field of NLP, leading to the development of LLMs like GPT, BERT, and notably, OpenAI’s ChatGPT. Recent models such as GPT-4 and LLaMA have pushed the boundaries by integrating sophisticated techniques like transformer architectures and advanced natural language understanding, illustrating the rapid evolution in this field [37]. These models represent a significant leap in NLP capabilities, leveraging vast computational resources and extensive datasets to achieve new heights in language understanding and generation [37, 50]. ChatGPT has shown impressive conversational skills and contextual understanding with a broad spectrum of functional uses in many areas, as evidenced by its technical and commercial success, including rapid adoption by over 100 million users shortly after launch, which underscores a robust market demand for natural language AI and has catalyzed interdisciplinary research into its applications in sectors like education, healthcare, and commerce [8, 50, 51, 52, 53]. In education, ChatGPT offers innovative approaches to personalized learning and interactive teaching [54, 51, 55, 56], while in commerce, it revolutionizes customer service and content creation [57, 58]. The widespread use of ChatGPT, Google Bard, Anthropic Claude and similar commercial LLMs has reignited important debates in the field of AI, particularly concerning AI consciousness and safety, as its human-like interaction capabilities raise significant ethical questions and highlight the need for robust governance and safety measures in AI development [59, 31, 32, 11]. Such influence appears to extend beyond its technical achievements, shaping cultural and societal discussions about the role and future of AI in our world.

The advancements in LLMs, including the development of models like GPT and BERT, have paved the way for the conceptualization of Q*. Specifically, the scalable architecture and extensive training data that characterize these models are foundational to the proposed capabilities of Q*. The success of ChatGPT in contextual understanding and conversational AI, for example, informs the design principles of Q*, suggesting a trajectory towards more sophisticated, context-aware, and adaptive language processing capabilities. Similarly, the emergence of multimodal systems like Gemini, capable of integrating text, images, audio, and video, reflects an evolutionary path that Q* could extend, combining the versatility of LLMs with advanced learning and pathfinding algorithms for a more holistic AI solution.
II-A3 Fine-tuning, Hallucination Reduction, and Alignment in LLMs

The advancement of LLMs has underlined the significance of fine-tuning [60, 61, 62, 63], hallucination reduction [64, 65, 66, 67], and alignment [68, 69, 70, 71, 72]. These aspects are crucial in enhancing the functionality and reliability of LLMs. Fine-tuning, which involves adapting pre-trained models to specific tasks, has seen significant progress: techniques like prompt-based and few-shot learning [73, 74, 75, 76], alongside supervised fine-tuning on specialized datasets [60, 77, 78, 79], have enhanced the adaptability of LLMs in various contexts, but challenges remain, particularly in bias mitigation and the generalization of models across diverse tasks [60, 80, 72]. Hallucination reduction is a persistent challenge in LLMs, characterized by the generation of confident but factually incorrect information [36]. Strategies such as confidence penalty regularization during fine-tuning have been implemented to mitigate overconfidence and improve accuracy [81, 82, 83]. Despite these efforts, the complexity of human language and the breadth of topics make completely eradicating hallucinations a daunting task, especially in culturally sensitive contexts [36, 9]. Alignment, ensuring LLM outputs are congruent with human values and ethics, is an area of ongoing research. Innovative approaches, from constrained optimization [84, 85, 86, 87, 88], to different types of reward modeling [89, 90, 91, 92], aim to embed human preferences within AI systems. While advancements in fine-tuning, hallucination reduction, and alignment have propelled LLMs forward, these areas still present considerable challenges. The complexity of aligning AI with the diverse spectrum of human ethics and the persistence of hallucinations, particularly on culturally sensitive topics, highlight the need for continued interdisciplinary research in the development and application of LLMs [9].
II-A4 Mixture of Experts: A Paradigm Shift

The adoption of the MoE architecture in LLMs marks a critical evolution in AI technology. This innovative approach, exemplified by advanced models like Google’s Switch Transformer6 and MistralAI s Mixtral-8x7B7, leverages multiple transformer-based expert modules for dynamic token routing, enhancing modeling efficiency and scalability. The primary advantage of MoE lies in its ability to handle vast parameter scales, reducing memory footprint and computational costs significantly [93, 94, 95, 96, 97]. This is achieved through model parallelism across specialized experts, allowing the training of models with trillions of parameters, and its specialization in handling diverse data distributions enhances its capability in few-shot learning and other complex tasks [94, 95]. To illustrate the practicality of MoE, consider its application in healthcare. For example, an MoE-based system could be used for personalized medicine, where different ‘expert’ modules specialize in various aspects of patient data analysis, including genomics, medical imaging, and electronic health records. This approach could significantly enhance diagnostic accuracy and treatment personalization. Similarly, in finance, MoE models can be deployed for risk assessment, where experts analyze distinct financial indicators, market trends, and regulatory compliance factors.

Despite its benefits, MoE confronts challenges in dynamic routing complexity [98, 99, 100, 101, 102], expert imbalance [103, 104, 105, 106], and probability dilution [107], and such technical hurdles demand sophisticated solutions to fully harness MoE’s potential. Moreover, while MoE may offer performance gains, it does not inherently solve ethical alignment issues in AI [108, 109, 110]. The complexity and specialization of MoE models can obscure the decision-making processes, complicating efforts to ensure ethical compliance and alignment with human values [108, 111]. Although the paradigm shift to MoE signifies a major leap in LLM development, offering significant scalability and specialization advantages, ensuring the safety, ethical alignment, and transparency of these models remains a paramount concern. The MoE architecture, while technologically advanced, entails continued interdisciplinary research and governance to align AI with broader societal values and ethical standards.
II-B Multimodal AI and the Future of Interaction

The advent of multimodal AI marks a transformative era in AI development, revolutionizing how machines interpret and interact with a diverse array of human sensory inputs and contextual data.
II-B1 Gemini: Redefining Benchmarks in Multimodality

Gemini, a pioneering multimodal conversational system, marks a significant shift in AI technology by surpassing traditional text-based LLMs like GPT-3 and even its multimodal counterpart, ChatGPT-4. Gemini’s architecture has been designed to incorporate the processing of diverse data types such as text, images, audio, and video, a feat facilitated by its unique multimodal encoder, cross-modal attention network, and multimodal decoder [112]. The architectural core of Gemini is its dual-encoder structure, with separate encoders for visual and textual data, enabling sophisticated multimodal contextualization [112]. This architecture is believed to surpass the capabilities of single-encoder systems, allowing Gemini to associate textual concepts with image regions and achieve a compositional understanding of scenes [112]. Furthermore, Gemini integrates structured knowledge and employs specialized training paradigms for cross-modal intelligence, setting new benchmarks in AI [112]. In [112], Google has claimed and demonstrated that Gemini distinguishes itself from ChatGPT-4 through several key features:

    •

    Breadth of Modalities: Unlike ChatGPT-4, which primarily focuses on text, documents, images, and code, Gemini handles a wider range of modalities including audio, and video. This extensive range allows Gemini to tackle complex tasks and understand real-world contexts more effectively.
    •

    Performance: Gemini Ultra excels in key multimodality benchmarks, notably in massive multitask language understanding (MMLU) which encompasses a diverse array of domains like science, law, and medicine, outperforming ChatGPT-4.
    •

    Scalability and Accessibility: Gemini is available in three tailored versions – Ultra, Pro, and Nano – catering to a range of applications from data centers to on-device tasks, a level of flexibility not yet seen in ChatGPT-4.
    •

    Code Generation: Gemini’s proficiency in understanding and generating code across various programming languages is more advanced, offering practical applications beyond ChatGPT-4’s capabilities.
    •

    Transparency and Explainability: A focus on explainability sets Gemini apart, as it provides justifications for its outputs, enhancing user trust and understanding of the AI’s reasoning process.

Despite these advancements, Gemini’s real-world performance in complex reasoning tasks that require integration of commonsense knowledge across modalities remains to be thoroughly evaluated.
II-B2 Technical Challenges in Multimodal Systems

The development of multimodal AI systems faces several technical hurdles, including creating robust and diverse datasets, managing scalability, and enhancing user trust and system interpretability [113, 114, 115]. Challenges like data skew and bias are prevalent due to data acquisition and annotation issues, which requires effective dataset management by employing strategies such as data augmentation, active learning, and transfer learning [113, 116, 80, 115]. A significant challenge is the computational demands of processing various data streams simultaneously, requiring powerful hardware and optimized model architectures for multiple encoders [117, 118]. Advanced algorithms and multimodal attention mechanisms are needed to balance attention across different input media and resolve conflicts between modalities, especially when they provide contradictory information [119, 120, 118]. Scalability issues, due to the extensive computational resources needed, are exacerbated by limited high-performance hardware availability [121, 122]. There is also a pressing need for calibrated multimodal encoders for compositional scene understanding and data integration [120]. Refining evaluation metrics for these systems is necessary to accurately assess performance in real-world tasks, calling for comprehensive datasets and unified benchmarks, and for enhancing user trust and system interpretability through explainable AI in multimodal contexts. Addressing these challenges is vital for the advancement of multimodal AI systems, enabling seamless and intelligent interaction aligned with human expectations.
II-B3 Multimodal AI: Beyond Text in Ethical and Social Contexts

The expansion of multimodal AI systems introduces both benefits and complex ethical and social challenges that extend beyond those faced by text-based AI. In commerce, multimodal AI can transform customer engagement by integrating visual, textual, and auditory data [123, 124, 125]. For autonomous vehicles, multimodality can enhance safety and navigation by synthesizing data from various sensors, including visual, radar, and Light Detection and Ranging (LIDAR) [126, 125, 127]. Still, DeepFake technology’s ability to generate convincingly realistic videos, audio, and images is a critical concern in multimodality, as it poses risks of misinformation and manipulation that significantly impact public opinion, political landscapes, and personal reputations, thereby compromising the authenticity of digital media and raising issues in social engineering and digital forensics where distinguishing genuine from AI-generated content becomes increasingly challenging [128, 129]. Privacy concerns are amplified in multimodal AI due to its ability to process and correlate diverse data sources, potentially leading to intrusive surveillance and profiling, which raises questions about the consent and rights of individuals, especially when personal media is used without permission for AI training or content creation [113, 130, 131]. Moreover, multimodal AI can propagate and amplify biases and stereotypes across different modalities, and if unchecked, this can perpetuate discrimination and social inequities, making it imperative to address algorithmic bias effectively [132, 133, 134]. The ethical development of multimodal AI systems requires robust governance frameworks focusing on transparency, consent, data handling protocols, and public awareness, when ethical guidelines must evolve to address the unique challenges posed by these technologies, including setting standards for data usage and safeguarding against the nonconsensual exploitation of personal information [135, 136]. Additionally, the development of AI literacy programs will be crucial in helping society understand and responsibly interact with multimodal AI technologies [113, 135]. As the field progresses, interdisciplinary collaboration will be key in ensuring these systems are developed and deployed in a manner that aligns with societal values and ethical principles [113].
II-C Speculative Advances and Chronological Trends

In the dynamic landscape of AI, the speculative capabilities of the Q* project, blending LLMs, Q-learning, and A* (A-Star algorithm), embodies a significant leap forward. This section explores the evolutionary trajectory from game-centric AI systems to the broad applications anticipated with Q*.
II-C1 From AlphaGo’s Groundtruth to Q-Star’s Exploration

The journey from AlphaGo, a game-centric AI, to the conceptual Q-Star project represents a significant paradigm shift in AI. AlphaGo’s mastery in the game of Go highlighted the effectiveness of deep learning and tree search algorithms within well-defined rule-based environments, underscoring the potential of AI in complex strategy and decision-making [137, 138]. Q-Star, however, is speculated to move beyond these confines, aiming to amalgamate the strengths of reinforcement learning (as seen in AlphaGo), with the knowledge, NLG, creativity and versatility of LLMs, and the strategic efficiency of pathfinding algorithms like A*. This blend, merging pathfinding algorithms and LLMs, could enable AI systems to transcend board game confines and, with Q-Star’s natural language processing, interact with human language, enabling nuanced interactions and marking a leap towards AI adept in both structured tasks and complex human-like communication and reasoning. Moreover, the incorporation of Q-learning and A* algorithms would enable Q-Star to optimize decision paths and learn from its interactions, making it more adaptable and intelligent over time. The combination of these technologies could lead to AI that is not only more efficient in problem-solving but also creative and insightful in its approach. This speculative advancement from the game-focused power of AlphaGo to the comprehensive potential of Q-Star illustrates the dynamic and ever-evolving nature of AI research, and opens up possibilities for AI applications that are more integrated with human life and capable of handling a broader range of tasks with greater autonomy and sophistication.
II-C2 Bridging Structured Learning with Creativity

The anticipated Q* project, blending Q-learning and A* algorithms with the creativity of LLMs, embodies a groundbreaking step in AI, potentially surpassing recent innovations like Gemini. The fusion suggested in Q* points to an integration of structured, goal-oriented learning with generative, creative capabilities, a combination that could transcend the existing achievements of Gemini. While Gemini represents a significant leap in multimodal AI, combining various forms of data inputs such as text, images, audio, and video, Q* is speculated to bring a more profound integration of creative reasoning and structured problem-solving. This would be achieved by merging the precision and efficiency of algorithms like A* with the learning adaptability of Q-learning, and the complex understanding of human language and context offered by LLMs. Such an integration could enable AI systems to not only process and analyze complex multimodal data but also to autonomously navigate through structured tasks while engaging in creative problem-solving and knowledge generation, mirroring the multifaceted nature of human cognition. The implications of this potential advancement are vast, suggesting applications that span beyond the capabilities of current multimodal systems like Gemini. By aligning the deterministic aspects of traditional AI algorithms with the creative and generative potential of LLMs, Q* could offer a more holistic approach to AI development. This could bridge the gap between the logical, rule-based processing of AI and the creative, abstract thinking characteristic of human intelligence. The anticipated unveiling of Q*, merging structured learning techniques and creative problem-solving in a singular, advanced framework, holds the promise of not only extending but also significantly surpassing the multimodal capabilities of systems like Gemini, thus heralding another game-changing era in the domain of generative AI, showcasing its potential as a crucial development eagerly awaited in the ongoing evolution of AI.


X Impact of Generative AI on Preprints Across Disciplines

The challenges detailed in this section are not directly related to the knowledge domains within generative AI, but are fueled by the success of Generative AI, particularly the commercialization of ChatGPT. The proliferation of preprints in the field of AI (Fig. 7), especially in the cs.AI category on platforms like arXiv, has introduced a set of academic challenges that merit careful consideration and strategic response. The rapid commercialization and adoption of tools such as ChatGPT, as evidenced by over 55,700 entries on Google Scholar mentioning “ChatGPT” within just one year of its commercialization, exemplify the accelerated pace at which the field is advancing. This rapid development is not mirrored in the traditional peer-review process, which is considerably slower. The peer-review process now appears to be overwhelmed with manuscripts that are either generated with ChatGPT (or other LLMs), or whose writing processes have been significantly accelerated by such LLMs, contributing to a bottleneck in scholarly communication [325, 326]. This situation is further compounded by the fact that many journals in disciplines outside of computer science are also experiencing longer review times and higher rates of desk rejections. Additionally, the flourishing trend of manuscripts and preprints, either generated by or significantly expedited using tools like ChatGPT, extends beyond computer science into diverse academic disciplines. This trend presents a looming challenge, potentially overwhelming both the traditional peer-review process and the flourishing preprint ecosystem with a volume of work that may not always adhere to established academic standards.


The sheer volume of preprints has made the task of selecting and scrutinizing research exceedingly demanding. In the current research era, the exploration of scientific literature has become increasingly complex, as knowledge has continued to expand and disseminate exponentially, while concurrently, integrative research efforts attempting to distill these vast literature, attempt to identify and understand a smaller sets of core contributions [327]. Thus, the rapid expansion of academic literature across various fields presents a significant challenge for researchers seeking to perform evidence syntheses over the increasingly vast body of available knowledge [328]. Furthermore, this explosion in publication volume poses a distinct challenge for literature reviews and surveys, where the human capacity for manually selecting, understanding, and critically evaluating articles is increasingly strained, potentially leading to gaps in synthesizing comprehensive knowledge landscapes. Although reproduction of results is a theoretical possibility, practical constraints such as the lack of technical expertise, computational resources, or access to proprietary datasets hinder rigorous evaluation. This is concerning, as the inability to thoroughly assess preprint research undermines the foundation of scientific reliability and validity. Furthermore, the peer-review system, a cornerstone of academic rigour, is under the threat of being further overwhelmed [325, 329]. The potential consequences are significant, with unvetted preprints possibly perpetuating biases or errors within the scientific community and beyond. The absence of established retraction mechanisms for preprints, akin to those for published articles, exacerbates the risk of persistent dissemination of flawed research.

The academic community is at a crossroads, necessitating an urgent and thoughtful discourse on navigating this emerging “mess” — a situation that risks spiraling out of control if left unaddressed. In this context, the role of peer review becomes increasingly crucial, as it serves as a critical checkpoint for quality and validity, ensuring that the rapid production of AI research is rigorously studied for scientific accuracy and relevance. However, the current modus operandi of traditional peer review does not appear to be sustainable, primarily due to its inability to keep pace with the exponential growth in AI-themed research and Generative-AI-accelerated research submissions, and the increasingly specialized nature of emerging AI topics [325, 326]. This situation is compounded by a finite pool of qualified reviewers, leading to delays, potential biases, and a burden on the scholarly community. This reality demands an exploration of new paradigms for peer review and dissemination of research that can keep pace with swift advancements in AI. Innovative models for community-driven vetting processes, enhanced reproducibility checks, and dynamic frameworks for post-publication scrutiny and correction may be necessary. Efforts to incorporate automated tools and AI-assisted review processes could also be explored to alleviate the strain on human reviewers.

In this rapidly evolving landscape, envision a convergence between the traditional peer review system and the flourishing preprint ecosystem, which could involve creating hybrid models (Fig. 8), where preprints undergo a preliminary community-based review, harnessing the collective expertise and rapid feedback of the academic community, similar to product review websites and Twitter [330]. This approach could provide an initial layer of validation, offering additional insights on issues that may be overlooked by a limited number of peer reviewers. The Editors-in-Chief (EICs) could consider the major criticisms and suggestions of an article from the community-based review, ensuring a more thorough and diverse evaluation. Subsequent, more formal peer review processes could then refine and endorse these preprints for academic rigor and quality assurance. This hybrid model would require robust technological support, possibly leveraging AI and machine learning tools to assist in initial screening and identification of suitable reviewers. The aim would be to establish a seamless continuum from rapid dissemination to validated publication, ensuring both the speed of preprints and the credibility of peer-reviewed research. A balanced approach must be struck to harness the benefits of preprints—such as rapid dissemination of findings and open access—while mitigating their drawbacks. The development of new infrastructure and norms could be instrumental in steering the academic community towards a sustainable model that upholds the integrity and trustworthiness of scientific research in the age of Generative AI.

XI Conclusions

This roadmap survey has embarked on an exploration of the transformative trends in generative AI research, particularly focusing on speculated advancements like Q* and the progressive strides towards AGI. Our analysis highlights a crucial paradigm shift, driven by innovations such as MoE, multimodal learning, and the pursuit of AGI. These advancements signal a future where AI systems could significantly extend their capabilities in reasoning, contextual understanding, and creative problem-solving. This study reflects on AI’s dual potential to either contribute to or impede global equity and justice. The equitable distribution of AI benefits and its role in decision-making processes raise crucial questions about fairness and inclusivity. It is imperative to thoughtfully integrate AI into societal structures to enhance justice and reduce disparities. Despite these advancements, several open questions and research gaps remain. These include ensuring the ethical alignment of advanced AI systems with human values and societal norms, a challenge compounded by their increasing autonomy. The safety and robustness of AGI systems in diverse environments also remain a significant research gap. Addressing these challenges requires a multidisciplinary approach, incorporating ethical, social, and philosophical perspectives.

Our survey has highlighted key areas for future interdisciplinary research in AI, emphasizing the integration of ethical, sociological, and technical perspectives. This approach will foster collaborative research, bridging the gap between technological advancement and societal needs, ensuring that AI development is aligned with human values and global welfare. The roles of MoE, multimodal, and AGI in reshaping generative AI have been identified as significant, as their advancements can enhance model performance and versatility, and pave the way for future research in areas like ethical AI alignment and AGI. As we forge ahead, the balance between AI advancements and human creativity is not just a goal but a necessity, ensuring AI’s role as a complementary force that amplifies our capacity to innovate and solve complex challenges. Our responsibility is to guide these advancements towards enriching the human experience, aligning technological progress with ethical standards and societal well-being.
