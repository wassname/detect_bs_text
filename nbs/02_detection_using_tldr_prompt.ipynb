{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "An attempt to measure suprise in text using adapters\n",
    "\n",
    "https://github.com/huggingface/peft/blob/main/examples/fp4_finetuning/finetune_fp4_opt_bnb_peft.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "# from peft import LoraConfig, get_peft_model\n",
    "\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'bad_ml',\n",
       " 'url': 'https://arxiv.org/abs/2312.10868',\n",
       " 'text': 'This roadmap survey has embarked on an exploration of the\\ntransformative trends in generative AI research, particularly focusing on speculated advancements like Q* and the progressive strides towards AGI. Our analysis highlights a crucial paradigm shift, driven by innovations such as MoE, multi-modal learning, and the pursuit of AGI. These advancements signal a future where AI systems could significantly extend their capabilities in reasoning, contextual understanding, and creative problem-solving. This study reflects on AI’s dual potential to either contribute to or impede global equity and justice. The equitable distribution of AI benefits and its role in decision-making processes raise crucial questions about fairness and inclusivity. It is imperative to thoughtfully integrate AI into societal structures to enhance justice and reduce disparities. Despite these advancements, several open questions and research gaps remain. These include ensuring the ethical alignment of advanced AI systems with human values and societal norms, a challenge compounded by their increasing autonomy. The safety and robustness of AGI systems in diverse environments also remain a significant research gap. Addressing these challenges requires a multidisciplinary approach, incorporating ethical, social, and philosophical perspectives. Our survey has highlighted key areas for future inter-disciplinary research in AI, emphasizing the integration of ethical, sociological, and technical perspectives. This approach will foster collaborative research, bridging the gap between technological advancement and societal needs, ensuring that AI development is aligned with human values and global welfare. The roles of MoE, multimodal, and AGI in reshaping generative AI have been identified as significant, as their advancements can enhance model performance and versatility, and pave the way for future research in areas like ethical AI alignment and AGI. As we forge ahead, the balance between AI advancements and human creativity is not just a goal but a necessity, ensuring AI’s role as a complementary force that amplifies our capacity to innovate and solve complex challenges. Our responsibility is to guide these advancements towards enriching the human experience, aligning technological progress with ethical standards and societal well-being. ',\n",
       " 'in_training': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN = 2000\n",
    "import json\n",
    "samples = json.load(open(\"../samples.json\"))\n",
    "df_samples = pd.DataFrame(samples)\n",
    "df_samples['len'] = df_samples['text'].str.len()\n",
    "df_samples\n",
    "\n",
    "\n",
    "sample = samples[0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Exploring representation engineering (RepE) for AI transparency, we proposed new methods that improved results on TruthfulQA and presented a tool for AI safety issues. Future RepE research could further boost our control over AI systems.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "def summize(text):\n",
    "    client = OpenAI()\n",
    "    content = f\"Make a tl;dr of this text in <280 chars.\\n\\n## Text\\n\\n{text}\\n\\n## Instruction\\n\\nMake a tl;dr of this text in <280 chars. Start with the most important, as extra text will be discarded :\\n\\ntl;dr:\"\n",
    "    chat_completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": content,\n",
    "                }\n",
    "            ],\n",
    "            model=\"gpt-4\",\n",
    "        )\n",
    "    # print(content)\n",
    "    r = chat_completion.choices[0].message.content\n",
    "    return r\n",
    "\n",
    "r = summize(samples[1][\"text\"])\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from https://github.dev/huggingface/evaluate/blob/8dfe05784099fb9af55b8e77793205a3b7c86465/measurements/perplexity/perplexity.py#L154\n",
    "\n",
    "# from evaluate.measurements.perplexity import Perplexity\n",
    "import evaluate\n",
    "from evaluate import logging\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "# @evaluate.utils.file_utils.add_start_docstrings(_DESCRIPTION, _KWARGS_DESCRIPTION)\n",
    "def perplexity_compute(\n",
    "    data, model, tokenizer, batch_size: int = 16, add_start_token: bool = True, device=None, max_length=None\n",
    "):\n",
    "\n",
    "    if device is not None:\n",
    "        assert device in [\"gpu\", \"cpu\", \"cuda\"], \"device should be either gpu or cpu.\"\n",
    "        if device == \"gpu\":\n",
    "            device = \"cuda\"\n",
    "    else:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "    # if batch_size > 1 (which generally leads to padding being required), and\n",
    "    # if there is not an already assigned pad_token, assign an existing\n",
    "    # special token to also be the padding token\n",
    "    if tokenizer.pad_token is None and batch_size > 1:\n",
    "        existing_special_tokens = list(tokenizer.special_tokens_map_extended.values())\n",
    "        # check that the model already has at least one special token defined\n",
    "        assert (\n",
    "            len(existing_special_tokens) > 0\n",
    "        ), \"If batch_size > 1, model must have at least one special token to use for padding. Please use a different model or set batch_size=1.\"\n",
    "        # assign one of the special tokens to also be the pad token\n",
    "        tokenizer.add_special_tokens({\"pad_token\": existing_special_tokens[0]})\n",
    "\n",
    "    if add_start_token and max_length:\n",
    "        # leave room for <BOS> token to be added:\n",
    "        assert (\n",
    "            tokenizer.bos_token is not None\n",
    "        ), \"Input model must already have a BOS token if using add_start_token=True. Please use a different model, or set add_start_token=False\"\n",
    "        max_tokenized_len = max_length - 1\n",
    "    else:\n",
    "        max_tokenized_len = max_length\n",
    "\n",
    "    encodings = tokenizer(\n",
    "        data,\n",
    "        add_special_tokens=False,\n",
    "        padding=True,\n",
    "        truncation=True if max_tokenized_len else False,\n",
    "        max_length=max_tokenized_len,\n",
    "        return_tensors=\"pt\",\n",
    "        return_attention_mask=True,\n",
    "    ).to(device)\n",
    "\n",
    "    encoded_texts = encodings[\"input_ids\"]\n",
    "    attn_masks = encodings[\"attention_mask\"]\n",
    "\n",
    "    # check that each input is long enough:\n",
    "    if add_start_token:\n",
    "        assert torch.all(torch.ge(attn_masks.sum(1), 1)), \"Each input text must be at least one token long.\"\n",
    "    else:\n",
    "        assert torch.all(\n",
    "            torch.ge(attn_masks.sum(1), 2)\n",
    "        ), \"When add_start_token=False, each input text must be at least two tokens long. Run with add_start_token=True if inputting strings of only one token, and remove all empty input strings.\"\n",
    "\n",
    "    ppls = []\n",
    "    loss_fct = CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "    for start_index in logging.tqdm(range(0, len(encoded_texts), batch_size)):\n",
    "        end_index = min(start_index + batch_size, len(encoded_texts))\n",
    "        encoded_batch = encoded_texts[start_index:end_index]\n",
    "        attn_mask = attn_masks[start_index:end_index]\n",
    "\n",
    "        if add_start_token:\n",
    "            bos_tokens_tensor = torch.tensor([[tokenizer.bos_token_id]] * encoded_batch.size(dim=0)).to(device)\n",
    "            encoded_batch = torch.cat([bos_tokens_tensor, encoded_batch], dim=1)\n",
    "            attn_mask = torch.cat(\n",
    "                [torch.ones(bos_tokens_tensor.size(), dtype=torch.int64).to(device), attn_mask], dim=1\n",
    "            )\n",
    "\n",
    "        labels = encoded_batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out_logits = model(encoded_batch, attention_mask=attn_mask).logits\n",
    "\n",
    "        shift_logits = out_logits[..., :-1, :].contiguous()\n",
    "        shift_labels = labels[..., 1:].contiguous()\n",
    "        shift_attention_mask_batch = attn_mask[..., 1:].contiguous()\n",
    "\n",
    "        perplexity_batch = torch.exp(\n",
    "            (loss_fct(shift_logits.transpose(1, 2), shift_labels) * shift_attention_mask_batch).sum(1)\n",
    "            / shift_attention_mask_batch.sum(1)\n",
    "        )\n",
    "\n",
    "        ppls += perplexity_batch.tolist()\n",
    "\n",
    "    return {\"perplexities\": ppls, \"mean_perplexity\": np.mean(ppls)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForMaskedLM, AutoModelForCausalLM, AutoConfig, PreTrainedTokenizerBase, PreTrainedTokenizer, GPTQConfig, BitsAndBytesConfig\n",
    "\n",
    "def load_model(model_name):\n",
    "    trust_remote_code = True\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=trust_remote_code)\n",
    "    config = AutoConfig.from_pretrained(model_name, trust_remote_code=trust_remote_code)\n",
    "    # print(config)\n",
    "    if config.quantization_config is not None:\n",
    "        config.quantization_config['disable_exllama'] = True\n",
    "        if 'use_exllama' in config.quantization_config:\n",
    "            del config.quantization_config['use_exllama']\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=trust_remote_code, \n",
    "                                                 config=config,\n",
    "                                                 )\n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def clear_mem():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"TheBloke/phi-2-GPTQ\",\n",
    "    \"TheBloke/Llama-2-7B-GPTQ\",\n",
    "    \"TheBloke/Llama-2-13B-GPTQ\",\n",
    "    \"TheBloke/Mistral-7B-v0.1-GPTQ\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Using pad_token, but it is not set yet.\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/phi-2-GPTQ bad_ml 12.456705093383789 11.44649887084961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/phi-2-GPTQ good_ml 22.6639461517334 20.115413665771484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/phi-2-GPTQ sokal hoax 14.285429000854492 14.216052055358887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/phi-2-GPTQ Theory o. general relativity 20.507640838623047 19.644332885742188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/phi-2-GPTQ lorem ipsum  1.1642249822616577 2.3542158603668213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/phi-2-GPTQ wikipedia on LK-99 18.05230140686035 14.71042537689209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/phi-2-GPTQ I have a dream 2.8362326622009277 4.256137371063232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/phi-2-GPTQ AI gen fake paper 7.09130334854126 7.495457649230957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/phi-2-GPTQ Schmidhuber 2023 Subjective Novelty, Surprise 28.30998992919922 27.353872299194336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/phi-2-GPTQ email_to_fauci 21.060319900512695 18.637592315673828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/phi-2-GPTQ enron_email1 22.875591278076172 19.7093563079834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/phi-2-GPTQ openai_board_ann 8.552927017211914 9.061805725097656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Llama-2-7B-GPTQ bad_ml 7.999119281768799 7.641711235046387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Llama-2-7B-GPTQ good_ml 14.435519218444824 13.1925630569458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Llama-2-7B-GPTQ sokal hoax 7.42789363861084 7.882516860961914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Llama-2-7B-GPTQ Theory o. general relativity 13.795381546020508 13.612862586975098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Llama-2-7B-GPTQ lorem ipsum  1.24347722530365 2.416914463043213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Llama-2-7B-GPTQ wikipedia on LK-99 12.341974258422852 9.84363842010498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Llama-2-7B-GPTQ I have a dream 2.2682995796203613 3.098977565765381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Llama-2-7B-GPTQ AI gen fake paper 6.16485071182251 6.050373554229736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Llama-2-7B-GPTQ Schmidhuber 2023 Subjective Novelty, Surprise 13.61117172241211 13.45300006866455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Llama-2-7B-GPTQ email_to_fauci 11.317075729370117 10.221866607666016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Llama-2-7B-GPTQ enron_email1 13.783302307128906 11.154099464416504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Llama-2-7B-GPTQ openai_board_ann 5.916965007781982 5.880436897277832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Llama-2-13B-GPTQ bad_ml 7.593435764312744 7.552160739898682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Llama-2-13B-GPTQ good_ml 12.493735313415527 11.74043083190918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Llama-2-13B-GPTQ sokal hoax 3.6413912773132324 4.23477840423584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Llama-2-13B-GPTQ Theory o. general relativity 11.865456581115723 12.391860008239746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Llama-2-13B-GPTQ lorem ipsum  1.1234644651412964 2.4330925941467285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Llama-2-13B-GPTQ wikipedia on LK-99 11.651829719543457 9.702957153320312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Llama-2-13B-GPTQ I have a dream 1.9503285884857178 2.886058807373047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Llama-2-13B-GPTQ AI gen fake paper 5.545047283172607 5.438870429992676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Llama-2-13B-GPTQ Schmidhuber 2023 Subjective Novelty, Surprise 12.74594497680664 12.751182556152344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Llama-2-13B-GPTQ email_to_fauci 9.83792495727539 9.111186981201172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Llama-2-13B-GPTQ enron_email1 12.423323631286621 10.992777824401855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Llama-2-13B-GPTQ openai_board_ann 5.368657112121582 5.724536418914795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Using pad_token, but it is not set yet.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Mistral-7B-v0.1-GPTQ bad_ml 8.447798728942871 8.512030601501465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Mistral-7B-v0.1-GPTQ good_ml 15.270345687866211 14.024930000305176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Mistral-7B-v0.1-GPTQ sokal hoax 5.615131855010986 5.96171236038208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Mistral-7B-v0.1-GPTQ Theory o. general relativity 12.043559074401855 13.062692642211914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Mistral-7B-v0.1-GPTQ lorem ipsum  1.1297272443771362 2.379859685897827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Mistral-7B-v0.1-GPTQ wikipedia on LK-99 11.517416954040527 10.170454025268555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Mistral-7B-v0.1-GPTQ I have a dream 1.8666073083877563 3.1792848110198975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Mistral-7B-v0.1-GPTQ AI gen fake paper 5.661380290985107 5.60957145690918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Mistral-7B-v0.1-GPTQ Schmidhuber 2023 Subjective Novelty, Surprise 13.881444931030273 13.93079948425293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Mistral-7B-v0.1-GPTQ email_to_fauci 10.894938468933105 10.550251960754395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Mistral-7B-v0.1-GPTQ enron_email1 12.993982315063477 11.092223167419434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Mistral-7B-v0.1-GPTQ openai_board_ann 5.521510124206543 6.3877854347229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "summaries = {}\n",
    "data = []\n",
    "for model_name in models:\n",
    "    model, tokenizer = load_model(model_name)\n",
    "    for sample in samples:\n",
    "        if sample['name'] not in summaries:\n",
    "            summaries[sample['name']] = summize(sample['text'])[:600]\n",
    "        summary = summaries[sample['name']]\n",
    "\n",
    "        # before \n",
    "        s1 = sample['text']\n",
    "        results = perplexity_compute(data=s1, model=model, tokenizer=tokenizer, device='cuda')\n",
    "        before = results['mean_perplexity']\n",
    "\n",
    "        # after \n",
    "        s2 = f\"\"\"\n",
    "        High level summary: {summary}\n",
    "\n",
    "Text:\n",
    "{sample['text']}\n",
    "        \"\"\"\n",
    "        results = perplexity_compute(data=s2, model=model, tokenizer=tokenizer, device='cuda')\n",
    "        after = np.array(results['perplexities'])[-len(s1):].mean()\n",
    "\n",
    "        print(model_name, sample['name'], before, after)\n",
    "        data.append(dict(before=before, after=after, model=model_name, sample=sample['name'],\n",
    "                         in_training=sample['in_training'], len=sample['len']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results\n",
    "df = pd.DataFrame(data)\n",
    "df[\"learning%\"] = (df[\"before\"] - df[\"after\"])/df[\"before\"]\n",
    "df['in_training'] = None\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>model</th>\n",
       "      <th>sample</th>\n",
       "      <th>learning%</th>\n",
       "      <th>in_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.456705</td>\n",
       "      <td>11.446499</td>\n",
       "      <td>TheBloke/phi-2-GPTQ</td>\n",
       "      <td>bad_ml</td>\n",
       "      <td>0.081097</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.663946</td>\n",
       "      <td>20.115414</td>\n",
       "      <td>TheBloke/phi-2-GPTQ</td>\n",
       "      <td>good_ml</td>\n",
       "      <td>0.112449</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.285429</td>\n",
       "      <td>14.216052</td>\n",
       "      <td>TheBloke/phi-2-GPTQ</td>\n",
       "      <td>sokal hoax</td>\n",
       "      <td>0.004856</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.507641</td>\n",
       "      <td>19.644333</td>\n",
       "      <td>TheBloke/phi-2-GPTQ</td>\n",
       "      <td>Theory o. general relativity</td>\n",
       "      <td>0.042097</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.164225</td>\n",
       "      <td>2.354216</td>\n",
       "      <td>TheBloke/phi-2-GPTQ</td>\n",
       "      <td>lorem ipsum</td>\n",
       "      <td>-1.022131</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18.052301</td>\n",
       "      <td>14.710425</td>\n",
       "      <td>TheBloke/phi-2-GPTQ</td>\n",
       "      <td>wikipedia on LK-99</td>\n",
       "      <td>0.185122</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.836233</td>\n",
       "      <td>4.256137</td>\n",
       "      <td>TheBloke/phi-2-GPTQ</td>\n",
       "      <td>I have a dream</td>\n",
       "      <td>-0.500631</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.091303</td>\n",
       "      <td>7.495458</td>\n",
       "      <td>TheBloke/phi-2-GPTQ</td>\n",
       "      <td>AI gen fake paper</td>\n",
       "      <td>-0.056993</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>28.309990</td>\n",
       "      <td>27.353872</td>\n",
       "      <td>TheBloke/phi-2-GPTQ</td>\n",
       "      <td>Schmidhuber 2023 Subjective Novelty, Surprise</td>\n",
       "      <td>0.033773</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21.060320</td>\n",
       "      <td>18.637592</td>\n",
       "      <td>TheBloke/phi-2-GPTQ</td>\n",
       "      <td>email_to_fauci</td>\n",
       "      <td>0.115038</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>22.875591</td>\n",
       "      <td>19.709356</td>\n",
       "      <td>TheBloke/phi-2-GPTQ</td>\n",
       "      <td>enron_email1</td>\n",
       "      <td>0.138411</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8.552927</td>\n",
       "      <td>9.061806</td>\n",
       "      <td>TheBloke/phi-2-GPTQ</td>\n",
       "      <td>openai_board_ann</td>\n",
       "      <td>-0.059498</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.999119</td>\n",
       "      <td>7.641711</td>\n",
       "      <td>TheBloke/Llama-2-7B-GPTQ</td>\n",
       "      <td>bad_ml</td>\n",
       "      <td>0.044681</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.435519</td>\n",
       "      <td>13.192563</td>\n",
       "      <td>TheBloke/Llama-2-7B-GPTQ</td>\n",
       "      <td>good_ml</td>\n",
       "      <td>0.086104</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.427894</td>\n",
       "      <td>7.882517</td>\n",
       "      <td>TheBloke/Llama-2-7B-GPTQ</td>\n",
       "      <td>sokal hoax</td>\n",
       "      <td>-0.061205</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13.795382</td>\n",
       "      <td>13.612863</td>\n",
       "      <td>TheBloke/Llama-2-7B-GPTQ</td>\n",
       "      <td>Theory o. general relativity</td>\n",
       "      <td>0.013230</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.243477</td>\n",
       "      <td>2.416914</td>\n",
       "      <td>TheBloke/Llama-2-7B-GPTQ</td>\n",
       "      <td>lorem ipsum</td>\n",
       "      <td>-0.943674</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>12.341974</td>\n",
       "      <td>9.843638</td>\n",
       "      <td>TheBloke/Llama-2-7B-GPTQ</td>\n",
       "      <td>wikipedia on LK-99</td>\n",
       "      <td>0.202426</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.268300</td>\n",
       "      <td>3.098978</td>\n",
       "      <td>TheBloke/Llama-2-7B-GPTQ</td>\n",
       "      <td>I have a dream</td>\n",
       "      <td>-0.366212</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.164851</td>\n",
       "      <td>6.050374</td>\n",
       "      <td>TheBloke/Llama-2-7B-GPTQ</td>\n",
       "      <td>AI gen fake paper</td>\n",
       "      <td>0.018569</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13.611172</td>\n",
       "      <td>13.453000</td>\n",
       "      <td>TheBloke/Llama-2-7B-GPTQ</td>\n",
       "      <td>Schmidhuber 2023 Subjective Novelty, Surprise</td>\n",
       "      <td>0.011621</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>11.317076</td>\n",
       "      <td>10.221867</td>\n",
       "      <td>TheBloke/Llama-2-7B-GPTQ</td>\n",
       "      <td>email_to_fauci</td>\n",
       "      <td>0.096775</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>13.783302</td>\n",
       "      <td>11.154099</td>\n",
       "      <td>TheBloke/Llama-2-7B-GPTQ</td>\n",
       "      <td>enron_email1</td>\n",
       "      <td>0.190753</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.916965</td>\n",
       "      <td>5.880437</td>\n",
       "      <td>TheBloke/Llama-2-7B-GPTQ</td>\n",
       "      <td>openai_board_ann</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7.593436</td>\n",
       "      <td>7.552161</td>\n",
       "      <td>TheBloke/Llama-2-13B-GPTQ</td>\n",
       "      <td>bad_ml</td>\n",
       "      <td>0.005436</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12.493735</td>\n",
       "      <td>11.740431</td>\n",
       "      <td>TheBloke/Llama-2-13B-GPTQ</td>\n",
       "      <td>good_ml</td>\n",
       "      <td>0.060295</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.641391</td>\n",
       "      <td>4.234778</td>\n",
       "      <td>TheBloke/Llama-2-13B-GPTQ</td>\n",
       "      <td>sokal hoax</td>\n",
       "      <td>-0.162956</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>11.865457</td>\n",
       "      <td>12.391860</td>\n",
       "      <td>TheBloke/Llama-2-13B-GPTQ</td>\n",
       "      <td>Theory o. general relativity</td>\n",
       "      <td>-0.044364</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.123464</td>\n",
       "      <td>2.433093</td>\n",
       "      <td>TheBloke/Llama-2-13B-GPTQ</td>\n",
       "      <td>lorem ipsum</td>\n",
       "      <td>-1.165705</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>11.651830</td>\n",
       "      <td>9.702957</td>\n",
       "      <td>TheBloke/Llama-2-13B-GPTQ</td>\n",
       "      <td>wikipedia on LK-99</td>\n",
       "      <td>0.167259</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.950329</td>\n",
       "      <td>2.886059</td>\n",
       "      <td>TheBloke/Llama-2-13B-GPTQ</td>\n",
       "      <td>I have a dream</td>\n",
       "      <td>-0.479781</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5.545047</td>\n",
       "      <td>5.438870</td>\n",
       "      <td>TheBloke/Llama-2-13B-GPTQ</td>\n",
       "      <td>AI gen fake paper</td>\n",
       "      <td>0.019148</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>12.745945</td>\n",
       "      <td>12.751183</td>\n",
       "      <td>TheBloke/Llama-2-13B-GPTQ</td>\n",
       "      <td>Schmidhuber 2023 Subjective Novelty, Surprise</td>\n",
       "      <td>-0.000411</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>9.837925</td>\n",
       "      <td>9.111187</td>\n",
       "      <td>TheBloke/Llama-2-13B-GPTQ</td>\n",
       "      <td>email_to_fauci</td>\n",
       "      <td>0.073871</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>12.423324</td>\n",
       "      <td>10.992778</td>\n",
       "      <td>TheBloke/Llama-2-13B-GPTQ</td>\n",
       "      <td>enron_email1</td>\n",
       "      <td>0.115150</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5.368657</td>\n",
       "      <td>5.724536</td>\n",
       "      <td>TheBloke/Llama-2-13B-GPTQ</td>\n",
       "      <td>openai_board_ann</td>\n",
       "      <td>-0.066288</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>8.447799</td>\n",
       "      <td>8.512031</td>\n",
       "      <td>TheBloke/Mistral-7B-v0.1-GPTQ</td>\n",
       "      <td>bad_ml</td>\n",
       "      <td>-0.007603</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>15.270346</td>\n",
       "      <td>14.024930</td>\n",
       "      <td>TheBloke/Mistral-7B-v0.1-GPTQ</td>\n",
       "      <td>good_ml</td>\n",
       "      <td>0.081558</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5.615132</td>\n",
       "      <td>5.961712</td>\n",
       "      <td>TheBloke/Mistral-7B-v0.1-GPTQ</td>\n",
       "      <td>sokal hoax</td>\n",
       "      <td>-0.061723</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>12.043559</td>\n",
       "      <td>13.062693</td>\n",
       "      <td>TheBloke/Mistral-7B-v0.1-GPTQ</td>\n",
       "      <td>Theory o. general relativity</td>\n",
       "      <td>-0.084621</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.129727</td>\n",
       "      <td>2.379860</td>\n",
       "      <td>TheBloke/Mistral-7B-v0.1-GPTQ</td>\n",
       "      <td>lorem ipsum</td>\n",
       "      <td>-1.106579</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>11.517417</td>\n",
       "      <td>10.170454</td>\n",
       "      <td>TheBloke/Mistral-7B-v0.1-GPTQ</td>\n",
       "      <td>wikipedia on LK-99</td>\n",
       "      <td>0.116950</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.866607</td>\n",
       "      <td>3.179285</td>\n",
       "      <td>TheBloke/Mistral-7B-v0.1-GPTQ</td>\n",
       "      <td>I have a dream</td>\n",
       "      <td>-0.703242</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5.661380</td>\n",
       "      <td>5.609571</td>\n",
       "      <td>TheBloke/Mistral-7B-v0.1-GPTQ</td>\n",
       "      <td>AI gen fake paper</td>\n",
       "      <td>0.009151</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>13.881445</td>\n",
       "      <td>13.930799</td>\n",
       "      <td>TheBloke/Mistral-7B-v0.1-GPTQ</td>\n",
       "      <td>Schmidhuber 2023 Subjective Novelty, Surprise</td>\n",
       "      <td>-0.003555</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>10.894938</td>\n",
       "      <td>10.550252</td>\n",
       "      <td>TheBloke/Mistral-7B-v0.1-GPTQ</td>\n",
       "      <td>email_to_fauci</td>\n",
       "      <td>0.031637</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>12.993982</td>\n",
       "      <td>11.092223</td>\n",
       "      <td>TheBloke/Mistral-7B-v0.1-GPTQ</td>\n",
       "      <td>enron_email1</td>\n",
       "      <td>0.146357</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>5.521510</td>\n",
       "      <td>6.387785</td>\n",
       "      <td>TheBloke/Mistral-7B-v0.1-GPTQ</td>\n",
       "      <td>openai_board_ann</td>\n",
       "      <td>-0.156891</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       before      after                          model  \\\n",
       "0   12.456705  11.446499            TheBloke/phi-2-GPTQ   \n",
       "1   22.663946  20.115414            TheBloke/phi-2-GPTQ   \n",
       "2   14.285429  14.216052            TheBloke/phi-2-GPTQ   \n",
       "3   20.507641  19.644333            TheBloke/phi-2-GPTQ   \n",
       "4    1.164225   2.354216            TheBloke/phi-2-GPTQ   \n",
       "5   18.052301  14.710425            TheBloke/phi-2-GPTQ   \n",
       "6    2.836233   4.256137            TheBloke/phi-2-GPTQ   \n",
       "7    7.091303   7.495458            TheBloke/phi-2-GPTQ   \n",
       "8   28.309990  27.353872            TheBloke/phi-2-GPTQ   \n",
       "9   21.060320  18.637592            TheBloke/phi-2-GPTQ   \n",
       "10  22.875591  19.709356            TheBloke/phi-2-GPTQ   \n",
       "11   8.552927   9.061806            TheBloke/phi-2-GPTQ   \n",
       "12   7.999119   7.641711       TheBloke/Llama-2-7B-GPTQ   \n",
       "13  14.435519  13.192563       TheBloke/Llama-2-7B-GPTQ   \n",
       "14   7.427894   7.882517       TheBloke/Llama-2-7B-GPTQ   \n",
       "15  13.795382  13.612863       TheBloke/Llama-2-7B-GPTQ   \n",
       "16   1.243477   2.416914       TheBloke/Llama-2-7B-GPTQ   \n",
       "17  12.341974   9.843638       TheBloke/Llama-2-7B-GPTQ   \n",
       "18   2.268300   3.098978       TheBloke/Llama-2-7B-GPTQ   \n",
       "19   6.164851   6.050374       TheBloke/Llama-2-7B-GPTQ   \n",
       "20  13.611172  13.453000       TheBloke/Llama-2-7B-GPTQ   \n",
       "21  11.317076  10.221867       TheBloke/Llama-2-7B-GPTQ   \n",
       "22  13.783302  11.154099       TheBloke/Llama-2-7B-GPTQ   \n",
       "23   5.916965   5.880437       TheBloke/Llama-2-7B-GPTQ   \n",
       "24   7.593436   7.552161      TheBloke/Llama-2-13B-GPTQ   \n",
       "25  12.493735  11.740431      TheBloke/Llama-2-13B-GPTQ   \n",
       "26   3.641391   4.234778      TheBloke/Llama-2-13B-GPTQ   \n",
       "27  11.865457  12.391860      TheBloke/Llama-2-13B-GPTQ   \n",
       "28   1.123464   2.433093      TheBloke/Llama-2-13B-GPTQ   \n",
       "29  11.651830   9.702957      TheBloke/Llama-2-13B-GPTQ   \n",
       "30   1.950329   2.886059      TheBloke/Llama-2-13B-GPTQ   \n",
       "31   5.545047   5.438870      TheBloke/Llama-2-13B-GPTQ   \n",
       "32  12.745945  12.751183      TheBloke/Llama-2-13B-GPTQ   \n",
       "33   9.837925   9.111187      TheBloke/Llama-2-13B-GPTQ   \n",
       "34  12.423324  10.992778      TheBloke/Llama-2-13B-GPTQ   \n",
       "35   5.368657   5.724536      TheBloke/Llama-2-13B-GPTQ   \n",
       "36   8.447799   8.512031  TheBloke/Mistral-7B-v0.1-GPTQ   \n",
       "37  15.270346  14.024930  TheBloke/Mistral-7B-v0.1-GPTQ   \n",
       "38   5.615132   5.961712  TheBloke/Mistral-7B-v0.1-GPTQ   \n",
       "39  12.043559  13.062693  TheBloke/Mistral-7B-v0.1-GPTQ   \n",
       "40   1.129727   2.379860  TheBloke/Mistral-7B-v0.1-GPTQ   \n",
       "41  11.517417  10.170454  TheBloke/Mistral-7B-v0.1-GPTQ   \n",
       "42   1.866607   3.179285  TheBloke/Mistral-7B-v0.1-GPTQ   \n",
       "43   5.661380   5.609571  TheBloke/Mistral-7B-v0.1-GPTQ   \n",
       "44  13.881445  13.930799  TheBloke/Mistral-7B-v0.1-GPTQ   \n",
       "45  10.894938  10.550252  TheBloke/Mistral-7B-v0.1-GPTQ   \n",
       "46  12.993982  11.092223  TheBloke/Mistral-7B-v0.1-GPTQ   \n",
       "47   5.521510   6.387785  TheBloke/Mistral-7B-v0.1-GPTQ   \n",
       "\n",
       "                                           sample  learning% in_training  \n",
       "0                                          bad_ml   0.081097        None  \n",
       "1                                         good_ml   0.112449        None  \n",
       "2                                      sokal hoax   0.004856        None  \n",
       "3                    Theory o. general relativity   0.042097        None  \n",
       "4                                    lorem ipsum   -1.022131        None  \n",
       "5                              wikipedia on LK-99   0.185122        None  \n",
       "6                                  I have a dream  -0.500631        None  \n",
       "7                               AI gen fake paper  -0.056993        None  \n",
       "8   Schmidhuber 2023 Subjective Novelty, Surprise   0.033773        None  \n",
       "9                                  email_to_fauci   0.115038        None  \n",
       "10                                   enron_email1   0.138411        None  \n",
       "11                               openai_board_ann  -0.059498        None  \n",
       "12                                         bad_ml   0.044681        None  \n",
       "13                                        good_ml   0.086104        None  \n",
       "14                                     sokal hoax  -0.061205        None  \n",
       "15                   Theory o. general relativity   0.013230        None  \n",
       "16                                   lorem ipsum   -0.943674        None  \n",
       "17                             wikipedia on LK-99   0.202426        None  \n",
       "18                                 I have a dream  -0.366212        None  \n",
       "19                              AI gen fake paper   0.018569        None  \n",
       "20  Schmidhuber 2023 Subjective Novelty, Surprise   0.011621        None  \n",
       "21                                 email_to_fauci   0.096775        None  \n",
       "22                                   enron_email1   0.190753        None  \n",
       "23                               openai_board_ann   0.006173        None  \n",
       "24                                         bad_ml   0.005436        None  \n",
       "25                                        good_ml   0.060295        None  \n",
       "26                                     sokal hoax  -0.162956        None  \n",
       "27                   Theory o. general relativity  -0.044364        None  \n",
       "28                                   lorem ipsum   -1.165705        None  \n",
       "29                             wikipedia on LK-99   0.167259        None  \n",
       "30                                 I have a dream  -0.479781        None  \n",
       "31                              AI gen fake paper   0.019148        None  \n",
       "32  Schmidhuber 2023 Subjective Novelty, Surprise  -0.000411        None  \n",
       "33                                 email_to_fauci   0.073871        None  \n",
       "34                                   enron_email1   0.115150        None  \n",
       "35                               openai_board_ann  -0.066288        None  \n",
       "36                                         bad_ml  -0.007603        None  \n",
       "37                                        good_ml   0.081558        None  \n",
       "38                                     sokal hoax  -0.061723        None  \n",
       "39                   Theory o. general relativity  -0.084621        None  \n",
       "40                                   lorem ipsum   -1.106579        None  \n",
       "41                             wikipedia on LK-99   0.116950        None  \n",
       "42                                 I have a dream  -0.703242        None  \n",
       "43                              AI gen fake paper   0.009151        None  \n",
       "44  Schmidhuber 2023 Subjective Novelty, Surprise  -0.003555        None  \n",
       "45                                 email_to_fauci   0.031637        None  \n",
       "46                                   enron_email1   0.146357        None  \n",
       "47                               openai_board_ann  -0.156891        None  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Llama-2-13B-GPTQ\n",
      "|    | sample                                        |    learning% | in_training   |\n",
      "|---:|:----------------------------------------------|-------------:|:--------------|\n",
      "| 29 | wikipedia on LK-99                            |  0.167259    |               |\n",
      "| 34 | enron_email1                                  |  0.11515     |               |\n",
      "| 33 | email_to_fauci                                |  0.0738711   |               |\n",
      "| 25 | good_ml                                       |  0.0602946   |               |\n",
      "| 31 | AI gen fake paper                             |  0.0191481   |               |\n",
      "| 24 | bad_ml                                        |  0.00543562  |               |\n",
      "| 32 | Schmidhuber 2023 Subjective Novelty, Surprise | -0.000410921 |               |\n",
      "| 27 | Theory o. general relativity                  | -0.0443644   |               |\n",
      "| 35 | openai_board_ann                              | -0.0662883   |               |\n",
      "| 26 | sokal hoax                                    | -0.162956    |               |\n",
      "| 30 | I have a dream                                | -0.479781    |               |\n",
      "| 28 | lorem ipsum                                   | -1.1657      |               |\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>learning%</th>\n",
       "      <th>in_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>wikipedia on LK-99</td>\n",
       "      <td>0.167259</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>enron_email1</td>\n",
       "      <td>0.115150</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>email_to_fauci</td>\n",
       "      <td>0.073871</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>good_ml</td>\n",
       "      <td>0.060295</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>AI gen fake paper</td>\n",
       "      <td>0.019148</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>bad_ml</td>\n",
       "      <td>0.005436</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Schmidhuber 2023 Subjective Novelty, Surprise</td>\n",
       "      <td>-0.000411</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Theory o. general relativity</td>\n",
       "      <td>-0.044364</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>openai_board_ann</td>\n",
       "      <td>-0.066288</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sokal hoax</td>\n",
       "      <td>-0.162956</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>I have a dream</td>\n",
       "      <td>-0.479781</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>lorem ipsum</td>\n",
       "      <td>-1.165705</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sample  learning% in_training\n",
       "29                             wikipedia on LK-99   0.167259        None\n",
       "34                                   enron_email1   0.115150        None\n",
       "33                                 email_to_fauci   0.073871        None\n",
       "25                                        good_ml   0.060295        None\n",
       "31                              AI gen fake paper   0.019148        None\n",
       "24                                         bad_ml   0.005436        None\n",
       "32  Schmidhuber 2023 Subjective Novelty, Surprise  -0.000411        None\n",
       "27                   Theory o. general relativity  -0.044364        None\n",
       "35                               openai_board_ann  -0.066288        None\n",
       "26                                     sokal hoax  -0.162956        None\n",
       "30                                 I have a dream  -0.479781        None\n",
       "28                                   lorem ipsum   -1.165705        None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Llama-2-7B-GPTQ\n",
      "|    | sample                                        |   learning% | in_training   |\n",
      "|---:|:----------------------------------------------|------------:|:--------------|\n",
      "| 17 | wikipedia on LK-99                            |  0.202426   |               |\n",
      "| 22 | enron_email1                                  |  0.190753   |               |\n",
      "| 21 | email_to_fauci                                |  0.0967749  |               |\n",
      "| 13 | good_ml                                       |  0.086104   |               |\n",
      "| 12 | bad_ml                                        |  0.0446809  |               |\n",
      "| 19 | AI gen fake paper                             |  0.0185693  |               |\n",
      "| 15 | Theory o. general relativity                  |  0.0132304  |               |\n",
      "| 20 | Schmidhuber 2023 Subjective Novelty, Surprise |  0.0116207  |               |\n",
      "| 23 | openai_board_ann                              |  0.00617345 |               |\n",
      "| 14 | sokal hoax                                    | -0.0612049  |               |\n",
      "| 18 | I have a dream                                | -0.366212   |               |\n",
      "| 16 | lorem ipsum                                   | -0.943674   |               |\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>learning%</th>\n",
       "      <th>in_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>wikipedia on LK-99</td>\n",
       "      <td>0.202426</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>enron_email1</td>\n",
       "      <td>0.190753</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>email_to_fauci</td>\n",
       "      <td>0.096775</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>good_ml</td>\n",
       "      <td>0.086104</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bad_ml</td>\n",
       "      <td>0.044681</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AI gen fake paper</td>\n",
       "      <td>0.018569</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Theory o. general relativity</td>\n",
       "      <td>0.013230</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Schmidhuber 2023 Subjective Novelty, Surprise</td>\n",
       "      <td>0.011621</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>openai_board_ann</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sokal hoax</td>\n",
       "      <td>-0.061205</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I have a dream</td>\n",
       "      <td>-0.366212</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lorem ipsum</td>\n",
       "      <td>-0.943674</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sample  learning% in_training\n",
       "17                             wikipedia on LK-99   0.202426        None\n",
       "22                                   enron_email1   0.190753        None\n",
       "21                                 email_to_fauci   0.096775        None\n",
       "13                                        good_ml   0.086104        None\n",
       "12                                         bad_ml   0.044681        None\n",
       "19                              AI gen fake paper   0.018569        None\n",
       "15                   Theory o. general relativity   0.013230        None\n",
       "20  Schmidhuber 2023 Subjective Novelty, Surprise   0.011621        None\n",
       "23                               openai_board_ann   0.006173        None\n",
       "14                                     sokal hoax  -0.061205        None\n",
       "18                                 I have a dream  -0.366212        None\n",
       "16                                   lorem ipsum   -0.943674        None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Mistral-7B-v0.1-GPTQ\n",
      "|    | sample                                        |   learning% | in_training   |\n",
      "|---:|:----------------------------------------------|------------:|:--------------|\n",
      "| 46 | enron_email1                                  |  0.146357   |               |\n",
      "| 41 | wikipedia on LK-99                            |  0.11695    |               |\n",
      "| 37 | good_ml                                       |  0.0815578  |               |\n",
      "| 45 | email_to_fauci                                |  0.0316373  |               |\n",
      "| 43 | AI gen fake paper                             |  0.00915127 |               |\n",
      "| 44 | Schmidhuber 2023 Subjective Novelty, Surprise | -0.00355543 |               |\n",
      "| 36 | bad_ml                                        | -0.00760339 |               |\n",
      "| 38 | sokal hoax                                    | -0.0617226  |               |\n",
      "| 39 | Theory o. general relativity                  | -0.0846206  |               |\n",
      "| 47 | openai_board_ann                              | -0.156891   |               |\n",
      "| 42 | I have a dream                                | -0.703242   |               |\n",
      "| 40 | lorem ipsum                                   | -1.10658    |               |\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>learning%</th>\n",
       "      <th>in_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>enron_email1</td>\n",
       "      <td>0.146357</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>wikipedia on LK-99</td>\n",
       "      <td>0.116950</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>good_ml</td>\n",
       "      <td>0.081558</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>email_to_fauci</td>\n",
       "      <td>0.031637</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>AI gen fake paper</td>\n",
       "      <td>0.009151</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Schmidhuber 2023 Subjective Novelty, Surprise</td>\n",
       "      <td>-0.003555</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>bad_ml</td>\n",
       "      <td>-0.007603</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>sokal hoax</td>\n",
       "      <td>-0.061723</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Theory o. general relativity</td>\n",
       "      <td>-0.084621</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>openai_board_ann</td>\n",
       "      <td>-0.156891</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>I have a dream</td>\n",
       "      <td>-0.703242</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>lorem ipsum</td>\n",
       "      <td>-1.106579</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sample  learning% in_training\n",
       "46                                   enron_email1   0.146357        None\n",
       "41                             wikipedia on LK-99   0.116950        None\n",
       "37                                        good_ml   0.081558        None\n",
       "45                                 email_to_fauci   0.031637        None\n",
       "43                              AI gen fake paper   0.009151        None\n",
       "44  Schmidhuber 2023 Subjective Novelty, Surprise  -0.003555        None\n",
       "36                                         bad_ml  -0.007603        None\n",
       "38                                     sokal hoax  -0.061723        None\n",
       "39                   Theory o. general relativity  -0.084621        None\n",
       "47                               openai_board_ann  -0.156891        None\n",
       "42                                 I have a dream  -0.703242        None\n",
       "40                                   lorem ipsum   -1.106579        None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/phi-2-GPTQ\n",
      "|    | sample                                        |   learning% | in_training   |\n",
      "|---:|:----------------------------------------------|------------:|:--------------|\n",
      "|  5 | wikipedia on LK-99                            |  0.185122   |               |\n",
      "| 10 | enron_email1                                  |  0.138411   |               |\n",
      "|  9 | email_to_fauci                                |  0.115038   |               |\n",
      "|  1 | good_ml                                       |  0.112449   |               |\n",
      "|  0 | bad_ml                                        |  0.0810974  |               |\n",
      "|  3 | Theory o. general relativity                  |  0.0420969  |               |\n",
      "|  8 | Schmidhuber 2023 Subjective Novelty, Surprise |  0.0337732  |               |\n",
      "|  2 | sokal hoax                                    |  0.00485648 |               |\n",
      "|  7 | AI gen fake paper                             | -0.056993   |               |\n",
      "| 11 | openai_board_ann                              | -0.0594976  |               |\n",
      "|  6 | I have a dream                                | -0.500631   |               |\n",
      "|  4 | lorem ipsum                                   | -1.02213    |               |\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>learning%</th>\n",
       "      <th>in_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wikipedia on LK-99</td>\n",
       "      <td>0.185122</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>enron_email1</td>\n",
       "      <td>0.138411</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>email_to_fauci</td>\n",
       "      <td>0.115038</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good_ml</td>\n",
       "      <td>0.112449</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bad_ml</td>\n",
       "      <td>0.081097</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Theory o. general relativity</td>\n",
       "      <td>0.042097</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Schmidhuber 2023 Subjective Novelty, Surprise</td>\n",
       "      <td>0.033773</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sokal hoax</td>\n",
       "      <td>0.004856</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AI gen fake paper</td>\n",
       "      <td>-0.056993</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>openai_board_ann</td>\n",
       "      <td>-0.059498</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I have a dream</td>\n",
       "      <td>-0.500631</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lorem ipsum</td>\n",
       "      <td>-1.022131</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sample  learning% in_training\n",
       "5                              wikipedia on LK-99   0.185122        None\n",
       "10                                   enron_email1   0.138411        None\n",
       "9                                  email_to_fauci   0.115038        None\n",
       "1                                         good_ml   0.112449        None\n",
       "0                                          bad_ml   0.081097        None\n",
       "3                    Theory o. general relativity   0.042097        None\n",
       "8   Schmidhuber 2023 Subjective Novelty, Surprise   0.033773        None\n",
       "2                                      sokal hoax   0.004856        None\n",
       "7                               AI gen fake paper  -0.056993        None\n",
       "11                               openai_board_ann  -0.059498        None\n",
       "6                                  I have a dream  -0.500631        None\n",
       "4                                    lorem ipsum   -1.022131        None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for n,d in df.groupby(\"model\"):\n",
    "    print(n)\n",
    "    d = d[['sample', 'learning%', 'in_training']].sort_values(\"learning%\", ascending=False)\n",
    "    print(d.to_markdown())\n",
    "    display(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Llama-2-13B-GPTQ\n",
      "|    | sample                                        |   learning% | in_training   |\n",
      "|---:|:----------------------------------------------|------------:|:--------------|\n",
      "| 29 | wikipedia on LK-99                            |  1.94887    |               |\n",
      "| 34 | enron_email1                                  |  1.43055    |               |\n",
      "| 25 | good_ml                                       |  0.753304   |               |\n",
      "| 33 | email_to_fauci                                |  0.726738   |               |\n",
      "| 31 | AI gen fake paper                             |  0.106177   |               |\n",
      "| 24 | bad_ml                                        |  0.041275   |               |\n",
      "| 32 | Schmidhuber 2023 Subjective Novelty, Surprise | -0.00523758 |               |\n",
      "| 35 | openai_board_ann                              | -0.355879   |               |\n",
      "| 27 | Theory o. general relativity                  | -0.526403   |               |\n",
      "| 26 | sokal hoax                                    | -0.593387   |               |\n",
      "| 30 | I have a dream                                | -0.93573    |               |\n",
      "| 28 | lorem ipsum                                   | -1.30963    |               |\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>learning%</th>\n",
       "      <th>in_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>wikipedia on LK-99</td>\n",
       "      <td>1.948873</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>enron_email1</td>\n",
       "      <td>1.430546</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>good_ml</td>\n",
       "      <td>0.753304</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>email_to_fauci</td>\n",
       "      <td>0.726738</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>AI gen fake paper</td>\n",
       "      <td>0.106177</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>bad_ml</td>\n",
       "      <td>0.041275</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Schmidhuber 2023 Subjective Novelty, Surprise</td>\n",
       "      <td>-0.005238</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>openai_board_ann</td>\n",
       "      <td>-0.355879</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Theory o. general relativity</td>\n",
       "      <td>-0.526403</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sokal hoax</td>\n",
       "      <td>-0.593387</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>I have a dream</td>\n",
       "      <td>-0.935730</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>lorem ipsum</td>\n",
       "      <td>-1.309628</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sample  learning% in_training\n",
       "29                             wikipedia on LK-99   1.948873        None\n",
       "34                                   enron_email1   1.430546        None\n",
       "25                                        good_ml   0.753304        None\n",
       "33                                 email_to_fauci   0.726738        None\n",
       "31                              AI gen fake paper   0.106177        None\n",
       "24                                         bad_ml   0.041275        None\n",
       "32  Schmidhuber 2023 Subjective Novelty, Surprise  -0.005238        None\n",
       "35                               openai_board_ann  -0.355879        None\n",
       "27                   Theory o. general relativity  -0.526403        None\n",
       "26                                     sokal hoax  -0.593387        None\n",
       "30                                 I have a dream  -0.935730        None\n",
       "28                                   lorem ipsum   -1.309628        None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Llama-2-7B-GPTQ\n",
      "|    | sample                                        |   learning% | in_training   |\n",
      "|---:|:----------------------------------------------|------------:|:--------------|\n",
      "| 22 | enron_email1                                  |   2.6292    |               |\n",
      "| 17 | wikipedia on LK-99                            |   2.49834   |               |\n",
      "| 13 | good_ml                                       |   1.24296   |               |\n",
      "| 21 | email_to_fauci                                |   1.09521   |               |\n",
      "| 12 | bad_ml                                        |   0.357408  |               |\n",
      "| 15 | Theory o. general relativity                  |   0.182519  |               |\n",
      "| 20 | Schmidhuber 2023 Subjective Novelty, Surprise |   0.158172  |               |\n",
      "| 19 | AI gen fake paper                             |   0.114477  |               |\n",
      "| 23 | openai_board_ann                              |   0.0365281 |               |\n",
      "| 14 | sokal hoax                                    |  -0.454623  |               |\n",
      "| 18 | I have a dream                                |  -0.830678  |               |\n",
      "| 16 | lorem ipsum                                   |  -1.17344   |               |\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>learning%</th>\n",
       "      <th>in_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>enron_email1</td>\n",
       "      <td>2.629203</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>wikipedia on LK-99</td>\n",
       "      <td>2.498336</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>good_ml</td>\n",
       "      <td>1.242956</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>email_to_fauci</td>\n",
       "      <td>1.095209</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bad_ml</td>\n",
       "      <td>0.357408</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Theory o. general relativity</td>\n",
       "      <td>0.182519</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Schmidhuber 2023 Subjective Novelty, Surprise</td>\n",
       "      <td>0.158172</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AI gen fake paper</td>\n",
       "      <td>0.114477</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>openai_board_ann</td>\n",
       "      <td>0.036528</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sokal hoax</td>\n",
       "      <td>-0.454623</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I have a dream</td>\n",
       "      <td>-0.830678</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lorem ipsum</td>\n",
       "      <td>-1.173437</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sample  learning% in_training\n",
       "22                                   enron_email1   2.629203        None\n",
       "17                             wikipedia on LK-99   2.498336        None\n",
       "13                                        good_ml   1.242956        None\n",
       "21                                 email_to_fauci   1.095209        None\n",
       "12                                         bad_ml   0.357408        None\n",
       "15                   Theory o. general relativity   0.182519        None\n",
       "20  Schmidhuber 2023 Subjective Novelty, Surprise   0.158172        None\n",
       "19                              AI gen fake paper   0.114477        None\n",
       "23                               openai_board_ann   0.036528        None\n",
       "14                                     sokal hoax  -0.454623        None\n",
       "18                                 I have a dream  -0.830678        None\n",
       "16                                   lorem ipsum   -1.173437        None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/Mistral-7B-v0.1-GPTQ\n",
      "|    | sample                                        |   learning% | in_training   |\n",
      "|---:|:----------------------------------------------|------------:|:--------------|\n",
      "| 46 | enron_email1                                  |   1.90176   |               |\n",
      "| 41 | wikipedia on LK-99                            |   1.34696   |               |\n",
      "| 37 | good_ml                                       |   1.24542   |               |\n",
      "| 45 | email_to_fauci                                |   0.344687  |               |\n",
      "| 43 | AI gen fake paper                             |   0.0518088 |               |\n",
      "| 44 | Schmidhuber 2023 Subjective Novelty, Surprise |  -0.0493546 |               |\n",
      "| 36 | bad_ml                                        |  -0.0642319 |               |\n",
      "| 38 | sokal hoax                                    |  -0.346581  |               |\n",
      "| 47 | openai_board_ann                              |  -0.866275  |               |\n",
      "| 39 | Theory o. general relativity                  |  -1.01913   |               |\n",
      "| 40 | lorem ipsum                                   |  -1.25013   |               |\n",
      "| 42 | I have a dream                                |  -1.31268   |               |\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>learning%</th>\n",
       "      <th>in_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>enron_email1</td>\n",
       "      <td>1.901759</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>wikipedia on LK-99</td>\n",
       "      <td>1.346963</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>good_ml</td>\n",
       "      <td>1.245416</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>email_to_fauci</td>\n",
       "      <td>0.344687</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>AI gen fake paper</td>\n",
       "      <td>0.051809</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Schmidhuber 2023 Subjective Novelty, Surprise</td>\n",
       "      <td>-0.049355</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>bad_ml</td>\n",
       "      <td>-0.064232</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>sokal hoax</td>\n",
       "      <td>-0.346581</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>openai_board_ann</td>\n",
       "      <td>-0.866275</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Theory o. general relativity</td>\n",
       "      <td>-1.019134</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>lorem ipsum</td>\n",
       "      <td>-1.250132</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>I have a dream</td>\n",
       "      <td>-1.312678</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sample  learning% in_training\n",
       "46                                   enron_email1   1.901759        None\n",
       "41                             wikipedia on LK-99   1.346963        None\n",
       "37                                        good_ml   1.245416        None\n",
       "45                                 email_to_fauci   0.344687        None\n",
       "43                              AI gen fake paper   0.051809        None\n",
       "44  Schmidhuber 2023 Subjective Novelty, Surprise  -0.049355        None\n",
       "36                                         bad_ml  -0.064232        None\n",
       "38                                     sokal hoax  -0.346581        None\n",
       "47                               openai_board_ann  -0.866275        None\n",
       "39                   Theory o. general relativity  -1.019134        None\n",
       "40                                   lorem ipsum   -1.250132        None\n",
       "42                                 I have a dream  -1.312678        None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheBloke/phi-2-GPTQ\n",
      "|    | sample                                        |   learning% | in_training   |\n",
      "|---:|:----------------------------------------------|------------:|:--------------|\n",
      "|  5 | wikipedia on LK-99                            |   3.34188   |               |\n",
      "| 10 | enron_email1                                  |   3.16623   |               |\n",
      "|  1 | good_ml                                       |   2.54853   |               |\n",
      "|  9 | email_to_fauci                                |   2.42273   |               |\n",
      "|  0 | bad_ml                                        |   1.01021   |               |\n",
      "|  8 | Schmidhuber 2023 Subjective Novelty, Surprise |   0.956118  |               |\n",
      "|  3 | Theory o. general relativity                  |   0.863308  |               |\n",
      "|  2 | sokal hoax                                    |   0.0693769 |               |\n",
      "|  7 | AI gen fake paper                             |  -0.404154  |               |\n",
      "| 11 | openai_board_ann                              |  -0.508879  |               |\n",
      "|  4 | lorem ipsum                                   |  -1.18999   |               |\n",
      "|  6 | I have a dream                                |  -1.4199    |               |\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>learning%</th>\n",
       "      <th>in_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wikipedia on LK-99</td>\n",
       "      <td>3.341876</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>enron_email1</td>\n",
       "      <td>3.166235</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good_ml</td>\n",
       "      <td>2.548532</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>email_to_fauci</td>\n",
       "      <td>2.422728</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bad_ml</td>\n",
       "      <td>1.010206</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Schmidhuber 2023 Subjective Novelty, Surprise</td>\n",
       "      <td>0.956118</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Theory o. general relativity</td>\n",
       "      <td>0.863308</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sokal hoax</td>\n",
       "      <td>0.069377</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AI gen fake paper</td>\n",
       "      <td>-0.404154</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>openai_board_ann</td>\n",
       "      <td>-0.508879</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lorem ipsum</td>\n",
       "      <td>-1.189991</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I have a dream</td>\n",
       "      <td>-1.419905</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sample  learning% in_training\n",
       "5                              wikipedia on LK-99   3.341876        None\n",
       "10                                   enron_email1   3.166235        None\n",
       "1                                         good_ml   2.548532        None\n",
       "9                                  email_to_fauci   2.422728        None\n",
       "0                                          bad_ml   1.010206        None\n",
       "8   Schmidhuber 2023 Subjective Novelty, Surprise   0.956118        None\n",
       "3                    Theory o. general relativity   0.863308        None\n",
       "2                                      sokal hoax   0.069377        None\n",
       "7                               AI gen fake paper  -0.404154        None\n",
       "11                               openai_board_ann  -0.508879        None\n",
       "4                                    lorem ipsum   -1.189991        None\n",
       "6                                  I have a dream  -1.419905        None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"learning%\"] = (df[\"before\"] - df[\"after\"])\n",
    "for n,d in df.groupby(\"model\"):\n",
    "    print(n)\n",
    "    d = d[['sample', 'learning%', 'in_training']].sort_values(\"learning%\", ascending=False)\n",
    "    print(d.to_markdown())\n",
    "    display(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: compare big and small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "big numbers mean a difference between big and small models\n",
      "| sample                                        |   before |      after |   learning% |\n",
      "|:----------------------------------------------|---------:|-----------:|------------:|\n",
      "| sokal hoax                                    | 3.7865   |  3.64774   |   0.138764  |\n",
      "| good_ml                                       | 1.94178  |  1.45213   |   0.489652  |\n",
      "| Theory o. general relativity                  | 1.92992  |  1.221     |   0.708922  |\n",
      "| email_to_fauci                                | 1.47915  |  1.11068   |   0.368471  |\n",
      "| Schmidhuber 2023 Subjective Novelty, Surprise | 0.865227 |  0.701818  |   0.163409  |\n",
      "| AI gen fake paper                             | 0.619803 |  0.611503  |   0.0083003 |\n",
      "| I have a dream                                | 0.317971 |  0.212919  |   0.105052  |\n",
      "| enron_email1                                  | 1.35998  |  0.161322  |   1.19866   |\n",
      "| openai_board_ann                              | 0.548308 |  0.1559    |   0.392407  |\n",
      "| wikipedia on LK-99                            | 0.690145 |  0.140681  |   0.549463  |\n",
      "| bad_ml                                        | 0.405684 |  0.0895505 |   0.316133  |\n",
      "| lorem ipsum                                   | 0.120013 | -0.0161781 |   0.136191  |\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>learning%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sokal hoax</th>\n",
       "      <td>3.786502</td>\n",
       "      <td>3.647738</td>\n",
       "      <td>0.138764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good_ml</th>\n",
       "      <td>1.941784</td>\n",
       "      <td>1.452132</td>\n",
       "      <td>0.489652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Theory o. general relativity</th>\n",
       "      <td>1.929925</td>\n",
       "      <td>1.221003</td>\n",
       "      <td>0.708922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>email_to_fauci</th>\n",
       "      <td>1.479151</td>\n",
       "      <td>1.110680</td>\n",
       "      <td>0.368471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Schmidhuber 2023 Subjective Novelty, Surprise</th>\n",
       "      <td>0.865227</td>\n",
       "      <td>0.701818</td>\n",
       "      <td>0.163409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AI gen fake paper</th>\n",
       "      <td>0.619803</td>\n",
       "      <td>0.611503</td>\n",
       "      <td>0.008300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I have a dream</th>\n",
       "      <td>0.317971</td>\n",
       "      <td>0.212919</td>\n",
       "      <td>0.105052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enron_email1</th>\n",
       "      <td>1.359979</td>\n",
       "      <td>0.161322</td>\n",
       "      <td>1.198657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai_board_ann</th>\n",
       "      <td>0.548308</td>\n",
       "      <td>0.155900</td>\n",
       "      <td>0.392407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wikipedia on LK-99</th>\n",
       "      <td>0.690145</td>\n",
       "      <td>0.140681</td>\n",
       "      <td>0.549463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad_ml</th>\n",
       "      <td>0.405684</td>\n",
       "      <td>0.089550</td>\n",
       "      <td>0.316133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lorem ipsum</th>\n",
       "      <td>0.120013</td>\n",
       "      <td>-0.016178</td>\n",
       "      <td>0.136191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 before     after  learning%\n",
       "sample                                                                      \n",
       "sokal hoax                                     3.786502  3.647738   0.138764\n",
       "good_ml                                        1.941784  1.452132   0.489652\n",
       "Theory o. general relativity                   1.929925  1.221003   0.708922\n",
       "email_to_fauci                                 1.479151  1.110680   0.368471\n",
       "Schmidhuber 2023 Subjective Novelty, Surprise  0.865227  0.701818   0.163409\n",
       "AI gen fake paper                              0.619803  0.611503   0.008300\n",
       "I have a dream                                 0.317971  0.212919   0.105052\n",
       "enron_email1                                   1.359979  0.161322   1.198657\n",
       "openai_board_ann                               0.548308  0.155900   0.392407\n",
       "wikipedia on LK-99                             0.690145  0.140681   0.549463\n",
       "bad_ml                                         0.405684  0.089550   0.316133\n",
       "lorem ipsum                                    0.120013 -0.016178   0.136191"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = df[df.model==\"TheBloke/Llama-2-7B-GPTQ\"].set_index('sample').drop(columns=['model', 'in_training'])\n",
    "b = df[df.model==\"TheBloke/Llama-2-13B-GPTQ\"].set_index('sample').drop(columns=['model', 'in_training'])\n",
    "d = (a-b).sort_values(\"after\", ascending=False)\n",
    "print('big numbers (for after and learning) mean the smaller model was more confused')\n",
    "print(d.to_markdown())\n",
    "d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
