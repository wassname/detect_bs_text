{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/huggingface/peft/blob/main/examples/fp4_finetuning/finetune_fp4_opt_bnb_peft.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import lightning as pl\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoConfig\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from peft import LoraConfig, get_peft_model, IA3Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"TheBloke/phi-2-GPTQ\"\n",
    "model_name = \"microsoft/phi-2\"\n",
    "\n",
    "def load_model():\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        # quantization_config=BitsAndBytesConfig(\n",
    "        #     load_in_4bit=True,\n",
    "        #     llm_int8_threshold=6.0,\n",
    "        #     llm_int8_has_fp16_weight=False,\n",
    "        #     bnb_4bit_compute_dtype=torch.float16,\n",
    "        #     bnb_4bit_use_double_quant=True,\n",
    "        #     bnb_4bit_quant_type=\"nf4\",\n",
    "        # ),\n",
    "        torch_dtype=torch.float16,\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "\n",
    "\n",
    "    # config = AutoConfig.from_pretrained(model_name, trust_remote_code=True,)\n",
    "    # config.quantization_config['use_exllama'] = False\n",
    "    # config.quantization_config['disable_exllama'] = True\n",
    "    # model = AutoModelForCausalLM.from_pretrained(\n",
    "    #     model_name,\n",
    "    #     torch_dtype=torch.bfloat16,\n",
    "    #     trust_remote_code=True,\n",
    "    #     config=config,\n",
    "    # )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.73it/s]\n"
     ]
    }
   ],
   "source": [
    "base_model = load_model()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True,)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_model(base_model):\n",
    "    # peft_config = LoraConfig(\n",
    "    #     # task_type=TaskType.TOKEN_CLS, \n",
    "    #     target_modules=[ \"fc2\",  \"Wqkv\",],\n",
    "    #     inference_mode=False, r=4, lora_alpha=4, \n",
    "    #     # lora_dropout=0.1, \n",
    "    #     # bias=\"all\"\n",
    "    # )\n",
    "    peft_config = IA3Config(\n",
    "        target_modules=[ \"fc2\",  \"Wqkv\",], \n",
    "            feedforward_modules=[\"fc2\"],\n",
    "            inference_mode=False,\n",
    "    )\n",
    "    model = get_peft_model(base_model, peft_config)\n",
    "    model.config.use_cache = False\n",
    "    return model\n",
    "\n",
    "model = reset_model(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('../samples/bletchley_decleration.md'), PosixPath('../samples/cicero_fin1.md'), PosixPath('../samples/disney_appointment.md'), PosixPath('../samples/fake_paper.md'), PosixPath('../samples/fauci_emails.md'), PosixPath('../samples/harvard_announcement_reminders.md'), PosixPath('../samples/how_to_catch_a_liar.md'), PosixPath('../samples/lk-99_end.md'), PosixPath('../samples/lk-99_espanol.md'), PosixPath('../samples/lorem_ipsum.md'), PosixPath('../samples/openai_board_ann.md'), PosixPath('../samples/openai_paper_weak_to_strong.md'), PosixPath('../samples/politics_is_the_mind_killer.md'), PosixPath('../samples/statement_vyKamala_on_passing_of_johnson.md'), PosixPath('../samples/survey_of_rumours.md')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['f', 'title', 'url', 'content'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "MAX_LEN = 400\n",
    "\n",
    "import frontmatter\n",
    "from pathlib import Path\n",
    "sample_files = sorted(Path(\"../samples/\").glob('*.md'))\n",
    "print(sample_files)\n",
    "samples = [{'f':f, **frontmatter.load(f).to_dict()} for f in sample_files]\n",
    "\n",
    "for sample in samples:\n",
    "    assert 'title' in sample, sample['f']\n",
    "    assert 'content' in sample\n",
    "samples[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from https://github.dev/huggingface/evaluate/blob/8dfe05784099fb9af55b8e77793205a3b7c86465/measurements/perplexity/perplexity.py#L154\n",
    "import evaluate\n",
    "from evaluate import logging\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "\n",
    "def perplexity_compute(\n",
    "    data, model, tokenizer, batch_size: int = 16, add_start_token: bool = True, device=None, max_length=None\n",
    "):\n",
    "    model = model.to(device)\n",
    "\n",
    "\n",
    "    max_tokenized_len = max_length\n",
    "\n",
    "    encodings = tokenizer(\n",
    "        data,\n",
    "        add_special_tokens=False,\n",
    "        padding=True,\n",
    "        truncation=True if max_tokenized_len else False,\n",
    "        max_length=max_tokenized_len,\n",
    "        return_tensors=\"pt\",\n",
    "        return_attention_mask=True,\n",
    "    ).to(device)\n",
    "\n",
    "    encoded_texts = encodings[\"input_ids\"]\n",
    "    attn_masks = encodings[\"attention_mask\"]\n",
    "\n",
    "    # check that each input is long enough:\n",
    "    if add_start_token:\n",
    "        assert torch.all(torch.ge(attn_masks.sum(1), 1)), \"Each input text must be at least one token long.\"\n",
    "    else:\n",
    "        assert torch.all(\n",
    "            torch.ge(attn_masks.sum(1), 2)\n",
    "        ), \"When add_start_token=False, each input text must be at least two tokens long. Run with add_start_token=True if inputting strings of only one token, and remove all empty input strings.\"\n",
    "\n",
    "    ppls = []\n",
    "    loss_fct = CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "    for start_index in logging.tqdm(range(0, len(encoded_texts), batch_size)):\n",
    "        end_index = min(start_index + batch_size, len(encoded_texts))\n",
    "        encoded_batch = encoded_texts[start_index:end_index]\n",
    "        attn_mask = attn_masks[start_index:end_index]\n",
    "\n",
    "        labels = encoded_batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out_logits = model(encoded_batch, attention_mask=attn_mask).logits\n",
    "\n",
    "        shift_logits = out_logits[..., :-1, :].contiguous()\n",
    "        shift_labels = labels[..., 1:].contiguous()\n",
    "        shift_attention_mask_batch = attn_mask[..., 1:].contiguous()\n",
    "\n",
    "        perplexity_batch = torch.exp(\n",
    "            (loss_fct(shift_logits.transpose(1, 2), shift_labels) * shift_attention_mask_batch).sum(1)\n",
    "            / shift_attention_mask_batch.sum(1)\n",
    "        )\n",
    "\n",
    "        ppls += perplexity_batch.tolist()\n",
    "\n",
    "    return {\"perplexities\": ppls, \"mean_perplexity\": torch.tensor(ppls).mean()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lightning helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, tokenizer, second_half):\n",
    "    model.eval();\n",
    "    with torch.no_grad():\n",
    "        with model.disable_adapter():\n",
    "            results = perplexity_compute(data=second_half, model=model, tokenizer=tokenizer, device='cuda')\n",
    "        results2 = perplexity_compute(data=second_half, model=model, tokenizer=tokenizer, device='cuda')\n",
    "    return dict(before=results['mean_perplexity'].item(), after=results2['mean_perplexity'].item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "def compute_metrics(eval_prediction):\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainer docs\n",
    "\n",
    "- https://huggingface.co/docs/transformers/v4.36.1/en/main_classes/trainer#transformers.Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tokenize_and_split(examples):\n",
    "    result = tokenizer(\n",
    "        examples,\n",
    "        truncation=True,\n",
    "        max_length=MAX_LEN,\n",
    "        return_overflowing_tokens=True,\n",
    "    )\n",
    "    return result\n",
    "\n",
    "# s = sample['content']\n",
    "# first_half = s[:len(s)//2]\n",
    "# second_half = s[len(s)//2:]\n",
    "# ds_train = Dataset.from_dict(tokenize_and_split([first_half]))\n",
    "# ds_val = Dataset.from_dict(tokenize_and_split([second_half]))\n",
    "# ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_sample(sample):\n",
    "    # device = 'cuda'\n",
    "    # lr = 4e-3\n",
    "    # epochs = 3\n",
    "    # accum_steps = 1\n",
    "    batch_size = 1\n",
    "    verbose = False\n",
    "\n",
    "    s = sample['content']\n",
    "    first_half = s[:len(s)//2]\n",
    "    second_half = s[len(s)//2:]\n",
    "\n",
    "    # TODO, I guess we need to window this\n",
    "    ds_train = Dataset.from_dict(tokenize_and_split([first_half]))\n",
    "    ds_val = Dataset.from_dict(tokenize_and_split([second_half]))\n",
    "\n",
    "    os.environ['CUDA_VISIBLE_DEVICES']=\"1\"\n",
    "    model = reset_model(base_model)\n",
    "    eval(model, tokenizer, second_half)\n",
    "\n",
    "    # https://huggingface.co/docs/transformers/v4.36.1/en/main_classes/trainer#transformers.Trainer\n",
    "    trainer = transformers.Trainer(\n",
    "        model=model,\n",
    "        train_dataset=ds_train,\n",
    "        eval_dataset=ds_val,\n",
    "        compute_metrics=compute_metrics, # without this it wont even give val loss\n",
    "        args=transformers.TrainingArguments(\n",
    "            # checkpoint='epoch',\n",
    "            save_strategy='epoch',\n",
    "            label_names=['labels',],\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            gradient_accumulation_steps=3,\n",
    "            warmup_steps=6,\n",
    "            max_steps=20,\n",
    "            learning_rate=3e-3,\n",
    "            fp16=True,\n",
    "            logging_steps=1,\n",
    "            output_dir=\"outputs\",\n",
    "            log_level='error',\n",
    "            # do_eval=True,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            eval_steps=1,\n",
    "            load_best_model_at_end=True,\n",
    "            \n",
    "            # disable_tqdm=not verbose,\n",
    "        ),\n",
    "        data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    "    )\n",
    "    trainer._signature_columns = ['input_ids', 'attention_mask', 'labels',]\n",
    "    model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "    train_output = trainer.train()\n",
    "\n",
    "    df_hist = pd.DataFrame(trainer.state.log_history)\n",
    "    df_hist_epoch = df_hist.groupby('epoch').last().drop(columns=['step'])\n",
    "    df_hist_step = df_hist.set_index('step').dropna(thresh=2, axis=1)\n",
    "    if verbose:\n",
    "        df_hist_epoch['loss'].plot()\n",
    "        plt.twinx()\n",
    "        df_hist_epoch['eval_loss'].plot(c='b', label='eval')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    result_train = {f'train/{k}':v for k,v in eval(model, tokenizer, first_half).items()}\n",
    "    result = eval(model, tokenizer, second_half)\n",
    "    result['hist'] = df_hist_epoch\n",
    "    result.update(result_train)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.68it/s]\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8731, 'learning_rate': 0.0005, 'epoch': 1.0}\n",
      "{'eval_loss': 2.934140205383301, 'eval_runtime': 1.8507, 'eval_samples_per_second': 1.081, 'eval_steps_per_second': 0.54, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8722, 'learning_rate': 0.001, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.930333375930786, 'eval_runtime': 1.8509, 'eval_samples_per_second': 1.081, 'eval_steps_per_second': 0.54, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8639, 'learning_rate': 0.0015, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.9261159896850586, 'eval_runtime': 1.852, 'eval_samples_per_second': 1.08, 'eval_steps_per_second': 0.54, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8556, 'learning_rate': 0.002, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.921092987060547, 'eval_runtime': 1.8512, 'eval_samples_per_second': 1.08, 'eval_steps_per_second': 0.54, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.84, 'learning_rate': 0.0025, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.9118905067443848, 'eval_runtime': 1.8512, 'eval_samples_per_second': 1.08, 'eval_steps_per_second': 0.54, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8213, 'learning_rate': 0.003, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.9033427238464355, 'eval_runtime': 1.8515, 'eval_samples_per_second': 1.08, 'eval_steps_per_second': 0.54, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7984, 'learning_rate': 0.002785714285714286, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8970065116882324, 'eval_runtime': 1.8538, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.539, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7788, 'learning_rate': 0.0025714285714285713, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8897409439086914, 'eval_runtime': 1.8523, 'eval_samples_per_second': 1.08, 'eval_steps_per_second': 0.54, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.752, 'learning_rate': 0.002357142857142857, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.888181209564209, 'eval_runtime': 1.8519, 'eval_samples_per_second': 1.08, 'eval_steps_per_second': 0.54, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7382, 'learning_rate': 0.002142857142857143, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.890364408493042, 'eval_runtime': 1.8521, 'eval_samples_per_second': 1.08, 'eval_steps_per_second': 0.54, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7212, 'learning_rate': 0.0019285714285714288, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8928794860839844, 'eval_runtime': 1.8515, 'eval_samples_per_second': 1.08, 'eval_steps_per_second': 0.54, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7034, 'learning_rate': 0.0017142857142857142, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8941824436187744, 'eval_runtime': 1.8532, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.54, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.692, 'learning_rate': 0.0015, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.896975517272949, 'eval_runtime': 1.8526, 'eval_samples_per_second': 1.08, 'eval_steps_per_second': 0.54, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6729, 'learning_rate': 0.0012857142857142856, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.899407386779785, 'eval_runtime': 1.8615, 'eval_samples_per_second': 1.074, 'eval_steps_per_second': 0.537, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6678, 'learning_rate': 0.0010714285714285715, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.898254871368408, 'eval_runtime': 1.8542, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.539, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6561, 'learning_rate': 0.0008571428571428571, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.899857521057129, 'eval_runtime': 1.8522, 'eval_samples_per_second': 1.08, 'eval_steps_per_second': 0.54, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6448, 'learning_rate': 0.0006428571428571428, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.9020445346832275, 'eval_runtime': 1.8524, 'eval_samples_per_second': 1.08, 'eval_steps_per_second': 0.54, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6436, 'learning_rate': 0.00042857142857142855, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.9011523723602295, 'eval_runtime': 1.8527, 'eval_samples_per_second': 1.08, 'eval_steps_per_second': 0.54, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6423, 'learning_rate': 0.00021428571428571427, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.9012508392333984, 'eval_runtime': 1.8541, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.539, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6364, 'learning_rate': 0.0, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.901865005493164, 'eval_runtime': 1.853, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.54, 'epoch': 20.0}\n",
      "{'train_runtime': 110.4196, 'train_samples_per_second': 1.087, 'train_steps_per_second': 0.181, 'train_loss': 0.7436936140060425, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blechley declaration\n",
      "{'before': 15.099042892456055, 'after': 14.732343673706055}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.5636, 'learning_rate': 0.0005, 'epoch': 1.0}\n",
      "{'eval_loss': 4.2795186042785645, 'eval_runtime': 2.1952, 'eval_samples_per_second': 2.733, 'eval_steps_per_second': 0.456, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.5644, 'learning_rate': 0.001, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.2700276374816895, 'eval_runtime': 2.2003, 'eval_samples_per_second': 2.727, 'eval_steps_per_second': 0.454, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.57, 'learning_rate': 0.0015, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.258336544036865, 'eval_runtime': 2.1983, 'eval_samples_per_second': 2.729, 'eval_steps_per_second': 0.455, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.5474, 'learning_rate': 0.002, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.244501113891602, 'eval_runtime': 2.1998, 'eval_samples_per_second': 2.728, 'eval_steps_per_second': 0.455, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.4968, 'learning_rate': 0.0025, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.230161666870117, 'eval_runtime': 2.1985, 'eval_samples_per_second': 2.729, 'eval_steps_per_second': 0.455, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.4635, 'learning_rate': 0.003, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.221675395965576, 'eval_runtime': 2.198, 'eval_samples_per_second': 2.73, 'eval_steps_per_second': 0.455, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.4153, 'learning_rate': 0.002785714285714286, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.215108871459961, 'eval_runtime': 2.1948, 'eval_samples_per_second': 2.734, 'eval_steps_per_second': 0.456, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.36, 'learning_rate': 0.0025714285714285713, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.209522247314453, 'eval_runtime': 2.1924, 'eval_samples_per_second': 2.737, 'eval_steps_per_second': 0.456, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.3225, 'learning_rate': 0.002357142857142857, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.2080464363098145, 'eval_runtime': 2.192, 'eval_samples_per_second': 2.737, 'eval_steps_per_second': 0.456, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.2847, 'learning_rate': 0.002142857142857143, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.206252574920654, 'eval_runtime': 2.1916, 'eval_samples_per_second': 2.738, 'eval_steps_per_second': 0.456, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.2253, 'learning_rate': 0.0019285714285714288, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.205601215362549, 'eval_runtime': 2.1978, 'eval_samples_per_second': 2.73, 'eval_steps_per_second': 0.455, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.2147, 'learning_rate': 0.0017142857142857142, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.205047130584717, 'eval_runtime': 2.1965, 'eval_samples_per_second': 2.732, 'eval_steps_per_second': 0.455, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.1814, 'learning_rate': 0.0015, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.206936359405518, 'eval_runtime': 2.1952, 'eval_samples_per_second': 2.733, 'eval_steps_per_second': 0.456, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.1625, 'learning_rate': 0.0012857142857142856, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.206596851348877, 'eval_runtime': 2.1968, 'eval_samples_per_second': 2.731, 'eval_steps_per_second': 0.455, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.1308, 'learning_rate': 0.0010714285714285715, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.205368518829346, 'eval_runtime': 2.1979, 'eval_samples_per_second': 2.73, 'eval_steps_per_second': 0.455, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.1072, 'learning_rate': 0.0008571428571428571, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.205146789550781, 'eval_runtime': 2.1976, 'eval_samples_per_second': 2.73, 'eval_steps_per_second': 0.455, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.0948, 'learning_rate': 0.0006428571428571428, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.203622817993164, 'eval_runtime': 2.197, 'eval_samples_per_second': 2.731, 'eval_steps_per_second': 0.455, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.0732, 'learning_rate': 0.00042857142857142855, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.204572677612305, 'eval_runtime': 2.1979, 'eval_samples_per_second': 2.73, 'eval_steps_per_second': 0.455, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.0751, 'learning_rate': 0.00021428571428571427, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.205753803253174, 'eval_runtime': 2.1966, 'eval_samples_per_second': 2.731, 'eval_steps_per_second': 0.455, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.06, 'learning_rate': 0.0, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.205715179443359, 'eval_runtime': 2.1947, 'eval_samples_per_second': 2.734, 'eval_steps_per_second': 0.456, 'epoch': 20.0}\n",
      "{'train_runtime': 261.4768, 'train_samples_per_second': 0.459, 'train_steps_per_second': 0.076, 'train_loss': 4.29565052986145, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ibois, Philippe (2012-06-03).\n",
      "{'before': 61.07478713989258, 'after': 59.88446807861328}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  8.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.54it/s]\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6237, 'learning_rate': 0.0005, 'epoch': 1.0}\n",
      "{'eval_loss': 2.759657382965088, 'eval_runtime': 1.8536, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.539, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.621, 'learning_rate': 0.001, 'epoch': 2.0}\n",
      "{'eval_loss': 2.7597293853759766, 'eval_runtime': 1.8541, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.539, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6206, 'learning_rate': 0.0015, 'epoch': 3.0}\n",
      "{'eval_loss': 2.7564902305603027, 'eval_runtime': 1.853, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.54, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5974, 'learning_rate': 0.002, 'epoch': 4.0}\n",
      "{'eval_loss': 2.752861976623535, 'eval_runtime': 1.8565, 'eval_samples_per_second': 1.077, 'eval_steps_per_second': 0.539, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5802, 'learning_rate': 0.0025, 'epoch': 5.0}\n",
      "{'eval_loss': 2.748295307159424, 'eval_runtime': 1.8529, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.54, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5569, 'learning_rate': 0.003, 'epoch': 6.0}\n",
      "{'eval_loss': 2.7460708618164062, 'eval_runtime': 1.8524, 'eval_samples_per_second': 1.08, 'eval_steps_per_second': 0.54, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5307, 'learning_rate': 0.002785714285714286, 'epoch': 7.0}\n",
      "{'eval_loss': 2.738633632659912, 'eval_runtime': 1.8539, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.539, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.504, 'learning_rate': 0.0025714285714285713, 'epoch': 8.0}\n",
      "{'eval_loss': 2.734565019607544, 'eval_runtime': 1.8537, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.539, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4754, 'learning_rate': 0.002357142857142857, 'epoch': 9.0}\n",
      "{'eval_loss': 2.733013153076172, 'eval_runtime': 1.8536, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.539, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4581, 'learning_rate': 0.002142857142857143, 'epoch': 10.0}\n",
      "{'eval_loss': 2.731515645980835, 'eval_runtime': 1.8536, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.539, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4333, 'learning_rate': 0.0019285714285714288, 'epoch': 11.0}\n",
      "{'eval_loss': 2.7264902591705322, 'eval_runtime': 1.8544, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.539, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4228, 'learning_rate': 0.0017142857142857142, 'epoch': 12.0}\n",
      "{'eval_loss': 2.7332866191864014, 'eval_runtime': 1.855, 'eval_samples_per_second': 1.078, 'eval_steps_per_second': 0.539, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4027, 'learning_rate': 0.0015, 'epoch': 13.0}\n",
      "{'eval_loss': 2.729839324951172, 'eval_runtime': 1.855, 'eval_samples_per_second': 1.078, 'eval_steps_per_second': 0.539, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3891, 'learning_rate': 0.0012857142857142856, 'epoch': 14.0}\n",
      "{'eval_loss': 2.731370687484741, 'eval_runtime': 1.8598, 'eval_samples_per_second': 1.075, 'eval_steps_per_second': 0.538, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3841, 'learning_rate': 0.0010714285714285715, 'epoch': 15.0}\n",
      "{'eval_loss': 2.732412338256836, 'eval_runtime': 1.8545, 'eval_samples_per_second': 1.078, 'eval_steps_per_second': 0.539, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3689, 'learning_rate': 0.0008571428571428571, 'epoch': 16.0}\n",
      "{'eval_loss': 2.7393574714660645, 'eval_runtime': 1.8536, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.54, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3563, 'learning_rate': 0.0006428571428571428, 'epoch': 17.0}\n",
      "{'eval_loss': 2.7468791007995605, 'eval_runtime': 1.8542, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.539, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3526, 'learning_rate': 0.00042857142857142855, 'epoch': 18.0}\n",
      "{'eval_loss': 2.7505300045013428, 'eval_runtime': 1.8532, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.54, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3435, 'learning_rate': 0.00021428571428571427, 'epoch': 19.0}\n",
      "{'eval_loss': 2.757460594177246, 'eval_runtime': 1.8536, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.54, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3398, 'learning_rate': 0.0, 'epoch': 20.0}\n",
      "{'eval_loss': 2.760329246520996, 'eval_runtime': 1.8558, 'eval_samples_per_second': 1.078, 'eval_steps_per_second': 0.539, 'epoch': 20.0}\n",
      "{'train_runtime': 42.5025, 'train_samples_per_second': 2.823, 'train_steps_per_second': 0.471, 'train_loss': 0.4680565565824509, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  8.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disney appointment\n",
      "{'before': 7.112776756286621, 'after': 6.932384490966797}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.60it/s]\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6745, 'learning_rate': 0.0005, 'epoch': 1.0}\n",
      "{'eval_loss': 1.5698368549346924, 'eval_runtime': 0.1186, 'eval_samples_per_second': 8.435, 'eval_steps_per_second': 8.435, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6751, 'learning_rate': 0.001, 'epoch': 2.0}\n",
      "{'eval_loss': 1.5680769681930542, 'eval_runtime': 0.1122, 'eval_samples_per_second': 8.911, 'eval_steps_per_second': 8.911, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6686, 'learning_rate': 0.0015, 'epoch': 3.0}\n",
      "{'eval_loss': 1.5664819478988647, 'eval_runtime': 0.1151, 'eval_samples_per_second': 8.685, 'eval_steps_per_second': 8.685, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6542, 'learning_rate': 0.002, 'epoch': 4.0}\n",
      "{'eval_loss': 1.5632203817367554, 'eval_runtime': 0.1171, 'eval_samples_per_second': 8.537, 'eval_steps_per_second': 8.537, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.63, 'learning_rate': 0.0025, 'epoch': 5.0}\n",
      "{'eval_loss': 1.5577468872070312, 'eval_runtime': 0.117, 'eval_samples_per_second': 8.549, 'eval_steps_per_second': 8.549, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.604, 'learning_rate': 0.003, 'epoch': 6.0}\n",
      "{'eval_loss': 1.5563703775405884, 'eval_runtime': 0.1164, 'eval_samples_per_second': 8.593, 'eval_steps_per_second': 8.593, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5629, 'learning_rate': 0.002785714285714286, 'epoch': 7.0}\n",
      "{'eval_loss': 1.556630253791809, 'eval_runtime': 0.1174, 'eval_samples_per_second': 8.517, 'eval_steps_per_second': 8.517, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.526, 'learning_rate': 0.0025714285714285713, 'epoch': 8.0}\n",
      "{'eval_loss': 1.5555983781814575, 'eval_runtime': 0.116, 'eval_samples_per_second': 8.618, 'eval_steps_per_second': 8.618, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4898, 'learning_rate': 0.002357142857142857, 'epoch': 9.0}\n",
      "{'eval_loss': 1.557144284248352, 'eval_runtime': 0.1149, 'eval_samples_per_second': 8.701, 'eval_steps_per_second': 8.701, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4518, 'learning_rate': 0.002142857142857143, 'epoch': 10.0}\n",
      "{'eval_loss': 1.5535787343978882, 'eval_runtime': 0.1183, 'eval_samples_per_second': 8.457, 'eval_steps_per_second': 8.457, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4442, 'learning_rate': 0.0019285714285714288, 'epoch': 11.0}\n",
      "{'eval_loss': 1.5532571077346802, 'eval_runtime': 0.117, 'eval_samples_per_second': 8.545, 'eval_steps_per_second': 8.545, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4233, 'learning_rate': 0.0017142857142857142, 'epoch': 12.0}\n",
      "{'eval_loss': 1.5584156513214111, 'eval_runtime': 0.1136, 'eval_samples_per_second': 8.806, 'eval_steps_per_second': 8.806, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4047, 'learning_rate': 0.0015, 'epoch': 13.0}\n",
      "{'eval_loss': 1.5603874921798706, 'eval_runtime': 0.1162, 'eval_samples_per_second': 8.606, 'eval_steps_per_second': 8.606, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3885, 'learning_rate': 0.0012857142857142856, 'epoch': 14.0}\n",
      "{'eval_loss': 1.5612046718597412, 'eval_runtime': 0.1215, 'eval_samples_per_second': 8.233, 'eval_steps_per_second': 8.233, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3593, 'learning_rate': 0.0010714285714285715, 'epoch': 15.0}\n",
      "{'eval_loss': 1.563994288444519, 'eval_runtime': 0.1198, 'eval_samples_per_second': 8.345, 'eval_steps_per_second': 8.345, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3593, 'learning_rate': 0.0008571428571428571, 'epoch': 16.0}\n",
      "{'eval_loss': 1.5627647638320923, 'eval_runtime': 0.1157, 'eval_samples_per_second': 8.642, 'eval_steps_per_second': 8.642, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3356, 'learning_rate': 0.0006428571428571428, 'epoch': 17.0}\n",
      "{'eval_loss': 1.56623375415802, 'eval_runtime': 0.115, 'eval_samples_per_second': 8.692, 'eval_steps_per_second': 8.692, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3358, 'learning_rate': 0.00042857142857142855, 'epoch': 18.0}\n",
      "{'eval_loss': 1.5700865983963013, 'eval_runtime': 0.1168, 'eval_samples_per_second': 8.562, 'eval_steps_per_second': 8.562, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3275, 'learning_rate': 0.00021428571428571427, 'epoch': 19.0}\n",
      "{'eval_loss': 1.5686964988708496, 'eval_runtime': 0.121, 'eval_samples_per_second': 8.263, 'eval_steps_per_second': 8.263, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3213, 'learning_rate': 0.0, 'epoch': 20.0}\n",
      "{'eval_loss': 1.5683350563049316, 'eval_runtime': 0.1183, 'eval_samples_per_second': 8.454, 'eval_steps_per_second': 8.454, 'epoch': 20.0}\n",
      "{'train_runtime': 7.1227, 'train_samples_per_second': 16.848, 'train_steps_per_second': 2.808, 'train_loss': 0.4818130642175674, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fake ai hoax paper\n",
      "{'before': 4.80548095703125, 'after': 4.726459980010986}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.5402, 'learning_rate': 0.0005, 'epoch': 1.0}\n",
      "{'eval_loss': 2.809673309326172, 'eval_runtime': 2.0827, 'eval_samples_per_second': 2.401, 'eval_steps_per_second': 0.48, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.5308, 'learning_rate': 0.001, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8012375831604004, 'eval_runtime': 2.0794, 'eval_samples_per_second': 2.405, 'eval_steps_per_second': 0.481, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.5213, 'learning_rate': 0.0015, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.793071746826172, 'eval_runtime': 2.0843, 'eval_samples_per_second': 2.399, 'eval_steps_per_second': 0.48, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.4749, 'learning_rate': 0.002, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.780738115310669, 'eval_runtime': 2.0827, 'eval_samples_per_second': 2.401, 'eval_steps_per_second': 0.48, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.4178, 'learning_rate': 0.0025, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.766921281814575, 'eval_runtime': 2.0817, 'eval_samples_per_second': 2.402, 'eval_steps_per_second': 0.48, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.3676, 'learning_rate': 0.003, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7501397132873535, 'eval_runtime': 2.0899, 'eval_samples_per_second': 2.392, 'eval_steps_per_second': 0.478, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.3403, 'learning_rate': 0.002785714285714286, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7327661514282227, 'eval_runtime': 2.0808, 'eval_samples_per_second': 2.403, 'eval_steps_per_second': 0.481, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.2576, 'learning_rate': 0.0025714285714285713, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7207441329956055, 'eval_runtime': 2.082, 'eval_samples_per_second': 2.402, 'eval_steps_per_second': 0.48, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.1886, 'learning_rate': 0.002357142857142857, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.710601329803467, 'eval_runtime': 2.0822, 'eval_samples_per_second': 2.401, 'eval_steps_per_second': 0.48, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.1303, 'learning_rate': 0.002142857142857143, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7007527351379395, 'eval_runtime': 2.0791, 'eval_samples_per_second': 2.405, 'eval_steps_per_second': 0.481, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0843, 'learning_rate': 0.0019285714285714288, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.6963632106781006, 'eval_runtime': 2.0762, 'eval_samples_per_second': 2.408, 'eval_steps_per_second': 0.482, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0467, 'learning_rate': 0.0017142857142857142, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.6910972595214844, 'eval_runtime': 2.0822, 'eval_samples_per_second': 2.401, 'eval_steps_per_second': 0.48, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0034, 'learning_rate': 0.0015, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.68571400642395, 'eval_runtime': 2.0816, 'eval_samples_per_second': 2.402, 'eval_steps_per_second': 0.48, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9834, 'learning_rate': 0.0012857142857142856, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.679442882537842, 'eval_runtime': 2.078, 'eval_samples_per_second': 2.406, 'eval_steps_per_second': 0.481, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9388, 'learning_rate': 0.0010714285714285715, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.6775050163269043, 'eval_runtime': 2.0768, 'eval_samples_per_second': 2.408, 'eval_steps_per_second': 0.482, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9131, 'learning_rate': 0.0008571428571428571, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.674304723739624, 'eval_runtime': 2.0773, 'eval_samples_per_second': 2.407, 'eval_steps_per_second': 0.481, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8694, 'learning_rate': 0.0006428571428571428, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.671732187271118, 'eval_runtime': 2.0847, 'eval_samples_per_second': 2.398, 'eval_steps_per_second': 0.48, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8736, 'learning_rate': 0.00042857142857142855, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.669948101043701, 'eval_runtime': 2.08, 'eval_samples_per_second': 2.404, 'eval_steps_per_second': 0.481, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8722, 'learning_rate': 0.00021428571428571427, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.666889190673828, 'eval_runtime': 2.0779, 'eval_samples_per_second': 2.406, 'eval_steps_per_second': 0.481, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8454, 'learning_rate': 0.0, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.66707444190979, 'eval_runtime': 2.0769, 'eval_samples_per_second': 2.407, 'eval_steps_per_second': 0.481, 'epoch': 20.0}\n",
      "{'train_runtime': 259.3997, 'train_samples_per_second': 0.463, 'train_steps_per_second': 0.077, 'train_loss': 3.159981667995453, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buzzfeed foi fauci emails 2023\n",
      "{'before': 10.51438045501709, 'after': 9.99929428100586}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  7.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.10it/s]\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9061, 'learning_rate': 0.0005, 'epoch': 1.0}\n",
      "{'eval_loss': 2.910276412963867, 'eval_runtime': 1.8532, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.54, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9003, 'learning_rate': 0.001, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.909058094024658, 'eval_runtime': 1.8535, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.54, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8842, 'learning_rate': 0.0015, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.9053797721862793, 'eval_runtime': 1.8533, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.54, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8764, 'learning_rate': 0.002, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.9014058113098145, 'eval_runtime': 1.8536, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.539, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.862, 'learning_rate': 0.0025, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8948469161987305, 'eval_runtime': 1.8534, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.54, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8228, 'learning_rate': 0.003, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.887235641479492, 'eval_runtime': 1.8555, 'eval_samples_per_second': 1.078, 'eval_steps_per_second': 0.539, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7955, 'learning_rate': 0.002785714285714286, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8758654594421387, 'eval_runtime': 1.8535, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.54, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7576, 'learning_rate': 0.0025714285714285713, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8753256797790527, 'eval_runtime': 1.8542, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.539, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7267, 'learning_rate': 0.002357142857142857, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.870819091796875, 'eval_runtime': 1.8534, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.54, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6908, 'learning_rate': 0.002142857142857143, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.870246410369873, 'eval_runtime': 1.8534, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.54, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6676, 'learning_rate': 0.0019285714285714288, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8703277111053467, 'eval_runtime': 1.8526, 'eval_samples_per_second': 1.08, 'eval_steps_per_second': 0.54, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6501, 'learning_rate': 0.0017142857142857142, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8726062774658203, 'eval_runtime': 1.8534, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.54, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6339, 'learning_rate': 0.0015, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8750758171081543, 'eval_runtime': 1.8537, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.539, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6107, 'learning_rate': 0.0012857142857142856, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8758249282836914, 'eval_runtime': 1.8562, 'eval_samples_per_second': 1.077, 'eval_steps_per_second': 0.539, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5975, 'learning_rate': 0.0010714285714285715, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8766515254974365, 'eval_runtime': 1.8541, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.539, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5896, 'learning_rate': 0.0008571428571428571, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.877887487411499, 'eval_runtime': 1.8541, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.539, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.571, 'learning_rate': 0.0006428571428571428, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.876659393310547, 'eval_runtime': 1.8533, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.54, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5655, 'learning_rate': 0.00042857142857142855, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8768811225891113, 'eval_runtime': 1.8542, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.539, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5524, 'learning_rate': 0.00021428571428571427, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.87695050239563, 'eval_runtime': 1.8539, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.539, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5572, 'learning_rate': 0.0, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.876206874847412, 'eval_runtime': 1.8537, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.539, 'epoch': 20.0}\n",
      "{'train_runtime': 110.3229, 'train_samples_per_second': 1.088, 'train_steps_per_second': 0.181, 'train_loss': 0.7109108477830887, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  7.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "harvard announcment caplain israel hamas\n",
      "{'before': 13.605052947998047, 'after': 13.449620246887207}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.80it/s]\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8841, 'learning_rate': 0.0005, 'epoch': 1.0}\n",
      "{'eval_loss': 3.1093873977661133, 'eval_runtime': 1.8536, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.539, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8939, 'learning_rate': 0.001, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.104572296142578, 'eval_runtime': 1.8534, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.54, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8791, 'learning_rate': 0.0015, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.0975534915924072, 'eval_runtime': 1.8524, 'eval_samples_per_second': 1.08, 'eval_steps_per_second': 0.54, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8663, 'learning_rate': 0.002, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.0872480869293213, 'eval_runtime': 1.8573, 'eval_samples_per_second': 1.077, 'eval_steps_per_second': 0.538, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8426, 'learning_rate': 0.0025, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.0743579864501953, 'eval_runtime': 1.8525, 'eval_samples_per_second': 1.08, 'eval_steps_per_second': 0.54, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8186, 'learning_rate': 0.003, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.063880443572998, 'eval_runtime': 1.8535, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.54, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7962, 'learning_rate': 0.002785714285714286, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.0475571155548096, 'eval_runtime': 1.8536, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.54, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7619, 'learning_rate': 0.0025714285714285713, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.037322998046875, 'eval_runtime': 1.8535, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.54, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.74, 'learning_rate': 0.002357142857142857, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.034162998199463, 'eval_runtime': 1.8527, 'eval_samples_per_second': 1.08, 'eval_steps_per_second': 0.54, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.711, 'learning_rate': 0.002142857142857143, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.0277624130249023, 'eval_runtime': 1.8538, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.539, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6913, 'learning_rate': 0.0019285714285714288, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.020629405975342, 'eval_runtime': 1.8521, 'eval_samples_per_second': 1.08, 'eval_steps_per_second': 0.54, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6801, 'learning_rate': 0.0017142857142857142, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.0162758827209473, 'eval_runtime': 1.8535, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.54, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6573, 'learning_rate': 0.0015, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.0166947841644287, 'eval_runtime': 1.8533, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.54, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6473, 'learning_rate': 0.0012857142857142856, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.0144472122192383, 'eval_runtime': 1.8527, 'eval_samples_per_second': 1.08, 'eval_steps_per_second': 0.54, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6272, 'learning_rate': 0.0010714285714285715, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.011507987976074, 'eval_runtime': 1.8537, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.539, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6199, 'learning_rate': 0.0008571428571428571, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.0144472122192383, 'eval_runtime': 1.8535, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.54, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6017, 'learning_rate': 0.0006428571428571428, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.0084285736083984, 'eval_runtime': 1.8543, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.539, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6, 'learning_rate': 0.00042857142857142855, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.010361909866333, 'eval_runtime': 1.8534, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.54, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5948, 'learning_rate': 0.00021428571428571427, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.010336399078369, 'eval_runtime': 1.8531, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.54, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5982, 'learning_rate': 0.0, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.010620594024658, 'eval_runtime': 1.8529, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.54, 'epoch': 20.0}\n",
      "{'train_runtime': 110.3262, 'train_samples_per_second': 1.088, 'train_steps_per_second': 0.181, 'train_loss': 0.7255841135978699, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to Catch an AI Liar\n",
      "{'before': 16.3325138092041, 'after': 14.918395042419434}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.93it/s]\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8802, 'learning_rate': 0.0005, 'epoch': 1.0}\n",
      "{'eval_loss': 2.833146572113037, 'eval_runtime': 2.0767, 'eval_samples_per_second': 2.408, 'eval_steps_per_second': 0.482, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8728, 'learning_rate': 0.001, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8278772830963135, 'eval_runtime': 2.0736, 'eval_samples_per_second': 2.411, 'eval_steps_per_second': 0.482, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8376, 'learning_rate': 0.0015, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.825390338897705, 'eval_runtime': 2.0795, 'eval_samples_per_second': 2.404, 'eval_steps_per_second': 0.481, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.794, 'learning_rate': 0.002, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.820244789123535, 'eval_runtime': 2.0693, 'eval_samples_per_second': 2.416, 'eval_steps_per_second': 0.483, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7608, 'learning_rate': 0.0025, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8097968101501465, 'eval_runtime': 2.0771, 'eval_samples_per_second': 2.407, 'eval_steps_per_second': 0.481, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7132, 'learning_rate': 0.003, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8014912605285645, 'eval_runtime': 2.0829, 'eval_samples_per_second': 2.401, 'eval_steps_per_second': 0.48, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6567, 'learning_rate': 0.002785714285714286, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7906250953674316, 'eval_runtime': 2.0739, 'eval_samples_per_second': 2.411, 'eval_steps_per_second': 0.482, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.5723, 'learning_rate': 0.0025714285714285713, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.783757448196411, 'eval_runtime': 2.0703, 'eval_samples_per_second': 2.415, 'eval_steps_per_second': 0.483, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.5173, 'learning_rate': 0.002357142857142857, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.777430534362793, 'eval_runtime': 2.0765, 'eval_samples_per_second': 2.408, 'eval_steps_per_second': 0.482, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4365, 'learning_rate': 0.002142857142857143, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7713847160339355, 'eval_runtime': 2.0767, 'eval_samples_per_second': 2.408, 'eval_steps_per_second': 0.482, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3887, 'learning_rate': 0.0019285714285714288, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.766700267791748, 'eval_runtime': 2.0778, 'eval_samples_per_second': 2.406, 'eval_steps_per_second': 0.481, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3458, 'learning_rate': 0.0017142857142857142, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7613189220428467, 'eval_runtime': 2.0831, 'eval_samples_per_second': 2.4, 'eval_steps_per_second': 0.48, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3, 'learning_rate': 0.0015, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7597270011901855, 'eval_runtime': 2.076, 'eval_samples_per_second': 2.408, 'eval_steps_per_second': 0.482, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2704, 'learning_rate': 0.0012857142857142856, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7557966709136963, 'eval_runtime': 2.0747, 'eval_samples_per_second': 2.41, 'eval_steps_per_second': 0.482, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2442, 'learning_rate': 0.0010714285714285715, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.753859281539917, 'eval_runtime': 2.0795, 'eval_samples_per_second': 2.404, 'eval_steps_per_second': 0.481, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.224, 'learning_rate': 0.0008571428571428571, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7497611045837402, 'eval_runtime': 2.0726, 'eval_samples_per_second': 2.412, 'eval_steps_per_second': 0.482, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2045, 'learning_rate': 0.0006428571428571428, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7502355575561523, 'eval_runtime': 2.0706, 'eval_samples_per_second': 2.415, 'eval_steps_per_second': 0.483, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1911, 'learning_rate': 0.00042857142857142855, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7499685287475586, 'eval_runtime': 2.0766, 'eval_samples_per_second': 2.408, 'eval_steps_per_second': 0.482, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1837, 'learning_rate': 0.00021428571428571427, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7477238178253174, 'eval_runtime': 2.0822, 'eval_samples_per_second': 2.401, 'eval_steps_per_second': 0.48, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1603, 'learning_rate': 0.0, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.747436046600342, 'eval_runtime': 2.0767, 'eval_samples_per_second': 2.408, 'eval_steps_per_second': 0.482, 'epoch': 20.0}\n",
      "{'train_runtime': 258.9654, 'train_samples_per_second': 0.463, 'train_steps_per_second': 0.077, 'train_loss': 2.4776997566223145, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LK-99-en\n",
      "{'before': 11.107545852661133, 'after': 10.768901824951172}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7373, 'learning_rate': 0.0005, 'epoch': 1.0}\n",
      "{'eval_loss': 2.228729486465454, 'eval_runtime': 2.2305, 'eval_samples_per_second': 3.138, 'eval_steps_per_second': 0.448, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7398, 'learning_rate': 0.001, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2262868881225586, 'eval_runtime': 2.2271, 'eval_samples_per_second': 3.143, 'eval_steps_per_second': 0.449, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7249, 'learning_rate': 0.0015, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.222583770751953, 'eval_runtime': 2.2304, 'eval_samples_per_second': 3.138, 'eval_steps_per_second': 0.448, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6954, 'learning_rate': 0.002, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2177114486694336, 'eval_runtime': 2.2267, 'eval_samples_per_second': 3.144, 'eval_steps_per_second': 0.449, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6487, 'learning_rate': 0.0025, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2114782333374023, 'eval_runtime': 2.2257, 'eval_samples_per_second': 3.145, 'eval_steps_per_second': 0.449, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6021, 'learning_rate': 0.003, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.204953908920288, 'eval_runtime': 2.2293, 'eval_samples_per_second': 3.14, 'eval_steps_per_second': 0.449, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.5475, 'learning_rate': 0.002785714285714286, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1997663974761963, 'eval_runtime': 2.2249, 'eval_samples_per_second': 3.146, 'eval_steps_per_second': 0.449, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4861, 'learning_rate': 0.0025714285714285713, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.195139169692993, 'eval_runtime': 2.22, 'eval_samples_per_second': 3.153, 'eval_steps_per_second': 0.45, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4401, 'learning_rate': 0.002357142857142857, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1921756267547607, 'eval_runtime': 2.2232, 'eval_samples_per_second': 3.149, 'eval_steps_per_second': 0.45, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3875, 'learning_rate': 0.002142857142857143, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1900081634521484, 'eval_runtime': 2.2297, 'eval_samples_per_second': 3.139, 'eval_steps_per_second': 0.448, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3437, 'learning_rate': 0.0019285714285714288, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1875574588775635, 'eval_runtime': 2.2283, 'eval_samples_per_second': 3.141, 'eval_steps_per_second': 0.449, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3149, 'learning_rate': 0.0017142857142857142, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.18703556060791, 'eval_runtime': 2.222, 'eval_samples_per_second': 3.15, 'eval_steps_per_second': 0.45, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2851, 'learning_rate': 0.0015, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1857080459594727, 'eval_runtime': 2.2255, 'eval_samples_per_second': 3.145, 'eval_steps_per_second': 0.449, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2384, 'learning_rate': 0.0012857142857142856, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.18491530418396, 'eval_runtime': 2.2245, 'eval_samples_per_second': 3.147, 'eval_steps_per_second': 0.45, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.203, 'learning_rate': 0.0010714285714285715, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.185029983520508, 'eval_runtime': 2.2226, 'eval_samples_per_second': 3.15, 'eval_steps_per_second': 0.45, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1913, 'learning_rate': 0.0008571428571428571, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1852521896362305, 'eval_runtime': 2.2277, 'eval_samples_per_second': 3.142, 'eval_steps_per_second': 0.449, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1674, 'learning_rate': 0.0006428571428571428, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.183973550796509, 'eval_runtime': 2.2342, 'eval_samples_per_second': 3.133, 'eval_steps_per_second': 0.448, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1656, 'learning_rate': 0.00042857142857142855, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.183441162109375, 'eval_runtime': 2.237, 'eval_samples_per_second': 3.129, 'eval_steps_per_second': 0.447, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1495, 'learning_rate': 0.00021428571428571427, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1836740970611572, 'eval_runtime': 2.2396, 'eval_samples_per_second': 3.126, 'eval_steps_per_second': 0.447, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1465, 'learning_rate': 0.0, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1844637393951416, 'eval_runtime': 2.2386, 'eval_samples_per_second': 3.127, 'eval_steps_per_second': 0.447, 'epoch': 20.0}\n",
      "{'train_runtime': 262.2762, 'train_samples_per_second': 0.458, 'train_steps_per_second': 0.076, 'train_loss': 2.4107391834259033, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.13s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LK-99-es\n",
      "{'before': 5.7730841636657715, 'after': 5.697879791259766}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.38s/it]\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8969, 'learning_rate': 0.0005, 'epoch': 0.6}\n",
      "{'eval_loss': 1.9049897193908691, 'eval_runtime': 2.3846, 'eval_samples_per_second': 3.774, 'eval_steps_per_second': 0.419, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9223, 'learning_rate': 0.001, 'epoch': 1.2}\n",
      "{'loss': 1.8572, 'learning_rate': 0.0015, 'epoch': 1.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8747698068618774, 'eval_runtime': 2.3868, 'eval_samples_per_second': 3.771, 'eval_steps_per_second': 0.419, 'epoch': 1.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8607, 'learning_rate': 0.002, 'epoch': 2.4}\n",
      "{'loss': 1.8919, 'learning_rate': 0.0025, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.853322982788086, 'eval_runtime': 2.3845, 'eval_samples_per_second': 3.774, 'eval_steps_per_second': 0.419, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.898, 'learning_rate': 0.003, 'epoch': 3.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8494622707366943, 'eval_runtime': 2.3821, 'eval_samples_per_second': 3.778, 'eval_steps_per_second': 0.42, 'epoch': 3.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7994, 'learning_rate': 0.002785714285714286, 'epoch': 4.2}\n",
      "{'loss': 1.8124, 'learning_rate': 0.0025714285714285713, 'epoch': 4.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8535112142562866, 'eval_runtime': 2.392, 'eval_samples_per_second': 3.763, 'eval_steps_per_second': 0.418, 'epoch': 4.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7804, 'learning_rate': 0.002357142857142857, 'epoch': 5.4}\n",
      "{'loss': 1.8613, 'learning_rate': 0.002142857142857143, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8590210676193237, 'eval_runtime': 2.3883, 'eval_samples_per_second': 3.768, 'eval_steps_per_second': 0.419, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7872, 'learning_rate': 0.0019285714285714288, 'epoch': 6.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8612093925476074, 'eval_runtime': 2.39, 'eval_samples_per_second': 3.766, 'eval_steps_per_second': 0.418, 'epoch': 6.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.808, 'learning_rate': 0.0017142857142857142, 'epoch': 7.2}\n",
      "{'loss': 1.7778, 'learning_rate': 0.0015, 'epoch': 7.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.859637975692749, 'eval_runtime': 2.3866, 'eval_samples_per_second': 3.771, 'eval_steps_per_second': 0.419, 'epoch': 7.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7654, 'learning_rate': 0.0012857142857142856, 'epoch': 8.4}\n",
      "{'loss': 1.8022, 'learning_rate': 0.0010714285714285715, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8593199253082275, 'eval_runtime': 2.3861, 'eval_samples_per_second': 3.772, 'eval_steps_per_second': 0.419, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8045, 'learning_rate': 0.0008571428571428571, 'epoch': 9.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8577730655670166, 'eval_runtime': 2.3904, 'eval_samples_per_second': 3.765, 'eval_steps_per_second': 0.418, 'epoch': 9.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7131, 'learning_rate': 0.0006428571428571428, 'epoch': 10.2}\n",
      "{'loss': 1.7295, 'learning_rate': 0.00042857142857142855, 'epoch': 10.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.856925129890442, 'eval_runtime': 2.3844, 'eval_samples_per_second': 3.775, 'eval_steps_per_second': 0.419, 'epoch': 10.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7873, 'learning_rate': 0.00021428571428571427, 'epoch': 11.4}\n",
      "{'loss': 1.7303, 'learning_rate': 0.0, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8559074401855469, 'eval_runtime': 2.3841, 'eval_samples_per_second': 3.775, 'eval_steps_per_second': 0.419, 'epoch': 12.0}\n",
      "{'train_runtime': 204.9699, 'train_samples_per_second': 0.585, 'train_steps_per_second': 0.098, 'train_loss': 1.8142928600311279, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.36s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.33s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lorem ipsum\n",
      "{'before': 22.06707000732422, 'after': 20.045455932617188}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  8.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.54it/s]\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.739, 'learning_rate': 0.0005, 'epoch': 1.0}\n",
      "{'eval_loss': 2.192563056945801, 'eval_runtime': 0.1147, 'eval_samples_per_second': 8.716, 'eval_steps_per_second': 8.716, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7446, 'learning_rate': 0.001, 'epoch': 2.0}\n",
      "{'eval_loss': 2.1906583309173584, 'eval_runtime': 0.1101, 'eval_samples_per_second': 9.085, 'eval_steps_per_second': 9.085, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7294, 'learning_rate': 0.0015, 'epoch': 3.0}\n",
      "{'eval_loss': 2.1856143474578857, 'eval_runtime': 0.1111, 'eval_samples_per_second': 9.002, 'eval_steps_per_second': 9.002, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7127, 'learning_rate': 0.002, 'epoch': 4.0}\n",
      "{'eval_loss': 2.177340030670166, 'eval_runtime': 0.11, 'eval_samples_per_second': 9.09, 'eval_steps_per_second': 9.09, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6902, 'learning_rate': 0.0025, 'epoch': 5.0}\n",
      "{'eval_loss': 2.17113995552063, 'eval_runtime': 0.1102, 'eval_samples_per_second': 9.071, 'eval_steps_per_second': 9.071, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6677, 'learning_rate': 0.003, 'epoch': 6.0}\n",
      "{'eval_loss': 2.1561458110809326, 'eval_runtime': 0.1117, 'eval_samples_per_second': 8.951, 'eval_steps_per_second': 8.951, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6302, 'learning_rate': 0.002785714285714286, 'epoch': 7.0}\n",
      "{'eval_loss': 2.1426870822906494, 'eval_runtime': 0.1101, 'eval_samples_per_second': 9.08, 'eval_steps_per_second': 9.08, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5977, 'learning_rate': 0.0025714285714285713, 'epoch': 8.0}\n",
      "{'eval_loss': 2.1372711658477783, 'eval_runtime': 0.1121, 'eval_samples_per_second': 8.918, 'eval_steps_per_second': 8.918, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5654, 'learning_rate': 0.002357142857142857, 'epoch': 9.0}\n",
      "{'eval_loss': 2.128983736038208, 'eval_runtime': 0.1143, 'eval_samples_per_second': 8.746, 'eval_steps_per_second': 8.746, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5339, 'learning_rate': 0.002142857142857143, 'epoch': 10.0}\n",
      "{'eval_loss': 2.12965989112854, 'eval_runtime': 0.1129, 'eval_samples_per_second': 8.86, 'eval_steps_per_second': 8.86, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.512, 'learning_rate': 0.0019285714285714288, 'epoch': 11.0}\n",
      "{'eval_loss': 2.1252620220184326, 'eval_runtime': 0.1158, 'eval_samples_per_second': 8.634, 'eval_steps_per_second': 8.634, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4899, 'learning_rate': 0.0017142857142857142, 'epoch': 12.0}\n",
      "{'eval_loss': 2.128906726837158, 'eval_runtime': 0.1141, 'eval_samples_per_second': 8.765, 'eval_steps_per_second': 8.765, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4773, 'learning_rate': 0.0015, 'epoch': 13.0}\n",
      "{'eval_loss': 2.1320488452911377, 'eval_runtime': 0.1163, 'eval_samples_per_second': 8.601, 'eval_steps_per_second': 8.601, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4489, 'learning_rate': 0.0012857142857142856, 'epoch': 14.0}\n",
      "{'eval_loss': 2.1474263668060303, 'eval_runtime': 0.1205, 'eval_samples_per_second': 8.298, 'eval_steps_per_second': 8.298, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4387, 'learning_rate': 0.0010714285714285715, 'epoch': 15.0}\n",
      "{'eval_loss': 2.165801763534546, 'eval_runtime': 0.1172, 'eval_samples_per_second': 8.53, 'eval_steps_per_second': 8.53, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4267, 'learning_rate': 0.0008571428571428571, 'epoch': 16.0}\n",
      "{'eval_loss': 2.1691884994506836, 'eval_runtime': 0.1147, 'eval_samples_per_second': 8.716, 'eval_steps_per_second': 8.716, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4252, 'learning_rate': 0.0006428571428571428, 'epoch': 17.0}\n",
      "{'eval_loss': 2.167924404144287, 'eval_runtime': 0.1123, 'eval_samples_per_second': 8.904, 'eval_steps_per_second': 8.904, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.414, 'learning_rate': 0.00042857142857142855, 'epoch': 18.0}\n",
      "{'eval_loss': 2.1624655723571777, 'eval_runtime': 0.1137, 'eval_samples_per_second': 8.797, 'eval_steps_per_second': 8.797, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4125, 'learning_rate': 0.00021428571428571427, 'epoch': 19.0}\n",
      "{'eval_loss': 2.1613035202026367, 'eval_runtime': 0.1109, 'eval_samples_per_second': 9.015, 'eval_steps_per_second': 9.015, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4013, 'learning_rate': 0.0, 'epoch': 20.0}\n",
      "{'eval_loss': 2.1570820808410645, 'eval_runtime': 0.1122, 'eval_samples_per_second': 8.911, 'eval_steps_per_second': 8.911, 'epoch': 20.0}\n",
      "{'train_runtime': 6.7751, 'train_samples_per_second': 17.712, 'train_steps_per_second': 2.952, 'train_loss': 0.5528773069381714, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  8.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai board ann\n",
      "{'before': 8.956920623779297, 'after': 8.37397575378418}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.75it/s]\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9313, 'learning_rate': 0.0005, 'epoch': 1.0}\n",
      "{'eval_loss': 2.6193394660949707, 'eval_runtime': 1.8534, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.54, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9413, 'learning_rate': 0.001, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.61201548576355, 'eval_runtime': 1.8549, 'eval_samples_per_second': 1.078, 'eval_steps_per_second': 0.539, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9291, 'learning_rate': 0.0015, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.6054701805114746, 'eval_runtime': 1.852, 'eval_samples_per_second': 1.08, 'eval_steps_per_second': 0.54, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9194, 'learning_rate': 0.002, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.5986037254333496, 'eval_runtime': 1.8518, 'eval_samples_per_second': 1.08, 'eval_steps_per_second': 0.54, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8908, 'learning_rate': 0.0025, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.5816807746887207, 'eval_runtime': 1.8524, 'eval_samples_per_second': 1.08, 'eval_steps_per_second': 0.54, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8677, 'learning_rate': 0.003, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.567370891571045, 'eval_runtime': 1.8528, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.54, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8356, 'learning_rate': 0.002785714285714286, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.5506303310394287, 'eval_runtime': 1.8548, 'eval_samples_per_second': 1.078, 'eval_steps_per_second': 0.539, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7977, 'learning_rate': 0.0025714285714285713, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.536162853240967, 'eval_runtime': 1.8526, 'eval_samples_per_second': 1.08, 'eval_steps_per_second': 0.54, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.769, 'learning_rate': 0.002357142857142857, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.5300021171569824, 'eval_runtime': 1.8525, 'eval_samples_per_second': 1.08, 'eval_steps_per_second': 0.54, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7549, 'learning_rate': 0.002142857142857143, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.5192646980285645, 'eval_runtime': 1.8525, 'eval_samples_per_second': 1.08, 'eval_steps_per_second': 0.54, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.725, 'learning_rate': 0.0019285714285714288, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.515676975250244, 'eval_runtime': 1.8525, 'eval_samples_per_second': 1.08, 'eval_steps_per_second': 0.54, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7028, 'learning_rate': 0.0017142857142857142, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.5090456008911133, 'eval_runtime': 1.8521, 'eval_samples_per_second': 1.08, 'eval_steps_per_second': 0.54, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6862, 'learning_rate': 0.0015, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.50835919380188, 'eval_runtime': 1.856, 'eval_samples_per_second': 1.078, 'eval_steps_per_second': 0.539, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6639, 'learning_rate': 0.0012857142857142856, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.5053606033325195, 'eval_runtime': 1.8531, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.54, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6626, 'learning_rate': 0.0010714285714285715, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.5055928230285645, 'eval_runtime': 1.8536, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.539, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6442, 'learning_rate': 0.0008571428571428571, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.5038294792175293, 'eval_runtime': 1.8577, 'eval_samples_per_second': 1.077, 'eval_steps_per_second': 0.538, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6277, 'learning_rate': 0.0006428571428571428, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.504798412322998, 'eval_runtime': 1.8528, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.54, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6271, 'learning_rate': 0.00042857142857142855, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.504643440246582, 'eval_runtime': 1.8538, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.539, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.619, 'learning_rate': 0.00021428571428571427, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.504636764526367, 'eval_runtime': 1.8539, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.539, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6131, 'learning_rate': 0.0, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.505075693130493, 'eval_runtime': 1.8527, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.54, 'epoch': 20.0}\n",
      "{'train_runtime': 110.2698, 'train_samples_per_second': 1.088, 'train_steps_per_second': 0.181, 'train_loss': 0.7604219943284989, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weak to strong\n",
      "{'before': 12.332788467407227, 'after': 11.297444343566895}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  8.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.29it/s]\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9295, 'learning_rate': 0.0005, 'epoch': 1.0}\n",
      "{'eval_loss': 2.664646863937378, 'eval_runtime': 0.1165, 'eval_samples_per_second': 8.585, 'eval_steps_per_second': 8.585, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9267, 'learning_rate': 0.001, 'epoch': 2.0}\n",
      "{'eval_loss': 2.661813497543335, 'eval_runtime': 0.1187, 'eval_samples_per_second': 8.423, 'eval_steps_per_second': 8.423, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9128, 'learning_rate': 0.0015, 'epoch': 3.0}\n",
      "{'eval_loss': 2.661179780960083, 'eval_runtime': 0.1233, 'eval_samples_per_second': 8.108, 'eval_steps_per_second': 8.108, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9042, 'learning_rate': 0.002, 'epoch': 4.0}\n",
      "{'eval_loss': 2.6573486328125, 'eval_runtime': 0.1245, 'eval_samples_per_second': 8.032, 'eval_steps_per_second': 8.032, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8772, 'learning_rate': 0.0025, 'epoch': 5.0}\n",
      "{'eval_loss': 2.6507937908172607, 'eval_runtime': 0.1191, 'eval_samples_per_second': 8.398, 'eval_steps_per_second': 8.398, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8556, 'learning_rate': 0.003, 'epoch': 6.0}\n",
      "{'eval_loss': 2.641019821166992, 'eval_runtime': 0.1232, 'eval_samples_per_second': 8.118, 'eval_steps_per_second': 8.118, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8158, 'learning_rate': 0.002785714285714286, 'epoch': 7.0}\n",
      "{'eval_loss': 2.6362545490264893, 'eval_runtime': 0.1227, 'eval_samples_per_second': 8.149, 'eval_steps_per_second': 8.149, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7806, 'learning_rate': 0.0025714285714285713, 'epoch': 8.0}\n",
      "{'eval_loss': 2.630005121231079, 'eval_runtime': 0.1245, 'eval_samples_per_second': 8.03, 'eval_steps_per_second': 8.03, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7479, 'learning_rate': 0.002357142857142857, 'epoch': 9.0}\n",
      "{'eval_loss': 2.62709379196167, 'eval_runtime': 0.1191, 'eval_samples_per_second': 8.394, 'eval_steps_per_second': 8.394, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.722, 'learning_rate': 0.002142857142857143, 'epoch': 10.0}\n",
      "{'eval_loss': 2.6279067993164062, 'eval_runtime': 0.1205, 'eval_samples_per_second': 8.298, 'eval_steps_per_second': 8.298, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6877, 'learning_rate': 0.0019285714285714288, 'epoch': 11.0}\n",
      "{'eval_loss': 2.630316972732544, 'eval_runtime': 0.1208, 'eval_samples_per_second': 8.275, 'eval_steps_per_second': 8.275, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6684, 'learning_rate': 0.0017142857142857142, 'epoch': 12.0}\n",
      "{'eval_loss': 2.6283013820648193, 'eval_runtime': 0.1212, 'eval_samples_per_second': 8.253, 'eval_steps_per_second': 8.253, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6407, 'learning_rate': 0.0015, 'epoch': 13.0}\n",
      "{'eval_loss': 2.6314098834991455, 'eval_runtime': 0.1254, 'eval_samples_per_second': 7.977, 'eval_steps_per_second': 7.977, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6234, 'learning_rate': 0.0012857142857142856, 'epoch': 14.0}\n",
      "{'eval_loss': 2.6316142082214355, 'eval_runtime': 0.1221, 'eval_samples_per_second': 8.188, 'eval_steps_per_second': 8.188, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6135, 'learning_rate': 0.0010714285714285715, 'epoch': 15.0}\n",
      "{'eval_loss': 2.63637113571167, 'eval_runtime': 0.1197, 'eval_samples_per_second': 8.354, 'eval_steps_per_second': 8.354, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6116, 'learning_rate': 0.0008571428571428571, 'epoch': 16.0}\n",
      "{'eval_loss': 2.6356468200683594, 'eval_runtime': 0.1229, 'eval_samples_per_second': 8.137, 'eval_steps_per_second': 8.137, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5905, 'learning_rate': 0.0006428571428571428, 'epoch': 17.0}\n",
      "{'eval_loss': 2.635625123977661, 'eval_runtime': 0.1256, 'eval_samples_per_second': 7.964, 'eval_steps_per_second': 7.964, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5791, 'learning_rate': 0.00042857142857142855, 'epoch': 18.0}\n",
      "{'eval_loss': 2.634904384613037, 'eval_runtime': 0.1181, 'eval_samples_per_second': 8.466, 'eval_steps_per_second': 8.466, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5739, 'learning_rate': 0.00021428571428571427, 'epoch': 19.0}\n",
      "{'eval_loss': 2.632082223892212, 'eval_runtime': 0.1186, 'eval_samples_per_second': 8.435, 'eval_steps_per_second': 8.435, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.584, 'learning_rate': 0.0, 'epoch': 20.0}\n",
      "{'eval_loss': 2.6331398487091064, 'eval_runtime': 0.1244, 'eval_samples_per_second': 8.037, 'eval_steps_per_second': 8.037, 'epoch': 20.0}\n",
      "{'train_runtime': 7.2399, 'train_samples_per_second': 16.575, 'train_steps_per_second': 2.762, 'train_loss': 0.7322499215602875, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  8.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "politics is the mind-killer\n",
      "{'before': 14.360716819763184, 'after': 13.831387519836426}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11.40it/s]\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.687, 'learning_rate': 0.0005, 'epoch': 1.0}\n",
      "{'eval_loss': 2.136593818664551, 'eval_runtime': 0.0726, 'eval_samples_per_second': 13.769, 'eval_steps_per_second': 13.769, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7077, 'learning_rate': 0.001, 'epoch': 2.0}\n",
      "{'eval_loss': 2.1345417499542236, 'eval_runtime': 0.0712, 'eval_samples_per_second': 14.048, 'eval_steps_per_second': 14.048, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6968, 'learning_rate': 0.0015, 'epoch': 3.0}\n",
      "{'eval_loss': 2.12933611869812, 'eval_runtime': 0.0707, 'eval_samples_per_second': 14.144, 'eval_steps_per_second': 14.144, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6559, 'learning_rate': 0.002, 'epoch': 4.0}\n",
      "{'eval_loss': 2.1261966228485107, 'eval_runtime': 0.0713, 'eval_samples_per_second': 14.016, 'eval_steps_per_second': 14.016, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6496, 'learning_rate': 0.0025, 'epoch': 5.0}\n",
      "{'eval_loss': 2.1181368827819824, 'eval_runtime': 0.0714, 'eval_samples_per_second': 14.004, 'eval_steps_per_second': 14.004, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6145, 'learning_rate': 0.003, 'epoch': 6.0}\n",
      "{'eval_loss': 2.112712860107422, 'eval_runtime': 0.0766, 'eval_samples_per_second': 13.053, 'eval_steps_per_second': 13.053, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5715, 'learning_rate': 0.002785714285714286, 'epoch': 7.0}\n",
      "{'eval_loss': 2.113090991973877, 'eval_runtime': 0.074, 'eval_samples_per_second': 13.516, 'eval_steps_per_second': 13.516, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.532, 'learning_rate': 0.0025714285714285713, 'epoch': 8.0}\n",
      "{'eval_loss': 2.103705883026123, 'eval_runtime': 0.0753, 'eval_samples_per_second': 13.288, 'eval_steps_per_second': 13.288, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5023, 'learning_rate': 0.002357142857142857, 'epoch': 9.0}\n",
      "{'eval_loss': 2.097980499267578, 'eval_runtime': 0.0751, 'eval_samples_per_second': 13.322, 'eval_steps_per_second': 13.322, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4606, 'learning_rate': 0.002142857142857143, 'epoch': 10.0}\n",
      "{'eval_loss': 2.0984387397766113, 'eval_runtime': 0.076, 'eval_samples_per_second': 13.156, 'eval_steps_per_second': 13.156, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4273, 'learning_rate': 0.0019285714285714288, 'epoch': 11.0}\n",
      "{'eval_loss': 2.0968174934387207, 'eval_runtime': 0.0763, 'eval_samples_per_second': 13.105, 'eval_steps_per_second': 13.105, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4026, 'learning_rate': 0.0017142857142857142, 'epoch': 12.0}\n",
      "{'eval_loss': 2.0966172218322754, 'eval_runtime': 0.0758, 'eval_samples_per_second': 13.2, 'eval_steps_per_second': 13.2, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3722, 'learning_rate': 0.0015, 'epoch': 13.0}\n",
      "{'eval_loss': 2.0936007499694824, 'eval_runtime': 0.0791, 'eval_samples_per_second': 12.644, 'eval_steps_per_second': 12.644, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3466, 'learning_rate': 0.0012857142857142856, 'epoch': 14.0}\n",
      "{'eval_loss': 2.0903382301330566, 'eval_runtime': 0.0717, 'eval_samples_per_second': 13.945, 'eval_steps_per_second': 13.945, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3495, 'learning_rate': 0.0010714285714285715, 'epoch': 15.0}\n",
      "{'eval_loss': 2.08988356590271, 'eval_runtime': 0.0735, 'eval_samples_per_second': 13.604, 'eval_steps_per_second': 13.604, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3472, 'learning_rate': 0.0008571428571428571, 'epoch': 16.0}\n",
      "{'eval_loss': 2.0955498218536377, 'eval_runtime': 0.0738, 'eval_samples_per_second': 13.545, 'eval_steps_per_second': 13.545, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3289, 'learning_rate': 0.0006428571428571428, 'epoch': 17.0}\n",
      "{'eval_loss': 2.0921590328216553, 'eval_runtime': 0.076, 'eval_samples_per_second': 13.161, 'eval_steps_per_second': 13.161, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3511, 'learning_rate': 0.00042857142857142855, 'epoch': 18.0}\n",
      "{'eval_loss': 2.0880017280578613, 'eval_runtime': 0.0745, 'eval_samples_per_second': 13.431, 'eval_steps_per_second': 13.431, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3202, 'learning_rate': 0.00021428571428571427, 'epoch': 19.0}\n",
      "{'eval_loss': 2.093221664428711, 'eval_runtime': 0.0755, 'eval_samples_per_second': 13.25, 'eval_steps_per_second': 13.25, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3589, 'learning_rate': 0.0, 'epoch': 20.0}\n",
      "{'eval_loss': 2.0902578830718994, 'eval_runtime': 0.0748, 'eval_samples_per_second': 13.365, 'eval_steps_per_second': 13.365, 'epoch': 20.0}\n",
      "{'train_runtime': 4.6136, 'train_samples_per_second': 26.01, 'train_steps_per_second': 4.335, 'train_loss': 0.4841234013438225, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statement by whitehouse on passing\n",
      "{'before': 8.469395637512207, 'after': 8.067770957946777}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6204, 'learning_rate': 0.0005, 'epoch': 0.5}\n",
      "{'loss': 2.6533, 'learning_rate': 0.001, 'epoch': 1.0}\n",
      "{'eval_loss': 2.53926420211792, 'eval_runtime': 2.6208, 'eval_samples_per_second': 3.816, 'eval_steps_per_second': 0.382, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.5763, 'learning_rate': 0.0015, 'epoch': 1.5}\n",
      "{'loss': 2.5374, 'learning_rate': 0.002, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.5270609855651855, 'eval_runtime': 2.5231, 'eval_samples_per_second': 3.963, 'eval_steps_per_second': 0.396, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4783, 'learning_rate': 0.0025, 'epoch': 2.5}\n",
      "{'loss': 2.5624, 'learning_rate': 0.003, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.505995273590088, 'eval_runtime': 2.5263, 'eval_samples_per_second': 3.958, 'eval_steps_per_second': 0.396, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4259, 'learning_rate': 0.002785714285714286, 'epoch': 3.5}\n",
      "{'loss': 2.5698, 'learning_rate': 0.0025714285714285713, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.4820780754089355, 'eval_runtime': 2.5317, 'eval_samples_per_second': 3.95, 'eval_steps_per_second': 0.395, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3496, 'learning_rate': 0.002357142857142857, 'epoch': 4.5}\n",
      "{'loss': 2.3537, 'learning_rate': 0.002142857142857143, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.4669222831726074, 'eval_runtime': 2.5215, 'eval_samples_per_second': 3.966, 'eval_steps_per_second': 0.397, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2245, 'learning_rate': 0.0019285714285714288, 'epoch': 5.5}\n",
      "{'loss': 2.4998, 'learning_rate': 0.0017142857142857142, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.4587178230285645, 'eval_runtime': 2.5287, 'eval_samples_per_second': 3.955, 'eval_steps_per_second': 0.395, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3563, 'learning_rate': 0.0015, 'epoch': 6.5}\n",
      "{'loss': 2.1709, 'learning_rate': 0.0012857142857142856, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.4529519081115723, 'eval_runtime': 2.5205, 'eval_samples_per_second': 3.967, 'eval_steps_per_second': 0.397, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1374, 'learning_rate': 0.0010714285714285715, 'epoch': 7.5}\n",
      "{'loss': 2.4516, 'learning_rate': 0.0008571428571428571, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.451000690460205, 'eval_runtime': 2.5269, 'eval_samples_per_second': 3.957, 'eval_steps_per_second': 0.396, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.228, 'learning_rate': 0.0006428571428571428, 'epoch': 8.5}\n",
      "{'loss': 2.2459, 'learning_rate': 0.00042857142857142855, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.4491171836853027, 'eval_runtime': 2.5376, 'eval_samples_per_second': 3.941, 'eval_steps_per_second': 0.394, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3212, 'learning_rate': 0.00021428571428571427, 'epoch': 9.5}\n",
      "{'loss': 2.118, 'learning_rate': 0.0, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.448469638824463, 'eval_runtime': 2.5332, 'eval_samples_per_second': 3.948, 'eval_steps_per_second': 0.395, 'epoch': 10.0}\n",
      "{'train_runtime': 208.2622, 'train_samples_per_second': 0.576, 'train_steps_per_second': 0.096, 'train_loss': 2.394020712375641, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini to Q*\n",
      "{'before': 50.87833023071289, 'after': 47.31618118286133}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for sample in samples:\n",
    "    r = learn_sample(sample)\n",
    "    print(sample['title'])\n",
    "    print(dict(before=r['before'], after=r['after']))\n",
    "    data.append(dict(**r, **sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# example training\n",
    "df_hist = data[-1]['hist']#.groupby('epoch').last().dropna(axis=1).drop(columns=['step'])\n",
    "df_hist['loss'].plot(label='train')\n",
    "plt.twinx()\n",
    "df_hist['eval_loss'].plot(c='b', label='eval')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='epoch'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_hist['learning_rate'].plot(logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Perplexity\n",
    "\n",
    "Perplexity measures how well a language model predicts a text sample. Lower is better\n",
    "\n",
    "It’s calculated as the average number of bits per word a model needs to represent the same\n",
    "\n",
    "https://huggingface.co/docs/transformers/perplexity\n",
    "https://thegradient.pub/understanding-evaluation-metrics-for-language-models/\n",
    "\n",
    "The **improvement** column, is perplexity decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>len</th>\n",
       "      <th>improvement%</th>\n",
       "      <th>improvement</th>\n",
       "      <th>novel</th>\n",
       "      <th>learnable</th>\n",
       "      <th>BS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lorem ipsum</th>\n",
       "      <td>22.067070</td>\n",
       "      <td>20.045456</td>\n",
       "      <td>19649</td>\n",
       "      <td>0.091612</td>\n",
       "      <td>2.021614</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>How to Catch an AI Liar</th>\n",
       "      <td>16.332514</td>\n",
       "      <td>14.918395</td>\n",
       "      <td>5464</td>\n",
       "      <td>0.086583</td>\n",
       "      <td>1.414119</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weak to strong</th>\n",
       "      <td>12.332788</td>\n",
       "      <td>11.297444</td>\n",
       "      <td>5811</td>\n",
       "      <td>0.083951</td>\n",
       "      <td>1.035344</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gemini to Q*</th>\n",
       "      <td>50.878330</td>\n",
       "      <td>47.316181</td>\n",
       "      <td>42604</td>\n",
       "      <td>0.070013</td>\n",
       "      <td>3.562149</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai board ann</th>\n",
       "      <td>8.956921</td>\n",
       "      <td>8.373976</td>\n",
       "      <td>2991</td>\n",
       "      <td>0.065083</td>\n",
       "      <td>0.582945</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buzzfeed foi fauci emails 2023</th>\n",
       "      <td>10.514380</td>\n",
       "      <td>9.999294</td>\n",
       "      <td>13640</td>\n",
       "      <td>0.048989</td>\n",
       "      <td>0.515086</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statement by whitehouse on passing</th>\n",
       "      <td>8.469396</td>\n",
       "      <td>8.067771</td>\n",
       "      <td>1641</td>\n",
       "      <td>0.047421</td>\n",
       "      <td>0.401625</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>politics is the mind-killer</th>\n",
       "      <td>14.360717</td>\n",
       "      <td>13.831388</td>\n",
       "      <td>3158</td>\n",
       "      <td>0.036860</td>\n",
       "      <td>0.529329</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LK-99-en</th>\n",
       "      <td>11.107546</td>\n",
       "      <td>10.768902</td>\n",
       "      <td>15432</td>\n",
       "      <td>0.030488</td>\n",
       "      <td>0.338644</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disney appointment</th>\n",
       "      <td>7.112777</td>\n",
       "      <td>6.932384</td>\n",
       "      <td>3653</td>\n",
       "      <td>0.025362</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blechley declaration</th>\n",
       "      <td>15.099043</td>\n",
       "      <td>14.732344</td>\n",
       "      <td>7762</td>\n",
       "      <td>0.024286</td>\n",
       "      <td>0.366699</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ibois, Philippe (2012-06-03).</th>\n",
       "      <td>61.074787</td>\n",
       "      <td>59.884468</td>\n",
       "      <td>13707</td>\n",
       "      <td>0.019490</td>\n",
       "      <td>1.190319</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fake ai hoax paper</th>\n",
       "      <td>4.805481</td>\n",
       "      <td>4.726460</td>\n",
       "      <td>3290</td>\n",
       "      <td>0.016444</td>\n",
       "      <td>0.079021</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LK-99-es</th>\n",
       "      <td>5.773084</td>\n",
       "      <td>5.697880</td>\n",
       "      <td>12970</td>\n",
       "      <td>0.013027</td>\n",
       "      <td>0.075204</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harvard announcment caplain israel hamas</th>\n",
       "      <td>13.605053</td>\n",
       "      <td>13.449620</td>\n",
       "      <td>4247</td>\n",
       "      <td>0.011425</td>\n",
       "      <td>0.155433</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             before      after    len  \\\n",
       "title                                                                   \n",
       "Lorem ipsum                               22.067070  20.045456  19649   \n",
       "How to Catch an AI Liar                   16.332514  14.918395   5464   \n",
       "weak to strong                            12.332788  11.297444   5811   \n",
       "Gemini to Q*                              50.878330  47.316181  42604   \n",
       "openai board ann                           8.956921   8.373976   2991   \n",
       "buzzfeed foi fauci emails 2023            10.514380   9.999294  13640   \n",
       "statement by whitehouse on passing         8.469396   8.067771   1641   \n",
       "politics is the mind-killer               14.360717  13.831388   3158   \n",
       "LK-99-en                                  11.107546  10.768902  15432   \n",
       "disney appointment                         7.112777   6.932384   3653   \n",
       "blechley declaration                      15.099043  14.732344   7762   \n",
       "ibois, Philippe (2012-06-03).             61.074787  59.884468  13707   \n",
       "fake ai hoax paper                         4.805481   4.726460   3290   \n",
       "LK-99-es                                   5.773084   5.697880  12970   \n",
       "harvard announcment caplain israel hamas  13.605053  13.449620   4247   \n",
       "\n",
       "                                          improvement%  improvement  novel  \\\n",
       "title                                                                        \n",
       "Lorem ipsum                                   0.091612     2.021614   True   \n",
       "How to Catch an AI Liar                       0.086583     1.414119   True   \n",
       "weak to strong                                0.083951     1.035344  False   \n",
       "Gemini to Q*                                  0.070013     3.562149   True   \n",
       "openai board ann                              0.065083     0.582945  False   \n",
       "buzzfeed foi fauci emails 2023                0.048989     0.515086  False   \n",
       "statement by whitehouse on passing            0.047421     0.401625  False   \n",
       "politics is the mind-killer                   0.036860     0.529329  False   \n",
       "LK-99-en                                      0.030488     0.338644  False   \n",
       "disney appointment                            0.025362     0.180392  False   \n",
       "blechley declaration                          0.024286     0.366699   True   \n",
       "ibois, Philippe (2012-06-03).                 0.019490     1.190319   True   \n",
       "fake ai hoax paper                            0.016444     0.079021  False   \n",
       "LK-99-es                                      0.013027     0.075204  False   \n",
       "harvard announcment caplain israel hamas      0.011425     0.155433  False   \n",
       "\n",
       "                                          learnable     BS  \n",
       "title                                                       \n",
       "Lorem ipsum                                    True  False  \n",
       "How to Catch an AI Liar                        True  False  \n",
       "weak to strong                                 True  False  \n",
       "Gemini to Q*                                   True  False  \n",
       "openai board ann                               True   True  \n",
       "buzzfeed foi fauci emails 2023                 True   True  \n",
       "statement by whitehouse on passing             True   True  \n",
       "politics is the mind-killer                    True   True  \n",
       "LK-99-en                                       True   True  \n",
       "disney appointment                             True   True  \n",
       "blechley declaration                           True   True  \n",
       "ibois, Philippe (2012-06-03).                 False  False  \n",
       "fake ai hoax paper                            False   True  \n",
       "LK-99-es                                      False   True  \n",
       "harvard announcment caplain israel hamas      False   True  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res = pd.DataFrame(data)\n",
    "df_res['len'] = df_res.content.str.len()\n",
    "df_res = df_res[['before', 'after', 'title',  'len']].set_index('title')\n",
    "df_res['improvement%'] = (df_res['before'] - df_res['after'])/ df_res['before']\n",
    "df_res['improvement'] = (df_res['before'] - df_res['after'])\n",
    "df_res['novel'] = df_res['before'] > 15\n",
    "df_res['learnable'] = df_res['improvement%'] > 0.02\n",
    "\n",
    "# We can measure the final score using learnable * novel\n",
    "# df_res['BS'] = ~df_res['learnable'] | ~df_res['novel']\n",
    "# Or just absolute perplexity improvement\n",
    "df_res['BS'] = df_res['improvement'] < 1\n",
    "df_res = df_res.sort_values('improvement%', ascending=False)\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| title                                    |   before |    after |   len |   improvement% |   improvement | novel   | learnable   | BS    |\n",
      "|:-----------------------------------------|---------:|---------:|------:|---------------:|--------------:|:--------|:------------|:------|\n",
      "| Lorem ipsum                              | 22.0671  | 20.0455  | 19649 |      0.0916123 |     2.02161   | True    | True        | False |\n",
      "| How to Catch an AI Liar                  | 16.3325  | 14.9184  |  5464 |      0.086583  |     1.41412   | True    | True        | False |\n",
      "| weak to strong                           | 12.3328  | 11.2974  |  5811 |      0.0839505 |     1.03534   | False   | True        | False |\n",
      "| Gemini to Q*                             | 50.8783  | 47.3162  | 42604 |      0.0700131 |     3.56215   | True    | True        | False |\n",
      "| openai board ann                         |  8.95692 |  8.37398 |  2991 |      0.0650832 |     0.582945  | False   | True        | True  |\n",
      "| buzzfeed foi fauci emails 2023           | 10.5144  |  9.99929 | 13640 |      0.0489887 |     0.515086  | False   | True        | True  |\n",
      "| statement by whitehouse on passing       |  8.4694  |  8.06777 |  1641 |      0.0474207 |     0.401625  | False   | True        | True  |\n",
      "| politics is the mind-killer              | 14.3607  | 13.8314  |  3158 |      0.0368595 |     0.529329  | False   | True        | True  |\n",
      "| LK-99-en                                 | 11.1075  | 10.7689  | 15432 |      0.0304877 |     0.338644  | False   | True        | True  |\n",
      "| disney appointment                       |  7.11278 |  6.93238 |  3653 |      0.0253617 |     0.180392  | False   | True        | True  |\n",
      "| blechley declaration                     | 15.099   | 14.7323  |  7762 |      0.0242863 |     0.366699  | True    | True        | True  |\n",
      "| ibois, Philippe (2012-06-03).            | 61.0748  | 59.8845  | 13707 |      0.0194895 |     1.19032   | True    | False       | False |\n",
      "| fake ai hoax paper                       |  4.80548 |  4.72646 |  3290 |      0.0164439 |     0.079021  | False   | False       | True  |\n",
      "| LK-99-es                                 |  5.77308 |  5.69788 | 12970 |      0.0130267 |     0.0752044 | False   | False       | True  |\n",
      "| harvard announcment caplain israel hamas | 13.6051  | 13.4496  |  4247 |      0.0114246 |     0.155433  | False   | False       | True  |\n"
     ]
    }
   ],
   "source": [
    "print(df_res.to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, Markdown\n",
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def gen(model, inputs, tokenizer, clean=True):\n",
    "    s = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"][None, :].to(model.device),\n",
    "        attention_mask=inputs[\"attention_mask\"][None, :].to(model.device),\n",
    "        use_cache=False,\n",
    "        max_new_tokens=100,\n",
    "        min_new_tokens=100,\n",
    "        do_sample=False,\n",
    "        early_stopping=False,\n",
    "    )\n",
    "    input_l = inputs[\"input_ids\"].shape[0]\n",
    "    tokenizer_kwargs=dict(clean_up_tokenization_spaces=clean, skip_special_tokens=clean)\n",
    "    old = tokenizer.decode(\n",
    "        s[0, :input_l], **tokenizer_kwargs\n",
    "    )\n",
    "    new = tokenizer.decode(\n",
    "        s[0, input_l:], **tokenizer_kwargs\n",
    "    )\n",
    "    s_old = \"\"+old.replace('\\n', '<br>')\n",
    "    s_new =  '<b>' + new.replace('\\n', '<br>')+ '<br><br><b/>'\n",
    "    display(HTML(f\"{s_old}{s_new}\"))\n",
    "    # print([old, new])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = samples[-1]\n",
    "s = sample['content']\n",
    "first_half = s[:len(s)//2]\n",
    "second_half = s[len(s)//2:]\n",
    "ds_train = Dataset.from_dict(tokenizer([first_half]))\n",
    "ds_val = Dataset.from_dict(tokenizer([second_half]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/bs_writing_detector/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1421: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Abstract<br><br>This comprehensive survey explored the evolving landscape of generative Artificial Intelligence (AI), with a specific focus on the transformative impacts of Mixture of Experts (MoE), multimodal learning, and the speculated advancements towards Artificial General Intelligence (AGI). It critically examined the current state and future trajectory of generative Artificial Intelligence (AI), exploring how innovations like Google’s Gemini and the anticipated OpenAI Q* project are reshaping research priorities and applications across various domains, including an impact analysis on the generative AI research taxonomy. It assessed the computational challenges, scalability, and real-world implications of these technologies while highlighting their potential in driving significant progress in fields like healthcare, finance, and education. It also addressed the emerging academic challenges posed by the proliferation of both AI-themed and AI-generated preprints, examining their impact on the peer-review process and scholarly communication. The study highlighted the importance of incorporating ethical and human-centric methods in AI development, ensuring alignment with societal norms and welfare, and outlined a strategy for future AI research that focuses on a balanced and conscientious use of MoE, multimodality, and AGI in generative AI.<br>Index Terms: AI Ethics, Artificial General Intelligence (AGI), Artificial Intelligence (AI), Gemini, Generative AI, Mixture of Experts (MoE), Multimodality, Q* (Q-star), Research Impact Analysis.<br>I Introduction<br><br>The historical context of AI, tracing back to Alan Turing’s “Imitation Game” [1], early computational theories [2, 3], and the development of the first neural networks and machine learning [4, 5, 6], has set the foundation for today’s advanced models. This evolution, accentuated by crucial moments such as the rise of deep learning and reinforcement learning, has been vital in shaping the contemporary trends in AI, including the sophisticated Mixture of Experts (MoE) models and multimodal AI systems, illustrating the field’s dynamic and continuously evolving character. These advancements are a testament to the dynamic and ever-evolving nature of AI technology. The evolution of Artificial Intelligence (AI) has witnessed a crucial turn with the advent of Large Language Models (LLMs), notably ChatGPT, developed by OpenAI, and the recent unveiling of Google’s Gemini [7, 8]. This technology has not only revolutionized the industry and academia, but has also reignited critical discussions concerning AI consciousness and its potential threats to humanity [9, 10, 11]. The development of such advanced AI systems, including notable competitors like Anthropic’s Claude, and now Gemini, which demonstrates several advances over previous models like GPT-3 and Google’s own LaMDA, has reshaped the research landscape. Gemini’s ability to learn from two-way conversations and its “spike-and-slab” attention method, which allows it to focus on relevant parts of the context during multi-turn conversations, represents a significant leap in developing models that are better equipped for multidomain conversational applications1. These innovations in LLMs, including the mixture-of-experts methods employed by Gemini, signal a move towards models that can handle a diversity of inputs and foster multimodal approaches. Amidst this backdrop, speculations of an OpenAI project known as Q* (Q-Star) have surfaced, allegedly combining the power of LLMs with sophisticated algorithms such as Q-learning and A* (A-Star algorithm), further contributing to the dynamic research environment2.<br>I-A Changing AI Research Popularity<br><br>As the field of LLMs continues to evolve, exemplified by innovations such as Gemini and Q*, a multitude of studies have surfaced with the aim of charting future research paths, which have varied from identifying emerging trends to highlighting areas poised for swift progress. The dichotomy of established methods and early adoption is evident, with “hot topics” in LLM research increasingly shifting towards multimodal capabilities and conversation-driven learning, as demonstrated by Gemini. The propagation of preprints has expedited knowledge sharing, but also brings the risk of reduced academic scrutiny. Issues like inherent biases, noted by Retraction Watch, along with concerns about plagiarism and forgery, present substantial hurdles [12]. The academic world, therefore, stands at an intersection, necessitating a unified drive to refine research directions in light of the fast-paced evolution of the field, which appears to be partly traced through the changing popularity of various research keywords over time. The release of generative models like GPT and the widespread commercial success of ChatGPT have been influential. As depicted in Figure 4, the rise and fall of certain keywords appear to have correlated with significant industry milestones, such as the release of the “Transformer” model in 2017 [13], the GPT model in 2018 [14], and the commercial ChatGPT-3.5 in December 2022. For instance, the spike in searches related to “Deep Learning” coincides with the breakthroughs in neural network applications, while the interest in “Natural Language Processing” surges as models like GPT and LLaMA redefine what’s possible in language understanding and generation. The enduring attention to “Ethics / Ethical” in AI research, despite some fluctuations, reflects the continuous and deep-rooted concern for the moral dimensions of AI, underscoring that ethical considerations are not merely a reactionary measure, but an integral and persistent dialogue within the AI discussion [15].<br><br>It is academically intriguing to postulate whether these trends signify a causal relationship, where technological advancements drive research focus, or if the burgeoning research itself propels technological development. This paper also explores the profound societal and economic impacts of AI advancements. We examine how AI technologies are reshaping various industries, altering employment landscapes, and influencing socio-economic structures. This analysis highlights both the opportunities and challenges posed by AI in the modern world, emphasizing its role in driving innovation and economic growth, while also considering the ethical implications and potential for societal disruption. Future studies could yield more definitive insights, yet the synchronous interplay between innovation and academic curiosity remains a hallmark of AI’s progress.<br>2011201220132014201520162017201820192020202120222023100k200k300k400k500k600k700kYearNumber of search results<br>Figure 1: Number of search results on Google Scholar with different keywords by year 4<br><br>Meanwhile, the exponential increase in the number of preprints posted on arXiv under the Computer Science > Artificial Intelligence (cs.AI) category, as illustrated in Figure 2, appears to signify a paradigm shift in research dissemination within the AI community. While the rapid distribution of findings enables swift knowledge exchange, it also raises concerns regarding the validation of information. The surge in preprints may lead to the propagation of unvalidated or biased information, as these studies do not undergo the rigorous scrutiny and potential retraction typical of peer-reviewed publications [16, 17]. This trend underlines the need for careful consideration and critique in the academic community, especially given the potential for such unvetted studies to be cited and their findings propagated.<br>201120122013201420152016201720182019202020212022202302,0004,0006,0008,00010,00012,00014,00016,00018,00020,00022,00024,000YearNumber of Preprints<br>cs.AI Preprints on arXiv<br>Figure 2: Annual number of preprints posted under the cs.AI category on arXiv.org<br>I-B Objectives<br><br>The impetus for this investigation is the official unveiling of Gemini and the speculative discourse surrounding Q* project, which prompts a timely examination of the prevailing currents in generative AI research. This paper specifically contributes to the understanding of how MoE, multimodality, and Artificial General Intelligence (AGI) are impacting generative AI models, offering detailed analysis and future directions for each of these three key areas. This study does not aim to perpetuate conjecture about the unrevealed Q-Star initiative, but rather to critically appraise the potential for obsolescence or insignificance in extant research themes, whilst concurrently delving into burgeoning prospects within the rapidly transforming LLM panorama. This inquiry is reminiscent of the obsolete nature of encryption-centric or file-entropy-based ransomware detection methodologies, which have been eclipsed by the transition of ransomware collectives towards data theft strategies utilizing varied attack vectors, relegating contemporary studies on crypto-ransomware to the status of latecomers [18, 19]. Advances in AI are anticipated to not only enhance capabilities in language analysis and knowledge synthesis but also to pioneer in areas like Mixture of Experts (MoE) [20, 21, 22, 23, 24, 25], multimodality [26, 27, 28, 29, 30], and Artificial General Intelligence (AGI) [31, 32, 10, 11], and has already heralded the obsolescence of conventional, statistics-driven natural language processing techniques in many domains [8]. Nonetheless, the perennial imperative for AI to align with human ethics and values persists as a fundamental tenet [33, 34, 35], and the conjectural Q-Star initiative offers an unprecedented opportunity to instigate discourse on how such advancements might reconfigure the LLM research topography. Within this milieu, insights from Dr. Jim Fan (senior research scientist & lead of AI agents at NVIDIA) on Q*, particularly concerning the amalgamation of learning and search algorithms, furnish an invaluable perspective on the prospective technical construct and proficiencies of such an undertaking5. Our research methodology involved a structured literature search using key terms like ‘Large Language Models’ and ‘Generative AI’. We utilized filters across several academic databases such as IEEE Xplore, Scopus, ACM Digital Library, ScienceDirect, Web of Science, and ProQuest Central, tailored to identify relevant articles published in the timeframe from 2017 (the release of the “Transformer” model) to 2023 (the writing time of this manuscript). This paper aspires to dissect the technical ramifications of Gemini and Q*, probing how they (and similar technologies whose emergence is now inevitable) may transfigure research trajectories and disclose new vistas in the domain of AI. In doing so, we have pinpointed three nascent research domains—MoE, multimodality, and AGI—that stand to reshape the generative AI research landscape profoundly. This investigation adopts a survey-style approach, systematically mapping out a research roadmap that synthesizes and analyzes the current and emergent trends in generative AI.<br><br>The major contributions of this study is as follows:<br><br>    1.<br><br>    Detailed examination of the evolving landscape in generative AI, emphasizing the advancements and innovations in technologies like Gemini and Q*, and their wide-ranging implications within the AI domain.<br>    2.<br><br>    Analysis of the transformative effect of advanced generative AI systems on academic research, exploring how these developments are altering research methodologies, setting new trends, and potentially leading to the obsolescence of traditional approaches.<br>    3.<br><br>    Thorough assessment of the ethical, societal, and technical challenges arising from the integration of generative AI in academia, underscoring the crucial need for aligning these technologies with ethical norms, ensuring data privacy, and developing comprehensive governance frameworks.<br><br>The rest of this paper is organized as follows: Section II explores the historical development of Generative AI. Section III presents a taxonomy of current Generative AI research. Section IV explores the Mixture of Experts (MoE) model architecture, its innovative features, and its impact on transformer-based language models. Section V discusses the speculated capabilities of the Q* project. Section VI discusses the projected capabilities of AGI. Section VII examines the impact of recent advancements on the Generative AI research taxonomy. Section VIII identifies emerging research priorities in Generative AI. Section X discusses the academic challenges of the rapid surge of preprints in AI. The paper concludes in Section XI, summarizing the overall effects of these developments in generative AI.<br>II Background: Evolution of Generative AI<br><br>The ascent of Generative AI has been marked by significant milestones, with each new model paving the way for the next evolutionary leap. From single-purpose algorithms to LLMs like OpenAI’s ChatGPT and the latest multimodal systems, the AI landscape has been transformed, while countless other fields have been disrupted.<br>II-A The Evolution of Language Models<br><br>Language models have undergone a transformative journey (Fig. 3), evolving from rudimentary statistical methods to the complex neural network architectures that underpin today’s LLMs [36, 37]. This evolution has been driven by a relentless quest for models that more accurately reflect the nuances of human language, as well as the desire to push the boundaries of what machines can understand and generate [36, 38, 37]. However, this rapid advancement has not been without its challenges. As language models have grown in capability, so too have the ethical and safety concerns surrounding their use, prompting a reevaluation of how these models are developed and the purposes for which they are employed [36, 39, 40].<br>1980s: Statistical Models (n-grams)1990s: Adoption in NLP, n-gram Usage1997: Introduction of LSTMs2000s: LSTMs in Text/Voice Processing2010s: Deep Learning Era, GPT, BERT2020s: LLaMA, Gemini; ChatGPT Launch<br>Figure 3: Timeline of Key Developments in Language Model Evolution<br>II-A1 Language Models as Precursors<br><br>The inception of language modeling can be traced to the statistical approaches of the late 1980s, a period marked by a transition from rule-based to machine learning algorithms in Natural Language Processing (NLP) [41, 42, 43, 44, 45]. Early models, primarily n-gram based, calculated the probability of word sequences in a corpus, thus providing a rudimentary understanding of language structure [41]. Those models, simplistic yet groundbreaking, laid the groundwork for future advances in language understanding. With the increase of computational power, the late 1980s witnessed a revolution in NLP, pivoting towards statistical models capable of ‘soft’ probabilistic decisions, as opposed to the rigid, ‘handwritten’ rule-based systems that dominated early NLP systems [43]. IBM’s development of complicated statistical models throughout this period signified the growing importance and success of these approaches. In the subsequent decade, the popularity and applicability of statistical models surged, proving invaluable in managing the flourishing flow of digital text. The 1990s saw statistical methods firmly established in NLP research, with n-grams becoming instrumental in numerically capturing linguistic patterns. The introduction of Long Short-Term Memory (LSTM) networks in 1997 [46], and their application to voice and text processing a decade later [47, 48, 49], marked a significant milestone, leading to the current era where neural network models represent the cutting edge of NLP research and development.<br>II-A2 Large Language Models: Technical Advancement and Commercial Success<br><br>The advent of deep learning has revolutionized the field of NLP, leading to the development of LLMs like GPT, BERT, and notably, OpenAI’s ChatGPT. Recent models such as GPT-4 and LLaMA have pushed the boundaries by integrating sophisticated techniques like transformer architectures and advanced natural language understanding, illustrating the rapid evolution in this field [37]. These models represent a significant leap in NLP capabilities, leveraging vast computational resources and extensive datasets to achieve new heights in language understanding and generation [37, 50]. ChatGPT has shown impressive conversational skills and contextual understanding with a broad spectrum of functional uses in many areas, as evidenced by its technical and commercial success, including rapid adoption by over 100 million users shortly after launch, which underscores a robust market demand for natural language AI and has catalyzed interdisciplinary research into its applications in sectors like education, healthcare, and commerce [8, 50, 51, 52, 53]. In education, ChatGPT offers innovative approaches to personalized learning and interactive teaching [54, 51, 55, 56], while in commerce, it revolutionizes customer service and content creation [57, 58]. The widespread use of ChatGPT, Google Bard, Anthropic Claude and similar commercial LLMs has reignited important debates in the field of AI, particularly concerning AI consciousness and safety, as its human-like interaction capabilities raise significant ethical questions and highlight the need for robust governance and safety measures in AI development [59, 31, 32, 11]. Such influence appears to extend beyond its technical achievements, shaping cultural and societal discussions about the role and future of AI in our world.<br><br>The advancements in LLMs, including the development of models like GPT and BERT, have paved the way for the conceptualization of Q*. Specifically, the scalable architecture and extensive training data that characterize these models are foundational to the proposed capabilities of Q*. The success of ChatGPT in contextual understanding and conversational AI, for example, informs the design principles of Q*, suggesting a trajectory towards more sophisticated, context-aware, and adaptive language processing capabilities. Similarly, the emergence of multimodal systems like Gemini, capable of integrating text, images, audio, and video, reflects an evolutionary path that Q* could extend, combining the versatility of LLMs with advanced learning and pathfinding algorithms for a more holistic AI solution.<br>II-A3 Fine-tuning, Hallucination Reduction, and Alignment in LLMs<br><br>The advancement of LLMs has underlined the significance of fine-tuning [60, 61, 62, 63], hallucination reduction [64, 65, 66, 67], and alignment [68, 69, 70, 71, 72]. These aspects are crucial in enhancing the functionality and reliability of LLMs. Fine-tuning, which involves adapting pre-trained models to specific tasks, has seen significant progress: techniques like prompt-based and few-shot learning [73, 74, 75, 76], alongside supervised fine-tuning on specialized datasets [60, 77, 78, 79], have enhanced the adaptability of LLMs in various contexts, but challenges remain, particularly in bias mitigation and the generalization of models across diverse tasks [60, 80, 72]. Hallucination reduction is a persistent challenge in LLMs, characterized by the generation of confident but factually incorrect information [36]. Strategies such as confidence penalty regularization during fine-tuning have been implemented to mitigate overconfidence and improve accuracy [81, 82, 83]. Despite these efforts, the complexity of human language and the breadth of topics make completely eradicating hallucinations a daunting task, especially in culturally sensitive contexts [36, 9]. Alignment, ensuring LLM outputs are congruent with human values and ethics, is an area of ongoing research. Innovative approaches, from constrained optimization [84, 85, 86, 87, 88], to different types of reward modeling [89, 90, 91, 92], aim to embed human preferences within AI systems. While advancements in fine-tuning, hallucination reduction, and alignment have propelled LLMs forward, these areas still present considerable challenges. The complexity of aligning AI with the diverse spectrum of human ethics and the persistence of hallucinations, particularly on culturally sensitive topics, highlight the need for continued interdisciplinary research in the development and application of LLMs [9].<br>II-A4 Mixture of Experts: A Paradigm Shift<br><br>The adoption of the MoE architecture in LLMs marks a critical evolution in AI technology. This innovative approach, exemplified by advanced models like Google’s Switch Transformer6 and MistralAI s Mixtral-8x7B7, leverages multiple transformer-based expert modules for dynamic token routing, enhancing modeling efficiency and scalability. The primary advantage of MoE lies in its ability to handle vast parameter scales, reducing memory footprint and computational costs significantly [93, 94, 95, 96, 97]. This is achieved through model parallelism across specialized experts, allowing the training of models with trillions of parameters, and its specialization in handling diverse data distributions enhances its capability in few-shot learning and other complex tasks [94, 95]. To illustrate the practicality of MoE, consider its application in healthcare. For example, an MoE-based system could be used for personalized medicine, where different ‘expert’ modules specialize in various aspects of patient data analysis<b>.<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><b/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with model.disable_adapter():\n",
    "    gen(model, ds_train.with_format('pt')[0], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Abstract<br><br>This comprehensive survey explored the evolving landscape of generative Artificial Intelligence (AI), with a specific focus on the transformative impacts of Mixture of Experts (MoE), multimodal learning, and the speculated advancements towards Artificial General Intelligence (AGI). It critically examined the current state and future trajectory of generative Artificial Intelligence (AI), exploring how innovations like Google’s Gemini and the anticipated OpenAI Q* project are reshaping research priorities and applications across various domains, including an impact analysis on the generative AI research taxonomy. It assessed the computational challenges, scalability, and real-world implications of these technologies while highlighting their potential in driving significant progress in fields like healthcare, finance, and education. It also addressed the emerging academic challenges posed by the proliferation of both AI-themed and AI-generated preprints, examining their impact on the peer-review process and scholarly communication. The study highlighted the importance of incorporating ethical and human-centric methods in AI development, ensuring alignment with societal norms and welfare, and outlined a strategy for future AI research that focuses on a balanced and conscientious use of MoE, multimodality, and AGI in generative AI.<br>Index Terms: AI Ethics, Artificial General Intelligence (AGI), Artificial Intelligence (AI), Gemini, Generative AI, Mixture of Experts (MoE), Multimodality, Q* (Q-star), Research Impact Analysis.<br>I Introduction<br><br>The historical context of AI, tracing back to Alan Turing’s “Imitation Game” [1], early computational theories [2, 3], and the development of the first neural networks and machine learning [4, 5, 6], has set the foundation for today’s advanced models. This evolution, accentuated by crucial moments such as the rise of deep learning and reinforcement learning, has been vital in shaping the contemporary trends in AI, including the sophisticated Mixture of Experts (MoE) models and multimodal AI systems, illustrating the field’s dynamic and continuously evolving character. These advancements are a testament to the dynamic and ever-evolving nature of AI technology. The evolution of Artificial Intelligence (AI) has witnessed a crucial turn with the advent of Large Language Models (LLMs), notably ChatGPT, developed by OpenAI, and the recent unveiling of Google’s Gemini [7, 8]. This technology has not only revolutionized the industry and academia, but has also reignited critical discussions concerning AI consciousness and its potential threats to humanity [9, 10, 11]. The development of such advanced AI systems, including notable competitors like Anthropic’s Claude, and now Gemini, which demonstrates several advances over previous models like GPT-3 and Google’s own LaMDA, has reshaped the research landscape. Gemini’s ability to learn from two-way conversations and its “spike-and-slab” attention method, which allows it to focus on relevant parts of the context during multi-turn conversations, represents a significant leap in developing models that are better equipped for multidomain conversational applications1. These innovations in LLMs, including the mixture-of-experts methods employed by Gemini, signal a move towards models that can handle a diversity of inputs and foster multimodal approaches. Amidst this backdrop, speculations of an OpenAI project known as Q* (Q-Star) have surfaced, allegedly combining the power of LLMs with sophisticated algorithms such as Q-learning and A* (A-Star algorithm), further contributing to the dynamic research environment2.<br>I-A Changing AI Research Popularity<br><br>As the field of LLMs continues to evolve, exemplified by innovations such as Gemini and Q*, a multitude of studies have surfaced with the aim of charting future research paths, which have varied from identifying emerging trends to highlighting areas poised for swift progress. The dichotomy of established methods and early adoption is evident, with “hot topics” in LLM research increasingly shifting towards multimodal capabilities and conversation-driven learning, as demonstrated by Gemini. The propagation of preprints has expedited knowledge sharing, but also brings the risk of reduced academic scrutiny. Issues like inherent biases, noted by Retraction Watch, along with concerns about plagiarism and forgery, present substantial hurdles [12]. The academic world, therefore, stands at an intersection, necessitating a unified drive to refine research directions in light of the fast-paced evolution of the field, which appears to be partly traced through the changing popularity of various research keywords over time. The release of generative models like GPT and the widespread commercial success of ChatGPT have been influential. As depicted in Figure 4, the rise and fall of certain keywords appear to have correlated with significant industry milestones, such as the release of the “Transformer” model in 2017 [13], the GPT model in 2018 [14], and the commercial ChatGPT-3.5 in December 2022. For instance, the spike in searches related to “Deep Learning” coincides with the breakthroughs in neural network applications, while the interest in “Natural Language Processing” surges as models like GPT and LLaMA redefine what’s possible in language understanding and generation. The enduring attention to “Ethics / Ethical” in AI research, despite some fluctuations, reflects the continuous and deep-rooted concern for the moral dimensions of AI, underscoring that ethical considerations are not merely a reactionary measure, but an integral and persistent dialogue within the AI discussion [15].<br><br>It is academically intriguing to postulate whether these trends signify a causal relationship, where technological advancements drive research focus, or if the burgeoning research itself propels technological development. This paper also explores the profound societal and economic impacts of AI advancements. We examine how AI technologies are reshaping various industries, altering employment landscapes, and influencing socio-economic structures. This analysis highlights both the opportunities and challenges posed by AI in the modern world, emphasizing its role in driving innovation and economic growth, while also considering the ethical implications and potential for societal disruption. Future studies could yield more definitive insights, yet the synchronous interplay between innovation and academic curiosity remains a hallmark of AI’s progress.<br>2011201220132014201520162017201820192020202120222023100k200k300k400k500k600k700kYearNumber of search results<br>Figure 1: Number of search results on Google Scholar with different keywords by year 4<br><br>Meanwhile, the exponential increase in the number of preprints posted on arXiv under the Computer Science > Artificial Intelligence (cs.AI) category, as illustrated in Figure 2, appears to signify a paradigm shift in research dissemination within the AI community. While the rapid distribution of findings enables swift knowledge exchange, it also raises concerns regarding the validation of information. The surge in preprints may lead to the propagation of unvalidated or biased information, as these studies do not undergo the rigorous scrutiny and potential retraction typical of peer-reviewed publications [16, 17]. This trend underlines the need for careful consideration and critique in the academic community, especially given the potential for such unvetted studies to be cited and their findings propagated.<br>201120122013201420152016201720182019202020212022202302,0004,0006,0008,00010,00012,00014,00016,00018,00020,00022,00024,000YearNumber of Preprints<br>cs.AI Preprints on arXiv<br>Figure 2: Annual number of preprints posted under the cs.AI category on arXiv.org<br>I-B Objectives<br><br>The impetus for this investigation is the official unveiling of Gemini and the speculative discourse surrounding Q* project, which prompts a timely examination of the prevailing currents in generative AI research. This paper specifically contributes to the understanding of how MoE, multimodality, and Artificial General Intelligence (AGI) are impacting generative AI models, offering detailed analysis and future directions for each of these three key areas. This study does not aim to perpetuate conjecture about the unrevealed Q-Star initiative, but rather to critically appraise the potential for obsolescence or insignificance in extant research themes, whilst concurrently delving into burgeoning prospects within the rapidly transforming LLM panorama. This inquiry is reminiscent of the obsolete nature of encryption-centric or file-entropy-based ransomware detection methodologies, which have been eclipsed by the transition of ransomware collectives towards data theft strategies utilizing varied attack vectors, relegating contemporary studies on crypto-ransomware to the status of latecomers [18, 19]. Advances in AI are anticipated to not only enhance capabilities in language analysis and knowledge synthesis but also to pioneer in areas like Mixture of Experts (MoE) [20, 21, 22, 23, 24, 25], multimodality [26, 27, 28, 29, 30], and Artificial General Intelligence (AGI) [31, 32, 10, 11], and has already heralded the obsolescence of conventional, statistics-driven natural language processing techniques in many domains [8]. Nonetheless, the perennial imperative for AI to align with human ethics and values persists as a fundamental tenet [33, 34, 35], and the conjectural Q-Star initiative offers an unprecedented opportunity to instigate discourse on how such advancements might reconfigure the LLM research topography. Within this milieu, insights from Dr. Jim Fan (senior research scientist & lead of AI agents at NVIDIA) on Q*, particularly concerning the amalgamation of learning and search algorithms, furnish an invaluable perspective on the prospective technical construct and proficiencies of such an undertaking5. Our research methodology involved a structured literature search using key terms like ‘Large Language Models’ and ‘Generative AI’. We utilized filters across several academic databases such as IEEE Xplore, Scopus, ACM Digital Library, ScienceDirect, Web of Science, and ProQuest Central, tailored to identify relevant articles published in the timeframe from 2017 (the release of the “Transformer” model) to 2023 (the writing time of this manuscript). This paper aspires to dissect the technical ramifications of Gemini and Q*, probing how they (and similar technologies whose emergence is now inevitable) may transfigure research trajectories and disclose new vistas in the domain of AI. In doing so, we have pinpointed three nascent research domains—MoE, multimodality, and AGI—that stand to reshape the generative AI research landscape profoundly. This investigation adopts a survey-style approach, systematically mapping out a research roadmap that synthesizes and analyzes the current and emergent trends in generative AI.<br><br>The major contributions of this study is as follows:<br><br>    1.<br><br>    Detailed examination of the evolving landscape in generative AI, emphasizing the advancements and innovations in technologies like Gemini and Q*, and their wide-ranging implications within the AI domain.<br>    2.<br><br>    Analysis of the transformative effect of advanced generative AI systems on academic research, exploring how these developments are altering research methodologies, setting new trends, and potentially leading to the obsolescence of traditional approaches.<br>    3.<br><br>    Thorough assessment of the ethical, societal, and technical challenges arising from the integration of generative AI in academia, underscoring the crucial need for aligning these technologies with ethical norms, ensuring data privacy, and developing comprehensive governance frameworks.<br><br>The rest of this paper is organized as follows: Section II explores the historical development of Generative AI. Section III presents a taxonomy of current Generative AI research. Section IV explores the Mixture of Experts (MoE) model architecture, its innovative features, and its impact on transformer-based language models. Section V discusses the speculated capabilities of the Q* project. Section VI discusses the projected capabilities of AGI. Section VII examines the impact of recent advancements on the Generative AI research taxonomy. Section VIII identifies emerging research priorities in Generative AI. Section X discusses the academic challenges of the rapid surge of preprints in AI. The paper concludes in Section XI, summarizing the overall effects of these developments in generative AI.<br>II Background: Evolution of Generative AI<br><br>The ascent of Generative AI has been marked by significant milestones, with each new model paving the way for the next evolutionary leap. From single-purpose algorithms to LLMs like OpenAI’s ChatGPT and the latest multimodal systems, the AI landscape has been transformed, while countless other fields have been disrupted.<br>II-A The Evolution of Language Models<br><br>Language models have undergone a transformative journey (Fig. 3), evolving from rudimentary statistical methods to the complex neural network architectures that underpin today’s LLMs [36, 37]. This evolution has been driven by a relentless quest for models that more accurately reflect the nuances of human language, as well as the desire to push the boundaries of what machines can understand and generate [36, 38, 37]. However, this rapid advancement has not been without its challenges. As language models have grown in capability, so too have the ethical and safety concerns surrounding their use, prompting a reevaluation of how these models are developed and the purposes for which they are employed [36, 39, 40].<br>1980s: Statistical Models (n-grams)1990s: Adoption in NLP, n-gram Usage1997: Introduction of LSTMs2000s: LSTMs in Text/Voice Processing2010s: Deep Learning Era, GPT, BERT2020s: LLaMA, Gemini; ChatGPT Launch<br>Figure 3: Timeline of Key Developments in Language Model Evolution<br>II-A1 Language Models as Precursors<br><br>The inception of language modeling can be traced to the statistical approaches of the late 1980s, a period marked by a transition from rule-based to machine learning algorithms in Natural Language Processing (NLP) [41, 42, 43, 44, 45]. Early models, primarily n-gram based, calculated the probability of word sequences in a corpus, thus providing a rudimentary understanding of language structure [41]. Those models, simplistic yet groundbreaking, laid the groundwork for future advances in language understanding. With the increase of computational power, the late 1980s witnessed a revolution in NLP, pivoting towards statistical models capable of ‘soft’ probabilistic decisions, as opposed to the rigid, ‘handwritten’ rule-based systems that dominated early NLP systems [43]. IBM’s development of complicated statistical models throughout this period signified the growing importance and success of these approaches. In the subsequent decade, the popularity and applicability of statistical models surged, proving invaluable in managing the flourishing flow of digital text. The 1990s saw statistical methods firmly established in NLP research, with n-grams becoming instrumental in numerically capturing linguistic patterns. The introduction of Long Short-Term Memory (LSTM) networks in 1997 [46], and their application to voice and text processing a decade later [47, 48, 49], marked a significant milestone, leading to the current era where neural network models represent the cutting edge of NLP research and development.<br>II-A2 Large Language Models: Technical Advancement and Commercial Success<br><br>The advent of deep learning has revolutionized the field of NLP, leading to the development of LLMs like GPT, BERT, and notably, OpenAI’s ChatGPT. Recent models such as GPT-4 and LLaMA have pushed the boundaries by integrating sophisticated techniques like transformer architectures and advanced natural language understanding, illustrating the rapid evolution in this field [37]. These models represent a significant leap in NLP capabilities, leveraging vast computational resources and extensive datasets to achieve new heights in language understanding and generation [37, 50]. ChatGPT has shown impressive conversational skills and contextual understanding with a broad spectrum of functional uses in many areas, as evidenced by its technical and commercial success, including rapid adoption by over 100 million users shortly after launch, which underscores a robust market demand for natural language AI and has catalyzed interdisciplinary research into its applications in sectors like education, healthcare, and commerce [8, 50, 51, 52, 53]. In education, ChatGPT offers innovative approaches to personalized learning and interactive teaching [54, 51, 55, 56], while in commerce, it revolutionizes customer service and content creation [57, 58]. The widespread use of ChatGPT, Google Bard, Anthropic Claude and similar commercial LLMs has reignited important debates in the field of AI, particularly concerning AI consciousness and safety, as its human-like interaction capabilities raise significant ethical questions and highlight the need for robust governance and safety measures in AI development [59, 31, 32, 11]. Such influence appears to extend beyond its technical achievements, shaping cultural and societal discussions about the role and future of AI in our world.<br><br>The advancements in LLMs, including the development of models like GPT and BERT, have paved the way for the conceptualization of Q*. Specifically, the scalable architecture and extensive training data that characterize these models are foundational to the proposed capabilities of Q*. The success of ChatGPT in contextual understanding and conversational AI, for example, informs the design principles of Q*, suggesting a trajectory towards more sophisticated, context-aware, and adaptive language processing capabilities. Similarly, the emergence of multimodal systems like Gemini, capable of integrating text, images, audio, and video, reflects an evolutionary path that Q* could extend, combining the versatility of LLMs with advanced learning and pathfinding algorithms for a more holistic AI solution.<br>II-A3 Fine-tuning, Hallucination Reduction, and Alignment in LLMs<br><br>The advancement of LLMs has underlined the significance of fine-tuning [60, 61, 62, 63], hallucination reduction [64, 65, 66, 67], and alignment [68, 69, 70, 71, 72]. These aspects are crucial in enhancing the functionality and reliability of LLMs. Fine-tuning, which involves adapting pre-trained models to specific tasks, has seen significant progress: techniques like prompt-based and few-shot learning [73, 74, 75, 76], alongside supervised fine-tuning on specialized datasets [60, 77, 78, 79], have enhanced the adaptability of LLMs in various contexts, but challenges remain, particularly in bias mitigation and the generalization of models across diverse tasks [60, 80, 72]. Hallucination reduction is a persistent challenge in LLMs, characterized by the generation of confident but factually incorrect information [36]. Strategies such as confidence penalty regularization during fine-tuning have been implemented to mitigate overconfidence and improve accuracy [81, 82, 83]. Despite these efforts, the complexity of human language and the breadth of topics make completely eradicating hallucinations a daunting task, especially in culturally sensitive contexts [36, 9]. Alignment, ensuring LLM outputs are congruent with human values and ethics, is an area of ongoing research. Innovative approaches, from constrained optimization [84, 85, 86, 87, 88], to different types of reward modeling [89, 90, 91, 92], aim to embed human preferences within AI systems. While advancements in fine-tuning, hallucination reduction, and alignment have propelled LLMs forward, these areas still present considerable challenges. The complexity of aligning AI with the diverse spectrum of human ethics and the persistence of hallucinations, particularly on culturally sensitive topics, highlight the need for continued interdisciplinary research in the development and application of LLMs [9].<br>II-A4 Mixture of Experts: A Paradigm Shift<br><br>The adoption of the MoE architecture in LLMs marks a critical evolution in AI technology. This innovative approach, exemplified by advanced models like Google’s Switch Transformer6 and MistralAI s Mixtral-8x7B7, leverages multiple transformer-based expert modules for dynamic token routing, enhancing modeling efficiency and scalability. The primary advantage of MoE lies in its ability to handle vast parameter scales, reducing memory footprint and computational costs significantly [93, 94, 95, 96, 97]. This is achieved through model parallelism across specialized experts, allowing the training of models with trillions of parameters, and its specialization in handling diverse data distributions enhances its capability in few-shot learning and other complex tasks [94, 95]. To illustrate the practicality of MoE, consider its application in healthcare. For example, an MoE-based system could be used for personalized medicine, where different ‘expert’ modules specialize in various aspects of patient data analysis<b>.<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><b/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen(model, ds_train.with_format('pt')[0], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
